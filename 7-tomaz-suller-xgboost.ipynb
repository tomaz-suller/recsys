{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use XGBoost in RecSys\n",
    "* Run your best algorithm and select a number of recommendations higher than the target cutoff, for example if you have to compute MAP@10, get 20 recommendations\n",
    "* Build a dataframe whose samples are the user-item recommendations\n",
    "* Add for each interaction some content features: item features, user features\n",
    "* Add for each interaction some features derived by other algorithms: CBF prediction, hybrid prediction\n",
    "* Add for each interaction other miscellaneous information: profile length, item popularity .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import scipy.sparse as sps\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBRanker\n",
    "\n",
    "from Data_manager.competition import load, load_raw\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Recommenders.Similarity.Compute_Similarity import Compute_Similarity\n",
    "from Recommenders.Hybrid import UserWideHybridRecommender, ScoresMultipleHybridRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_FOLDS = 10\n",
    "CUTOFF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODELS_DIR = Path() / \"models\" / \"train\" / \"map\"\n",
    "MODELS_DIR.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34226</th>\n",
       "      <td>35729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34227</th>\n",
       "      <td>35730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34228</th>\n",
       "      <td>35731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34229</th>\n",
       "      <td>35734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34230</th>\n",
       "      <td>35735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34231 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id\n",
       "0            0\n",
       "1            1\n",
       "2            2\n",
       "3            3\n",
       "4            4\n",
       "...        ...\n",
       "34226    35729\n",
       "34227    35730\n",
       "34228    35731\n",
       "34229    35734\n",
       "34230    35735\n",
       "\n",
       "[34231 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_ID_PATH = Path() / \"Data_manager_split_datasets\" / \"competition\" / \"data_target_users_test.csv\"\n",
    "test_df = pd.read_csv(TEST_ID_PATH)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_PATH = Path(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736 38121\n"
     ]
    }
   ],
   "source": [
    "icm_df, urm_df = load_raw()\n",
    "number_users = urm_df[\"user_id\"].nunique()\n",
    "number_items = icm_df[\"item_id\"].nunique()\n",
    "print(number_users, number_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "icm_matrix, urm_all, urm_train, urm_validation, urm_test = load()\n",
    "ranker_urm = urm_validation + urm_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_user_dicts(user_dicts: list[dict]) -> dict:\n",
    "    return  {\n",
    "        user_dict[\"UserID\"]: user_dict[\"ItemID\"][0]\n",
    "        for user_dict in user_dicts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_to_list() -> pl.Expr:\n",
    "    return pl.col(\"ItemID\").implode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(input_df: pd.DataFrame, model: XGBRanker, drop_ids: bool = False) -> dict[int, list]:\n",
    "    output_df = input_df[[\"UserID\", \"ItemID\"]].copy()\n",
    "    if drop_ids:\n",
    "        input_df = input_df.drop(columns=[\"UserID\", \"ItemID\"])\n",
    "    output_df[\"Score\"] = model.predict(input_df)\n",
    "\n",
    "    output_dicts = (\n",
    "        pl.from_pandas(output_df)\n",
    "        .group_by(\"UserID\", \"ItemID\")\n",
    "        .agg(pl.mean(\"Score\"))\n",
    "        .sort(\"UserID\", \"Score\", descending=True)\n",
    "        .group_by(\"UserID\")\n",
    "        .head(10)\n",
    "        .group_by(\"UserID\")\n",
    "        .agg(item_to_list())\n",
    "        .to_dicts()\n",
    "    )\n",
    "    return encode_user_dicts(output_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_targets(input_df: pd.DataFrame, relevant_mask: pd.Series) -> dict[int, list]:\n",
    "    return encode_user_dicts(\n",
    "        pl.from_pandas(input_df[relevant_mask])\n",
    "        .group_by(\"UserID\")\n",
    "        .agg(item_to_list())\n",
    "        .to_dicts()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(predictions: Union[dict[int, list], list[list]], true_labels: Union[dict[int, list], list[list]], k=10):\n",
    "    \"\"\"\n",
    "    Compute Mean Average Precision at K (MAP@K).\n",
    "\n",
    "    Parameters:\n",
    "    - predictions: A list of lists, where each inner list contains the predicted item IDs for a user (ranked in descending order of relevance).\n",
    "    - true_labels: A list of sets, where each set contains the ground-truth relevant item IDs for the corresponding user.\n",
    "    - k: The cutoff for precision evaluation.\n",
    "\n",
    "    Returns:\n",
    "    - mean_ap: Mean Average Precision at K across all users.\n",
    "    \"\"\"\n",
    "    def average_precision_at_k(predicted, actual, k):\n",
    "        if len(predicted) > k:\n",
    "            predicted = predicted[:k]\n",
    "\n",
    "        score = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(predicted):\n",
    "            if p in actual and p not in predicted[:i]:  # Avoid duplicates\n",
    "                num_hits += 1.0\n",
    "                score += num_hits / (i + 1.0)\n",
    "\n",
    "        if not actual:\n",
    "            return 0.0\n",
    "\n",
    "        return score / min(len(actual), k)\n",
    "\n",
    "    if isinstance(predictions, list):\n",
    "        predictions = {user: prediction for user, prediction in enumerate(predictions)}\n",
    "    if isinstance(true_labels, list):\n",
    "        true_labels = {user: true for user, true in enumerate(true_labels)}\n",
    "\n",
    "    # Calculate AP@K for each user\n",
    "    ap_scores = [\n",
    "        average_precision_at_k(predictions[user], true, k)\n",
    "        for user, true in true_labels.items()\n",
    "    ]\n",
    "\n",
    "    # Return the mean AP@K\n",
    "    return np.mean(ap_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_WIDE_HYBRID_BEGIN = 30\n",
    "MODELS_TO_USE = (\n",
    "    60,\n",
    "    61,\n",
    "    62,\n",
    "    63,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_GROUPS_USER_WIDE_HYBRID = 10\n",
    "MULTIPLE_SCORE_HYBRID_WEIGHTS = {\n",
    "    50: 0.253770701546336,\n",
    "    51: 0.10324855050317669,\n",
    "}\n",
    "\n",
    "\n",
    "def build_user_wide_hybrid(urm: sps.csr_matrix, models: dict[str, BaseRecommender]):\n",
    "    profile_lengths = np.ediff1d(urm.indptr)\n",
    "    sorted_users = np.argsort(profile_lengths)\n",
    "    block_size = len(sorted_users) // NUMBER_GROUPS_USER_WIDE_HYBRID\n",
    "    group_users = {}\n",
    "    for group in range(NUMBER_GROUPS_USER_WIDE_HYBRID + 1):\n",
    "        group_users[group] = sorted_users[group * block_size : (group + 1) * block_size]\n",
    "    group_recommenders = {\n",
    "        group: models.pop(str(USER_WIDE_HYBRID_BEGIN + group)) for group in range(NUMBER_GROUPS_USER_WIDE_HYBRID + 1)\n",
    "    }\n",
    "    return UserWideHybridRecommender(urm, group_users, group_recommenders)\n",
    "\n",
    "def build_score_hybrid(urm: sps.csr_matrix, models: dict[str, BaseRecommender]):\n",
    "    recommenders = [models.pop(str(index)) for index in MULTIPLE_SCORE_HYBRID_WEIGHTS.keys()]\n",
    "    weights = list(MULTIPLE_SCORE_HYBRID_WEIGHTS.values())\n",
    "    return ScoresMultipleHybridRecommender(urm, recommenders, weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d8d787a9712422d91cd8c2875d987dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d19a6d93fb4f2c8adda06927553c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "314e33bdee12439fbd3d82454588f95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56651a22c6464e8a82562e1c64618372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67c2f95c969455598ab37a017609db8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990825a43f5340529bf6be37384033f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4daf419a196d4937b8aae2d0e982bb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a458106350437d959d265be0c04ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd4944638724587b1ba28353176aadd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415d572864e84c9c98a550b9d0083233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49cdf4dbafc94f62b04ed3a32fcaff21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f4a1799538b48f492ff8283abb63a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca2282770bf643a081c9ad67c476872a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31bb835aaa1245ffb42b46cccc0fa432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312646ac1a564fc1aee2c3f5dccf5fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd89161fe1fe4413bb9aee373f38553a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5b3f9bd2530450fbc72fd7c089432c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "455f317c1af94fb39cb44c843ce6f442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91adeb26b2934ea79cdcefc0b0dcadab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/sklearn/base.py:376: InconsistentVersionWarning: Trying to unpickle estimator ElasticNet from version 1.6.0 when using version 1.5.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b0e82b24bc44d55b080ce9598b2ccb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a2a1b49898443f9901b8d95bdb5328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_training_dataframes: dict[int, pd.DataFrame] = {}\n",
    "for i, (train_indices, val_indices) in tqdm(\n",
    "    enumerate(KFold(NUMBER_FOLDS, shuffle=True, random_state=42).split(urm_df)),\n",
    "    total=NUMBER_FOLDS,\n",
    "    desc=\"Fold\",\n",
    "):\n",
    "    fold_urm_train_df = urm_df.iloc[train_indices]\n",
    "    fold_urm_train  = sps.csr_matrix(\n",
    "        (fold_urm_train_df.data, (fold_urm_train_df.user_id, fold_urm_train_df.item_id)),\n",
    "        shape=(number_users, number_items),\n",
    "    )\n",
    "\n",
    "    fold_models_dir = MODELS_DIR / str(i)\n",
    "    models: dict[str, BaseRecommender] = {\n",
    "        path.stem: pickle.load(path.open(\"rb\"))\n",
    "        for path in fold_models_dir.glob(\"*.pkl\")\n",
    "    }\n",
    "    if \"user_wide_hybrid\" not in models:\n",
    "        fold_user_wide_hybrid = build_user_wide_hybrid(fold_urm_train, models)\n",
    "    # if \"score_hybrid\" not in models:\n",
    "    #     fold_score_hybrid = build_score_hybrid(fold_urm_train, models)\n",
    "\n",
    "    models = {str(index): models[str(index)] for index in MODELS_TO_USE}\n",
    "    if \"user_wide_hybrid\" not in models:\n",
    "        models[\"user_wide_hybrid\"] = fold_user_wide_hybrid\n",
    "    # if \"score_hybrid\" not in models:\n",
    "    #     models[\"score_hybrid\"] = fold_score_hybrid\n",
    "\n",
    "    training_dataframe = pd.DataFrame(index=range(0, number_users), columns=[\"ItemID\"])\n",
    "    training_dataframe.index.name = \"UserID\"\n",
    "\n",
    "    recommendations_list = []\n",
    "    recommenders_list = []\n",
    "    rank_list = []\n",
    "    for user_id in tqdm(range(number_users), desc=\"User (candidate)\"):\n",
    "        user_recommendations = []\n",
    "        user_recommenders = []\n",
    "        user_rankings = []\n",
    "        for name, recommender in models.items():\n",
    "            user_recommendations.extend(\n",
    "                recommender.recommend(\n",
    "                    user_id,\n",
    "                    cutoff=CUTOFF,\n",
    "                    remove_seen_flag=True,\n",
    "                )\n",
    "            )\n",
    "            user_recommenders.extend([name] * CUTOFF)\n",
    "            user_rankings.extend(list(range(CUTOFF)))\n",
    "        recommendations_list.append(user_recommendations)\n",
    "        recommenders_list.append(user_recommenders)\n",
    "        rank_list.append(user_rankings)\n",
    "\n",
    "    training_dataframe[\"ItemID\"] = recommendations_list\n",
    "    training_dataframe[\"Recommender\"] = recommenders_list\n",
    "    training_dataframe[\"Ranking\"] = rank_list\n",
    "\n",
    "    exploded_recommender = training_dataframe[\"Recommender\"].explode()\n",
    "    exploded_ranking = training_dataframe[\"Ranking\"].explode()\n",
    "    training_dataframe = training_dataframe.explode(\"ItemID\")\n",
    "    training_dataframe[\"Recommender\"] = exploded_recommender\n",
    "    training_dataframe[\"Ranking\"] = exploded_ranking.astype(\"int\")\n",
    "\n",
    "    recommender_agreement = (\n",
    "        training_dataframe.reset_index()[[\"UserID\", \"ItemID\"]]\n",
    "        .groupby([\"UserID\", \"ItemID\"])\n",
    "        .value_counts()\n",
    "    )\n",
    "    training_dataframe[\"recommender_agreement\"] = recommender_agreement.loc[\n",
    "        list(zip(training_dataframe.index, training_dataframe[\"ItemID\"]))\n",
    "    ].to_numpy()\n",
    "\n",
    "    fold_urm_val_df = urm_df.iloc[val_indices]\n",
    "    fold_urm_val  = sps.csr_matrix(\n",
    "        (fold_urm_val_df.data, (fold_urm_val_df.user_id, fold_urm_val_df.item_id)),\n",
    "        shape=(number_users, number_items),\n",
    "    )\n",
    "    fold_urm_coo = sps.coo_matrix(fold_urm_val)\n",
    "    correct_recommendations = pd.DataFrame(\n",
    "        {\"UserID\": fold_urm_coo.row, \"ItemID\": fold_urm_coo.col}\n",
    "    )\n",
    "    training_dataframe = training_dataframe.merge(\n",
    "        correct_recommendations,\n",
    "        on=[\"UserID\", \"ItemID\"],\n",
    "        how=\"left\",\n",
    "        indicator=\"Exist\",\n",
    "    )\n",
    "    training_dataframe[\"Label\"] = training_dataframe[\"Exist\"] == \"both\"\n",
    "    training_dataframe = training_dataframe.drop(columns=[\"Exist\"])\n",
    "\n",
    "    training_dataframe = training_dataframe.set_index(\"UserID\")\n",
    "    for user_id in tqdm(training_dataframe.index.unique(), desc=\"User (score)\"):\n",
    "        for rec_label, rec_instance in models.items():\n",
    "            item_list = training_dataframe.loc[user_id, \"ItemID\"].to_list()\n",
    "\n",
    "            all_item_scores = rec_instance._compute_item_score(\n",
    "                [user_id], items_to_compute=item_list\n",
    "            )\n",
    "\n",
    "            training_dataframe.loc[user_id, rec_label] = all_item_scores[0, item_list]\n",
    "\n",
    "    training_dataframe = training_dataframe.reset_index()\n",
    "    training_dataframe = training_dataframe.rename(columns={\"index\": \"UserID\"})\n",
    "\n",
    "    training_dataframe[\"fold\"] = i\n",
    "    fold_training_dataframes[i] = training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>Label</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7703</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.268031</td>\n",
       "      <td>0.401745</td>\n",
       "      <td>2.693894</td>\n",
       "      <td>0.085774</td>\n",
       "      <td>0.272271</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>7547</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>0.258316</td>\n",
       "      <td>0.352410</td>\n",
       "      <td>2.404292</td>\n",
       "      <td>0.066998</td>\n",
       "      <td>0.265295</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>6822</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>0.237978</td>\n",
       "      <td>0.143136</td>\n",
       "      <td>0.850208</td>\n",
       "      <td>0.182649</td>\n",
       "      <td>0.221734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.234505</td>\n",
       "      <td>0.300062</td>\n",
       "      <td>1.903718</td>\n",
       "      <td>0.160482</td>\n",
       "      <td>0.222038</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3077</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>0.234102</td>\n",
       "      <td>0.241273</td>\n",
       "      <td>1.361896</td>\n",
       "      <td>0.182695</td>\n",
       "      <td>0.232855</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>37445</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.343499</td>\n",
       "      <td>0.630422</td>\n",
       "      <td>4.550226</td>\n",
       "      <td>0.199559</td>\n",
       "      <td>0.353038</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37507</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.313335</td>\n",
       "      <td>0.395291</td>\n",
       "      <td>1.350077</td>\n",
       "      <td>0.171390</td>\n",
       "      <td>0.333600</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>0.326151</td>\n",
       "      <td>0.581158</td>\n",
       "      <td>3.998512</td>\n",
       "      <td>0.191833</td>\n",
       "      <td>0.327440</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>34998</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>0.326401</td>\n",
       "      <td>0.430699</td>\n",
       "      <td>2.925698</td>\n",
       "      <td>0.127431</td>\n",
       "      <td>0.326283</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>37801</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>0.304025</td>\n",
       "      <td>0.662617</td>\n",
       "      <td>4.754726</td>\n",
       "      <td>0.184366</td>\n",
       "      <td>0.299684</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17868000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0   7703                60        0                      4   \n",
       "1             0   7547                60        1                      4   \n",
       "2             0   6822                60        2                      3   \n",
       "3             0    572                60        3                      5   \n",
       "4             0   3077                60        4                      4   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  37445  user_wide_hybrid        5                      5   \n",
       "1786796   35735  37507  user_wide_hybrid        6                      2   \n",
       "1786797   35735  36775  user_wide_hybrid        7                      5   \n",
       "1786798   35735  34998  user_wide_hybrid        8                      2   \n",
       "1786799   35735  37801  user_wide_hybrid        9                      5   \n",
       "\n",
       "         Label        60        61        62        63  user_wide_hybrid  fold  \n",
       "0        False  0.268031  0.401745  2.693894  0.085774          0.272271     0  \n",
       "1        False  0.258316  0.352410  2.404292  0.066998          0.265295     0  \n",
       "2         True  0.237978  0.143136  0.850208  0.182649          0.221734     0  \n",
       "3        False  0.234505  0.300062  1.903718  0.160482          0.222038     0  \n",
       "4         True  0.234102  0.241273  1.361896  0.182695          0.232855     0  \n",
       "...        ...       ...       ...       ...       ...               ...   ...  \n",
       "1786795  False  0.343499  0.630422  4.550226  0.199559          0.353038     9  \n",
       "1786796  False  0.313335  0.395291  1.350077  0.171390          0.333600     9  \n",
       "1786797  False  0.326151  0.581158  3.998512  0.191833          0.327440     9  \n",
       "1786798  False  0.326401  0.430699  2.925698  0.127431          0.326283     9  \n",
       "1786799   True  0.304025  0.662617  4.754726  0.184366          0.299684     9  \n",
       "\n",
       "[17868000 rows x 12 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = pd.concat(fold_training_dataframes.values())\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da10807b63c247f0b58be17496ddf0db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c89412e08183457babf610432cfcf64c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273  \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018  \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547  \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901  \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573  \n",
       "...           ...       ...       ...       ...               ...  \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134  \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393  \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799  \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921  \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385  \n",
       "\n",
       "[1786800 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_models_dir = Path() / \"models\" / \"all\" / \"map\" / \"0\"\n",
    "models: dict[str, BaseRecommender] = {\n",
    "    path.stem: pickle.load(path.open(\"rb\"))\n",
    "    for path in submit_models_dir.glob(\"*.pkl\")\n",
    "}\n",
    "\n",
    "submission_dataframe = pd.DataFrame(index=range(0, number_users), columns=[\"ItemID\"])\n",
    "submission_dataframe.index.name = \"UserID\"\n",
    "\n",
    "recommendations_list = []\n",
    "recommenders_list = []\n",
    "rank_list = []\n",
    "for user_id in tqdm(range(number_users), desc=\"User (candidate)\"):\n",
    "    user_recommendations = []\n",
    "    user_recommenders = []\n",
    "    user_rankings = []\n",
    "    for name, recommender in models.items():\n",
    "        user_recommendations.extend(\n",
    "            recommender.recommend(\n",
    "                user_id,\n",
    "                cutoff=CUTOFF,\n",
    "                remove_seen_flag=True,\n",
    "            )\n",
    "        )\n",
    "        user_recommenders.extend([name] * CUTOFF)\n",
    "        user_rankings.extend(list(range(CUTOFF)))\n",
    "    recommendations_list.append(user_recommendations)\n",
    "    recommenders_list.append(user_recommenders)\n",
    "    rank_list.append(user_rankings)\n",
    "\n",
    "submission_dataframe[\"ItemID\"] = recommendations_list\n",
    "submission_dataframe[\"Recommender\"] = recommenders_list\n",
    "submission_dataframe[\"Ranking\"] = rank_list\n",
    "\n",
    "exploded_recommender = submission_dataframe[\"Recommender\"].explode()\n",
    "exploded_ranking = submission_dataframe[\"Ranking\"].explode()\n",
    "submission_dataframe = submission_dataframe.explode(\"ItemID\")\n",
    "submission_dataframe[\"Recommender\"] = exploded_recommender\n",
    "submission_dataframe[\"Ranking\"] = exploded_ranking.astype(\"int\")\n",
    "\n",
    "recommender_agreement = (\n",
    "    submission_dataframe.reset_index()[[\"UserID\", \"ItemID\"]]\n",
    "    .groupby([\"UserID\", \"ItemID\"])\n",
    "    .value_counts()\n",
    ")\n",
    "submission_dataframe[\"recommender_agreement\"] = recommender_agreement.loc[\n",
    "    list(zip(submission_dataframe.index, submission_dataframe[\"ItemID\"]))\n",
    "].to_numpy()\n",
    "\n",
    "\n",
    "for user_id in tqdm(submission_dataframe.index.unique(), desc=\"User (score)\"):\n",
    "    for rec_label, rec_instance in models.items():\n",
    "        item_list = submission_dataframe.loc[user_id, \"ItemID\"].to_list()\n",
    "\n",
    "        all_item_scores = rec_instance._compute_item_score(\n",
    "            [user_id], items_to_compute=item_list\n",
    "        )\n",
    "\n",
    "        submission_dataframe.loc[user_id, rec_label] = all_item_scores[0, item_list]\n",
    "\n",
    "submission_dataframe = submission_dataframe.reset_index()\n",
    "submission_dataframe = submission_dataframe.rename(columns={\"index\": \"UserID\"})\n",
    "submission_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273  \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018  \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547  \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901  \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573  \n",
       "...           ...       ...       ...       ...               ...  \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134  \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393  \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799  \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921  \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385  \n",
       "\n",
       "[1786800 rows x 10 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = submission_dataframe\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_popularity = np.ediff1d(sps.csc_matrix(urm_all).indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>Label</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>fold</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11919</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>2.036243</td>\n",
       "      <td>0.185144</td>\n",
       "      <td>0.457867</td>\n",
       "      <td>0.898495</td>\n",
       "      <td>0.279088</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.010543</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>6166</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>1.322843</td>\n",
       "      <td>0.142692</td>\n",
       "      <td>0.410831</td>\n",
       "      <td>0.314082</td>\n",
       "      <td>0.275740</td>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>3.110688</td>\n",
       "      <td>0.239450</td>\n",
       "      <td>0.206285</td>\n",
       "      <td>0.740719</td>\n",
       "      <td>0.144743</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2.772010</td>\n",
       "      <td>0.219615</td>\n",
       "      <td>0.148456</td>\n",
       "      <td>0.641081</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3055</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2.486904</td>\n",
       "      <td>0.125511</td>\n",
       "      <td>0.207595</td>\n",
       "      <td>0.236244</td>\n",
       "      <td>0.265044</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867995</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>5.954237</td>\n",
       "      <td>0.231383</td>\n",
       "      <td>0.389701</td>\n",
       "      <td>1.841514</td>\n",
       "      <td>0.552304</td>\n",
       "      <td>6</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867996</th>\n",
       "      <td>35735</td>\n",
       "      <td>36034</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>10.295866</td>\n",
       "      <td>0.404087</td>\n",
       "      <td>0.471801</td>\n",
       "      <td>2.180797</td>\n",
       "      <td>1.575182</td>\n",
       "      <td>9</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867997</th>\n",
       "      <td>35735</td>\n",
       "      <td>36266</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>4.560175</td>\n",
       "      <td>0.319728</td>\n",
       "      <td>0.326213</td>\n",
       "      <td>1.904749</td>\n",
       "      <td>0.555987</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>0.001241</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867998</th>\n",
       "      <td>35735</td>\n",
       "      <td>37800</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>6.373811</td>\n",
       "      <td>0.285733</td>\n",
       "      <td>0.520935</td>\n",
       "      <td>1.544810</td>\n",
       "      <td>1.246396</td>\n",
       "      <td>9</td>\n",
       "      <td>76</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867999</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>5.902622</td>\n",
       "      <td>0.321256</td>\n",
       "      <td>0.215594</td>\n",
       "      <td>1.113893</td>\n",
       "      <td>0.561077</td>\n",
       "      <td>6</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17868000 rows Ã— 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          UserID  ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0              0   11919  user_wide_hybrid        4                      4   \n",
       "1              0    6166  user_wide_hybrid        5                      2   \n",
       "2              0     572                23        0                      3   \n",
       "3              0   14888                23        1                      3   \n",
       "4              0    3055                23        2                      2   \n",
       "...          ...     ...               ...      ...                    ...   \n",
       "17867995   35735   37017                22        2                      3   \n",
       "17867996   35735   36034                23        0                      5   \n",
       "17867997   35735   36266  user_wide_hybrid        6                      4   \n",
       "17867998   35735   37800  user_wide_hybrid        4                      3   \n",
       "17867999   35735   37660  user_wide_hybrid        5                      3   \n",
       "\n",
       "          Label         23        21        22        20  user_wide_hybrid  \\\n",
       "0         False   2.036243  0.185144  0.457867  0.898495          0.279088   \n",
       "1         False   1.322843  0.142692  0.410831  0.314082          0.275740   \n",
       "2         False   3.110688  0.239450  0.206285  0.740719          0.144743   \n",
       "3         False   2.772010  0.219615  0.148456  0.641081          0.263636   \n",
       "4         False   2.486904  0.125511  0.207595  0.236244          0.265044   \n",
       "...         ...        ...       ...       ...       ...               ...   \n",
       "17867995  False   5.954237  0.231383  0.389701  1.841514          0.552304   \n",
       "17867996  False  10.295866  0.404087  0.471801  2.180797          1.575182   \n",
       "17867997   True   4.560175  0.319728  0.326213  1.904749          0.555987   \n",
       "17867998   True   6.373811  0.285733  0.520935  1.544810          1.246396   \n",
       "17867999  False   5.902622  0.321256  0.215594  1.113893          0.561077   \n",
       "\n",
       "          fold  item_popularity  item_similarity  user_profile_len  top_10  \\\n",
       "0            0               29         0.010543               114     0.0   \n",
       "1            0              129         0.000371               114     0.0   \n",
       "2            0               93         0.000246               114     0.0   \n",
       "3            0              110         0.000250               114     0.0   \n",
       "4            0               93         0.001264               114     0.0   \n",
       "...        ...              ...              ...               ...     ...   \n",
       "17867995     6               58         0.003902                37     0.0   \n",
       "17867996     9               81         0.000403                37     0.0   \n",
       "17867997     6               20         0.001241                37     0.0   \n",
       "17867998     9               76         0.003428                37     0.0   \n",
       "17867999     6               70         0.003902                37     0.0   \n",
       "\n",
       "          top_100  top_1000  user_similarity  \n",
       "0             1.0       7.0         0.000183  \n",
       "1             1.0       7.0         0.000183  \n",
       "2             1.0       7.0         0.000183  \n",
       "3             1.0       7.0         0.000183  \n",
       "4             1.0       7.0         0.000183  \n",
       "...           ...       ...              ...  \n",
       "17867995      0.0       0.0         0.000272  \n",
       "17867996      0.0       0.0         0.000272  \n",
       "17867997      0.0       0.0         0.000272  \n",
       "17867998      0.0       0.0         0.000272  \n",
       "17867999      0.0       0.0         0.000272  \n",
       "\n",
       "[17868000 rows x 19 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe[\"item_popularity\"] = item_popularity[\n",
    "    training_dataframe[\"ItemID\"].to_numpy().astype(int)\n",
    "]\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance to closest items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 38121 (100.0%), 984.42 column/sec. Elapsed time 38.72 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 3812100 stored elements and shape (38121, 38121)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity = Compute_Similarity(icm_matrix.T).compute_similarity()\n",
    "item_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38116</th>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38117</th>\n",
       "      <td>0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38118</th>\n",
       "      <td>0.005463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38119</th>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38120</th>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38121 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_similarity\n",
       "0             0.000046\n",
       "1             0.000309\n",
       "2             0.000140\n",
       "3             0.000105\n",
       "4             0.000015\n",
       "...                ...\n",
       "38116         0.000397\n",
       "38117         0.007546\n",
       "38118         0.005463\n",
       "38119         0.000602\n",
       "38120         0.002821\n",
       "\n",
       "[38121 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_item_similarity_dict = {i: row.mean() for i, row in enumerate(item_similarity)}\n",
    "mean_item_similarity: pd.DataFrame = pd.Series(mean_item_similarity_dict).to_frame(name=\"item_similarity\")\n",
    "mean_item_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  item_similarity  \n",
       "0                     93         0.000246  \n",
       "1                    110         0.000250  \n",
       "2                    120         0.000545  \n",
       "3                     27         0.000040  \n",
       "4                    107         0.000224  \n",
       "...                  ...              ...  \n",
       "1786795               88         0.003954  \n",
       "1786796               70         0.003902  \n",
       "1786797              147         0.003986  \n",
       "1786798               58         0.003902  \n",
       "1786799               28         0.000684  \n",
       "\n",
       "[1786800 rows x 12 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = training_dataframe.join(mean_item_similarity, on=\"ItemID\")\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_popularity = np.ediff1d(sps.csr_matrix(urm_all).indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  \n",
       "0                     93         0.000246               114  \n",
       "1                    110         0.000250               114  \n",
       "2                    120         0.000545               114  \n",
       "3                     27         0.000040               114  \n",
       "4                    107         0.000224               114  \n",
       "...                  ...              ...               ...  \n",
       "1786795               88         0.003954                37  \n",
       "1786796               70         0.003902                37  \n",
       "1786797              147         0.003986                37  \n",
       "1786798               58         0.003902                37  \n",
       "1786799               28         0.000684                37  \n",
       "\n",
       "[1786800 rows x 13 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe[\"user_profile_len\"] = user_popularity[\n",
    "    training_dataframe[\"UserID\"].to_numpy().astype(int)\n",
    "]\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User popularity bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of how much popularity influences the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11146, 25392,  4601, ...,  8491, 21675,  8152])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_popularity_ranking = item_popularity.argsort()[::-1]\n",
    "item_popularity_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764602</th>\n",
       "      <td>35735</td>\n",
       "      <td>37802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764603</th>\n",
       "      <td>35735</td>\n",
       "      <td>37803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764604</th>\n",
       "      <td>35735</td>\n",
       "      <td>37805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764605</th>\n",
       "      <td>35735</td>\n",
       "      <td>38000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764606</th>\n",
       "      <td>35735</td>\n",
       "      <td>38034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1764607 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id\n",
       "0              0        0\n",
       "1              0        2\n",
       "2              0      120\n",
       "3              0      128\n",
       "4              0      211\n",
       "...          ...      ...\n",
       "1764602    35735    37802\n",
       "1764603    35735    37803\n",
       "1764604    35735    37805\n",
       "1764605    35735    38000\n",
       "1764606    35735    38034\n",
       "\n",
       "[1764607 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_id_df = urm_df[[\"user_id\", \"item_id\"]]\n",
    "item_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_POPULAR_THRESHOLDS = (10, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764602</th>\n",
       "      <td>35735</td>\n",
       "      <td>37802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764603</th>\n",
       "      <td>35735</td>\n",
       "      <td>37803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764604</th>\n",
       "      <td>35735</td>\n",
       "      <td>37805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764605</th>\n",
       "      <td>35735</td>\n",
       "      <td>38000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764606</th>\n",
       "      <td>35735</td>\n",
       "      <td>38034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1764607 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  top_10  top_100  top_1000\n",
       "0              0        0     0.0      0.0       0.0\n",
       "1              0        2     0.0      0.0       0.0\n",
       "2              0      120     0.0      0.0       0.0\n",
       "3              0      128     0.0      0.0       0.0\n",
       "4              0      211     0.0      0.0       1.0\n",
       "...          ...      ...     ...      ...       ...\n",
       "1764602    35735    37802     0.0      0.0       0.0\n",
       "1764603    35735    37803     0.0      0.0       0.0\n",
       "1764604    35735    37805     0.0      0.0       0.0\n",
       "1764605    35735    38000     0.0      0.0       0.0\n",
       "1764606    35735    38034     0.0      0.0       0.0\n",
       "\n",
       "[1764607 rows x 5 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in TOP_POPULAR_THRESHOLDS:\n",
    "    top_k_popular = item_popularity_ranking[:k]\n",
    "    item_id_df.loc[item_id_df[\"item_id\"].isin(top_k_popular), f\"top_{k}\"] = 1\n",
    "item_id_df = item_id_df.fillna(0)\n",
    "item_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35733</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35735</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35736 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         top_10  top_100  top_1000\n",
       "user_id                           \n",
       "0           0.0      1.0       7.0\n",
       "1           2.0      3.0      10.0\n",
       "2           0.0      0.0       0.0\n",
       "3           1.0      4.0      11.0\n",
       "4           0.0      3.0      29.0\n",
       "...         ...      ...       ...\n",
       "35731       0.0      0.0       0.0\n",
       "35732       0.0      0.0       1.0\n",
       "35733       0.0      0.0       0.0\n",
       "35734       0.0      0.0       0.0\n",
       "35735       0.0      0.0       0.0\n",
       "\n",
       "[35736 rows x 3 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_top_k_df = item_id_df.groupby(\"user_id\").aggregate({f\"top_{k}\": \"sum\" for k in TOP_POPULAR_THRESHOLDS})\n",
    "user_top_k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  top_10  top_100  \\\n",
       "0                     93         0.000246               114     0.0      1.0   \n",
       "1                    110         0.000250               114     0.0      1.0   \n",
       "2                    120         0.000545               114     0.0      1.0   \n",
       "3                     27         0.000040               114     0.0      1.0   \n",
       "4                    107         0.000224               114     0.0      1.0   \n",
       "...                  ...              ...               ...     ...      ...   \n",
       "1786795               88         0.003954                37     0.0      0.0   \n",
       "1786796               70         0.003902                37     0.0      0.0   \n",
       "1786797              147         0.003986                37     0.0      0.0   \n",
       "1786798               58         0.003902                37     0.0      0.0   \n",
       "1786799               28         0.000684                37     0.0      0.0   \n",
       "\n",
       "         top_1000  \n",
       "0             7.0  \n",
       "1             7.0  \n",
       "2             7.0  \n",
       "3             7.0  \n",
       "4             7.0  \n",
       "...           ...  \n",
       "1786795       0.0  \n",
       "1786796       0.0  \n",
       "1786797       0.0  \n",
       "1786798       0.0  \n",
       "1786799       0.0  \n",
       "\n",
       "[1786800 rows x 16 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = training_dataframe.join(user_top_k_df, on=\"UserID\")\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance to closest users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 35736 (100.0%), 6092.46 column/sec. Elapsed time 5.87 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 3573591 stored elements and shape (35736, 35736)>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity = Compute_Similarity(urm_all.T).compute_similarity()\n",
    "user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35731</th>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35732</th>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35733</th>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35734</th>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35735</th>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35736 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_similarity\n",
       "0             0.000183\n",
       "1             0.000357\n",
       "2             0.000161\n",
       "3             0.000158\n",
       "4             0.001004\n",
       "...                ...\n",
       "35731         0.000204\n",
       "35732         0.000333\n",
       "35733         0.000267\n",
       "35734         0.000341\n",
       "35735         0.000272\n",
       "\n",
       "[35736 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_user_similarity_dict = {i: row.mean() for i, row in enumerate(user_similarity)}\n",
    "mean_user_similarity: pd.DataFrame = pd.Series(mean_user_similarity_dict).to_frame(name=\"user_similarity\")\n",
    "mean_user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  top_10  top_100  \\\n",
       "0                     93         0.000246               114     0.0      1.0   \n",
       "1                    110         0.000250               114     0.0      1.0   \n",
       "2                    120         0.000545               114     0.0      1.0   \n",
       "3                     27         0.000040               114     0.0      1.0   \n",
       "4                    107         0.000224               114     0.0      1.0   \n",
       "...                  ...              ...               ...     ...      ...   \n",
       "1786795               88         0.003954                37     0.0      0.0   \n",
       "1786796               70         0.003902                37     0.0      0.0   \n",
       "1786797              147         0.003986                37     0.0      0.0   \n",
       "1786798               58         0.003902                37     0.0      0.0   \n",
       "1786799               28         0.000684                37     0.0      0.0   \n",
       "\n",
       "         top_1000  user_similarity  \n",
       "0             7.0         0.000183  \n",
       "1             7.0         0.000183  \n",
       "2             7.0         0.000183  \n",
       "3             7.0         0.000183  \n",
       "4             7.0         0.000183  \n",
       "...           ...              ...  \n",
       "1786795       0.0         0.000272  \n",
       "1786796       0.0         0.000272  \n",
       "1786797       0.0         0.000272  \n",
       "1786798       0.0         0.000272  \n",
       "1786799       0.0         0.000272  \n",
       "\n",
       "[1786800 rows x 17 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = training_dataframe.join(mean_user_similarity, on=\"UserID\")\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6166</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142024</td>\n",
       "      <td>0.421410</td>\n",
       "      <td>0.353835</td>\n",
       "      <td>0.270525</td>\n",
       "      <td>129</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11966</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145097</td>\n",
       "      <td>0.267107</td>\n",
       "      <td>0.893614</td>\n",
       "      <td>0.283992</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2743</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.452733</td>\n",
       "      <td>0.195061</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>0.521364</td>\n",
       "      <td>0.284803</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2637</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197307</td>\n",
       "      <td>0.381694</td>\n",
       "      <td>0.790003</td>\n",
       "      <td>0.218590</td>\n",
       "      <td>67</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>738</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.694155</td>\n",
       "      <td>0.103107</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.318969</td>\n",
       "      <td>0.093946</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37445</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.411239</td>\n",
       "      <td>0.408742</td>\n",
       "      <td>0.455056</td>\n",
       "      <td>3.137702</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36917</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.380329</td>\n",
       "      <td>0.453475</td>\n",
       "      <td>0.383239</td>\n",
       "      <td>2.259961</td>\n",
       "      <td>0.839466</td>\n",
       "      <td>76</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>36034</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.576296</td>\n",
       "      <td>0.430645</td>\n",
       "      <td>0.403139</td>\n",
       "      <td>2.485576</td>\n",
       "      <td>1.015675</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>36493</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11.521591</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.614241</td>\n",
       "      <td>2.720541</td>\n",
       "      <td>1.047983</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0   6166  user_wide_hybrid        7                      2   \n",
       "1             0  11966  user_wide_hybrid        6                      1   \n",
       "2             0   2743  user_wide_hybrid        5                      1   \n",
       "3             0   2637                22        8                      1   \n",
       "4             0    738                22        9                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37445  user_wide_hybrid        4                      5   \n",
       "1786797   35735  36917  user_wide_hybrid        3                      5   \n",
       "1786798   35735  36034  user_wide_hybrid        2                      5   \n",
       "1786799   35735  36493  user_wide_hybrid        1                      5   \n",
       "\n",
       "                23        21        22        20  user_wide_hybrid  \\\n",
       "0         0.000000  0.142024  0.421410  0.353835          0.270525   \n",
       "1         0.000000  0.145097  0.267107  0.893614          0.283992   \n",
       "2         1.452733  0.195061  0.273309  0.521364          0.284803   \n",
       "3         0.000000  0.197307  0.381694  0.790003          0.218590   \n",
       "4         1.694155  0.103107  0.370141  0.318969          0.093946   \n",
       "...            ...       ...       ...       ...               ...   \n",
       "1786795   8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796   7.411239  0.408742  0.455056  3.137702          0.680556   \n",
       "1786797   8.380329  0.453475  0.383239  2.259961          0.839466   \n",
       "1786798  10.576296  0.430645  0.403139  2.485576          1.015675   \n",
       "1786799  11.521591  0.512244  0.614241  2.720541          1.047983   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  top_10  top_100  \\\n",
       "0                    129         0.000371               114     0.0      1.0   \n",
       "1                     52         0.000568               114     0.0      1.0   \n",
       "2                     39         0.000069               114     0.0      1.0   \n",
       "3                     67         0.000177               114     0.0      1.0   \n",
       "4                     29         0.000474               114     0.0      1.0   \n",
       "...                  ...              ...               ...     ...      ...   \n",
       "1786795               88         0.003954                37     0.0      0.0   \n",
       "1786796               27         0.000132                37     0.0      0.0   \n",
       "1786797               76         0.004296                37     0.0      0.0   \n",
       "1786798               81         0.000403                37     0.0      0.0   \n",
       "1786799               33         0.000083                37     0.0      0.0   \n",
       "\n",
       "         top_1000  user_similarity  \n",
       "0             7.0         0.000183  \n",
       "1             7.0         0.000183  \n",
       "2             7.0         0.000183  \n",
       "3             7.0         0.000183  \n",
       "4             7.0         0.000183  \n",
       "...           ...              ...  \n",
       "1786795       0.0         0.000272  \n",
       "1786796       0.0         0.000272  \n",
       "1786797       0.0         0.000272  \n",
       "1786798       0.0         0.000272  \n",
       "1786799       0.0         0.000272  \n",
       "\n",
       "[1786800 rows x 17 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = training_dataframe.sort_values(\"UserID\").reset_index(drop=True)\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1786800 entries, 0 to 1786799\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   UserID                 int64  \n",
      " 1   ItemID                 object \n",
      " 2   Recommender            object \n",
      " 3   Ranking                int64  \n",
      " 4   recommender_agreement  int64  \n",
      " 5   23                     float32\n",
      " 6   21                     float32\n",
      " 7   22                     float32\n",
      " 8   20                     float32\n",
      " 9   user_wide_hybrid       float32\n",
      " 10  item_popularity        int32  \n",
      " 11  item_similarity        float32\n",
      " 12  user_profile_len       int32  \n",
      " 13  top_10                 float64\n",
      " 14  top_100                float64\n",
      " 15  top_1000               float64\n",
      " 16  user_similarity        float32\n",
      "dtypes: float32(7), float64(3), int32(2), int64(3), object(2)\n",
      "memory usage: 170.4+ MB\n"
     ]
    }
   ],
   "source": [
    "training_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1786800 entries, 0 to 1786799\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   UserID                 int64  \n",
      " 1   ItemID                 object \n",
      " 2   Recommender            object \n",
      " 3   Ranking                int64  \n",
      " 4   recommender_agreement  int64  \n",
      " 5   23                     float32\n",
      " 6   21                     float32\n",
      " 7   22                     float32\n",
      " 8   20                     float32\n",
      " 9   user_wide_hybrid       float32\n",
      " 10  item_popularity        int32  \n",
      " 11  item_similarity        float32\n",
      " 12  user_profile_len       int32  \n",
      " 13  top_10                 float64\n",
      " 14  top_100                float64\n",
      " 15  top_1000               float64\n",
      " 16  user_similarity        float32\n",
      "dtypes: float32(7), float64(3), int32(2), int64(3), object(2)\n",
      "memory usage: 170.4+ MB\n"
     ]
    }
   ],
   "source": [
    "training_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1786800 entries, 0 to 1786799\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   UserID                 category\n",
      " 1   ItemID                 category\n",
      " 2   Recommender            category\n",
      " 3   Ranking                int64   \n",
      " 4   recommender_agreement  int64   \n",
      " 5   23                     float32 \n",
      " 6   21                     float32 \n",
      " 7   22                     float32 \n",
      " 8   20                     float32 \n",
      " 9   user_wide_hybrid       float32 \n",
      " 10  item_popularity        int32   \n",
      " 11  item_similarity        float32 \n",
      " 12  user_profile_len       int32   \n",
      " 13  top_10                 float64 \n",
      " 14  top_100                float64 \n",
      " 15  top_1000               float64 \n",
      " 16  user_similarity        float32 \n",
      "dtypes: category(3), float32(7), float64(3), int32(2), int64(2)\n",
      "memory usage: 144.0 MB\n"
     ]
    }
   ],
   "source": [
    "categorical_training_dataframe = training_dataframe\n",
    "for categorical_column in (\"UserID\", \"ItemID\", \"Recommender\"):\n",
    "    categorical_training_dataframe[categorical_column] = categorical_training_dataframe[categorical_column].astype(\"category\")\n",
    "categorical_training_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_training_dataframe.to_parquet(\"ranker_training_data_2_no_score.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranker pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_training_dataframe = pd.read_parquet(\"ranker_training_data_statistics.parquet\")\n",
    "categorical_training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = categorical_training_dataframe.pop(\"fold\")\n",
    "\n",
    "train_df = categorical_training_dataframe[fold != 9]\n",
    "y_train = train_df[\"Label\"]\n",
    "X_train = train_df.drop(columns=\"Label\")\n",
    "\n",
    "val_df = categorical_training_dataframe[fold == 9]\n",
    "y_val = val_df[\"Label\"]\n",
    "X_val = val_df.drop(columns=\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the ranker one first needs to specify the size of the groups, a group is the dimension you rank on, in this case each group corresponds to a user. Since we have generated a fixed number of candidates for each user, all groups have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35736,) (35736,)\n"
     ]
    }
   ],
   "source": [
    "train_groups = X_train.groupby(\"UserID\").size().to_numpy()\n",
    "val_groups = X_val.groupby(\"UserID\").size().to_numpy()\n",
    "\n",
    "print(train_groups.shape, val_groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.941629\n",
      "True     0.058371\n",
      "Name: Label, dtype: float64\n",
      "False    0.941629\n",
      "True     0.058371\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for y in (y_train, y_val):\n",
    "    print(pd.Series(y_train).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 19297440 entries, 0 to 2144159\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Dtype   \n",
      "---  ------                  -----   \n",
      " 0   UserID                  int64   \n",
      " 1   ItemID                  int64   \n",
      " 2   Recommender             category\n",
      " 3   Ranking                 int64   \n",
      " 4   recommender_agreement   int64   \n",
      " 5   score_20                float32 \n",
      " 6   score_21                float32 \n",
      " 7   score_22                float32 \n",
      " 8   score_23                float32 \n",
      " 9   score_user_wide_hybrid  float32 \n",
      " 10  score_score_hybrid      float32 \n",
      " 11  score_mean              float32 \n",
      " 12  score_std               float32 \n",
      " 13  score_min               float32 \n",
      " 14  score_max               float32 \n",
      " 15  score_kurtosis          float32 \n",
      " 16  score_skew              float64 \n",
      " 17  item_popularity         int32   \n",
      " 18  item_similarity         float32 \n",
      " 19  user_profile_len        int32   \n",
      " 20  top_10                  float64 \n",
      " 21  top_100                 float64 \n",
      " 22  top_1000                float64 \n",
      " 23  user_similarity         float32 \n",
      "dtypes: category(1), float32(13), float64(4), int32(2), int64(4)\n",
      "memory usage: 2.4 GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2144160 entries, 0 to 2144159\n",
      "Data columns (total 24 columns):\n",
      " #   Column                  Dtype   \n",
      "---  ------                  -----   \n",
      " 0   UserID                  int64   \n",
      " 1   ItemID                  int64   \n",
      " 2   Recommender             category\n",
      " 3   Ranking                 int64   \n",
      " 4   recommender_agreement   int64   \n",
      " 5   score_20                float32 \n",
      " 6   score_21                float32 \n",
      " 7   score_22                float32 \n",
      " 8   score_23                float32 \n",
      " 9   score_user_wide_hybrid  float32 \n",
      " 10  score_score_hybrid      float32 \n",
      " 11  score_mean              float32 \n",
      " 12  score_std               float32 \n",
      " 13  score_min               float32 \n",
      " 14  score_max               float32 \n",
      " 15  score_kurtosis          float32 \n",
      " 16  score_skew              float64 \n",
      " 17  item_popularity         int32   \n",
      " 18  item_similarity         float32 \n",
      " 19  user_profile_len        int32   \n",
      " 20  top_10                  float64 \n",
      " 21  top_100                 float64 \n",
      " 22  top_1000                float64 \n",
      " 23  user_similarity         float32 \n",
      "dtypes: category(1), float32(13), float64(4), int32(2), int64(4)\n",
      "memory usage: 272.0 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for X in (X_train, X_val):\n",
    "    print(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "BEST_XGB_RANKER = {\n",
    "    # Fixed parameters\n",
    "    \"enable_categorical\": True,\n",
    "    \"random_state\": 42,\n",
    "    \"objective\": \"rank:pairwise\",\n",
    "    \"eval_metric\": \"map@10\",\n",
    "    \"early_stopping_rounds\": 10,  # Early stopping patience\n",
    "    # Optimised parameters\n",
    "    \"learning_rate\": 0.021791864322986187,\n",
    "    \"n_estimators\": 79,\n",
    "    \"max_depth\": 10,\n",
    "    \"reg_alpha\": 0.06351745398607728,  # L1 regularisation\n",
    "    \"reg_lambda\": 0.7509535138381521,  # L2 regularisation\n",
    "    \"subsample\": 0.628614024512387,\n",
    "    \"colsample_bytree\": 0.6104118118708399,\n",
    "}\n",
    "\n",
    "XGB_model = XGBRanker(**BEST_XGB_RANKER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-map@10:0.56641\n",
      "[1]\tvalidation_0-map@10:0.58357\n",
      "[2]\tvalidation_0-map@10:0.59015\n",
      "[3]\tvalidation_0-map@10:0.59280\n",
      "[4]\tvalidation_0-map@10:0.59434\n",
      "[5]\tvalidation_0-map@10:0.59573\n",
      "[6]\tvalidation_0-map@10:0.59704\n",
      "[7]\tvalidation_0-map@10:0.59770\n",
      "[8]\tvalidation_0-map@10:0.59841\n",
      "[9]\tvalidation_0-map@10:0.59921\n",
      "[10]\tvalidation_0-map@10:0.59953\n",
      "[11]\tvalidation_0-map@10:0.60004\n",
      "[12]\tvalidation_0-map@10:0.60071\n",
      "[13]\tvalidation_0-map@10:0.60114\n",
      "[14]\tvalidation_0-map@10:0.60116\n",
      "[15]\tvalidation_0-map@10:0.60160\n",
      "[16]\tvalidation_0-map@10:0.60187\n",
      "[17]\tvalidation_0-map@10:0.60206\n",
      "[18]\tvalidation_0-map@10:0.60218\n",
      "[19]\tvalidation_0-map@10:0.60217\n",
      "[20]\tvalidation_0-map@10:0.60212\n",
      "[21]\tvalidation_0-map@10:0.60235\n",
      "[22]\tvalidation_0-map@10:0.60257\n",
      "[23]\tvalidation_0-map@10:0.60262\n",
      "[24]\tvalidation_0-map@10:0.60309\n",
      "[25]\tvalidation_0-map@10:0.60300\n",
      "[26]\tvalidation_0-map@10:0.60297\n",
      "[27]\tvalidation_0-map@10:0.60290\n",
      "[28]\tvalidation_0-map@10:0.60308\n",
      "[29]\tvalidation_0-map@10:0.60340\n",
      "[30]\tvalidation_0-map@10:0.60371\n",
      "[31]\tvalidation_0-map@10:0.60367\n",
      "[32]\tvalidation_0-map@10:0.60391\n",
      "[33]\tvalidation_0-map@10:0.60407\n",
      "[34]\tvalidation_0-map@10:0.60406\n",
      "[35]\tvalidation_0-map@10:0.60414\n",
      "[36]\tvalidation_0-map@10:0.60434\n",
      "[37]\tvalidation_0-map@10:0.60438\n",
      "[38]\tvalidation_0-map@10:0.60453\n",
      "[39]\tvalidation_0-map@10:0.60460\n",
      "[40]\tvalidation_0-map@10:0.60464\n",
      "[41]\tvalidation_0-map@10:0.60458\n",
      "[42]\tvalidation_0-map@10:0.60469\n",
      "[43]\tvalidation_0-map@10:0.60466\n",
      "[44]\tvalidation_0-map@10:0.60467\n",
      "[45]\tvalidation_0-map@10:0.60487\n",
      "[46]\tvalidation_0-map@10:0.60501\n",
      "[47]\tvalidation_0-map@10:0.60511\n",
      "[48]\tvalidation_0-map@10:0.60514\n",
      "[49]\tvalidation_0-map@10:0.60513\n",
      "[50]\tvalidation_0-map@10:0.60525\n",
      "[51]\tvalidation_0-map@10:0.60526\n",
      "[52]\tvalidation_0-map@10:0.60542\n",
      "[53]\tvalidation_0-map@10:0.60544\n",
      "[54]\tvalidation_0-map@10:0.60557\n",
      "[55]\tvalidation_0-map@10:0.60574\n",
      "[56]\tvalidation_0-map@10:0.60585\n",
      "[57]\tvalidation_0-map@10:0.60600\n",
      "[58]\tvalidation_0-map@10:0.60604\n",
      "[59]\tvalidation_0-map@10:0.60610\n",
      "[60]\tvalidation_0-map@10:0.60615\n",
      "[61]\tvalidation_0-map@10:0.60621\n",
      "[62]\tvalidation_0-map@10:0.60645\n",
      "[63]\tvalidation_0-map@10:0.60642\n",
      "[64]\tvalidation_0-map@10:0.60641\n",
      "[65]\tvalidation_0-map@10:0.60657\n",
      "[66]\tvalidation_0-map@10:0.60668\n",
      "[67]\tvalidation_0-map@10:0.60657\n",
      "[68]\tvalidation_0-map@10:0.60667\n",
      "[69]\tvalidation_0-map@10:0.60664\n",
      "[70]\tvalidation_0-map@10:0.60673\n",
      "[71]\tvalidation_0-map@10:0.60664\n",
      "[72]\tvalidation_0-map@10:0.60679\n",
      "[73]\tvalidation_0-map@10:0.60667\n",
      "[74]\tvalidation_0-map@10:0.60661\n",
      "[75]\tvalidation_0-map@10:0.60668\n",
      "[76]\tvalidation_0-map@10:0.60670\n",
      "[77]\tvalidation_0-map@10:0.60675\n",
      "[78]\tvalidation_0-map@10:0.60689\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=0.6104118118708399,\n",
       "          device=None, early_stopping_rounds=10, enable_categorical=True,\n",
       "          eval_metric=&#x27;map@10&#x27;, feature_types=None, gamma=None,\n",
       "          grow_policy=None, importance_type=None, interaction_constraints=None,\n",
       "          learning_rate=0.021791864322986187, max_bin=None,\n",
       "          max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=None,\n",
       "          max_depth=10, max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=79,\n",
       "          n_jobs=None, num_parallel_tree=None, objective=&#x27;rank:pairwise&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRanker<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=0.6104118118708399,\n",
       "          device=None, early_stopping_rounds=10, enable_categorical=True,\n",
       "          eval_metric=&#x27;map@10&#x27;, feature_types=None, gamma=None,\n",
       "          grow_policy=None, importance_type=None, interaction_constraints=None,\n",
       "          learning_rate=0.021791864322986187, max_bin=None,\n",
       "          max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=None,\n",
       "          max_depth=10, max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=79,\n",
       "          n_jobs=None, num_parallel_tree=None, objective=&#x27;rank:pairwise&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=0.6104118118708399,\n",
       "          device=None, early_stopping_rounds=10, enable_categorical=True,\n",
       "          eval_metric='map@10', feature_types=None, gamma=None,\n",
       "          grow_policy=None, importance_type=None, interaction_constraints=None,\n",
       "          learning_rate=0.021791864322986187, max_bin=None,\n",
       "          max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=None,\n",
       "          max_depth=10, max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=79,\n",
       "          n_jobs=None, num_parallel_tree=None, objective='rank:pairwise', ...)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.fit(\n",
    "    X_train,  # .drop(columns=[\"UserID\", \"ItemID\"]),\n",
    "    y_train,\n",
    "    group=train_groups,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_group=[val_groups],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.score(\n",
    "    X_train,  # .drop(columns=[\"UserID\", \"ItemID\"]),\n",
    "    y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.score(\n",
    "    X_val,  # .drop(columns=[\"UserID\", \"ItemID\"]),\n",
    "    y_val,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained we can use it to compute predictions. Each prediction will refer to a specific user-item pair, which we will then need to rank as we do in any other recommender model.\n",
    "\n",
    "**Important:** In order to use this model to predict the score of new datapoints (i.e., new recommendations) we have to repeat the same data processing steps but:\n",
    "- We do not need a train-label split, we can user all the data we have to compute the predictions and the features\n",
    "- The recommendation models used to generate the scores should be trained on all the available data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look to the feature importance to assess which are the most informative ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Weight (Frequence)'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plot_importance(XGB_model, importance_type=\"weight\", title=\"Weight (Frequence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18456"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_items_dict = decode_targets(X_val, y_val)\n",
    "len(val_items_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35736"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions_dict = decode_predictions(X_val, XGB_model)\n",
    "len(val_predictions_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute recommendation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08769395100307618"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_at_k(val_predictions_dict, val_items_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to perform hyperparameter tuning?\n",
    "\n",
    "The issue with this method is that you need a label which should be an item the user has not interacted with but that is a correct recommendation. In practice the idea is:\n",
    "- Split the data in the usual training-validation-test\n",
    "- Split the training data in two: one part you use to train the recommenders and another you use as the hidden Label to train XGBoost\n",
    "- Evaluate your predictions on the validation data as you did for any other recommender model. Use this to select the optimal hyperparameters.\n",
    "- Given the selected hyperparameters, train the recommender models on all the available data and use all the available data to compute the features used by XGBoost.\n",
    "\n",
    "Challenge: Since the label we use for training XGBoost is the split of a split, it may happen that the actual correct recommendations are very few. This will result in a problem that is very unbalanced towards zero and will make the training difficult and the evaluation noisy. To mitigate this you may use k-fold cross validation and define the valdation result of a certain hyperparameter configuration as the average obtained with k different training-label splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-04 08:49:22,458] A new study created in memory with name: no-name-177fe6c7-69a3-4cb4-bd33-f6d51fd12855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-01-04 08:52:32,263] Trial 0 finished with value: 0.331555167099186 and parameters: {'learning_rate': 0.173343543694998, 'n_estimators': 470, 'max_depth': 3, 'l1_regularisation': 0.9261233493910119, 'l2_regularisation': 0.4494340618101842, 'subsample': 0.5366066089996964, 'colsample_bytree': 0.786856252879855}. Best is trial 0 with value: 0.331555167099186.\n",
      "[I 2025-01-04 08:55:45,651] Trial 1 finished with value: 0.3285352756367114 and parameters: {'learning_rate': 0.12318439195285222, 'n_estimators': 294, 'max_depth': 3, 'l1_regularisation': 0.4833461157621478, 'l2_regularisation': 0.9166027196530923, 'subsample': 0.7361149844407555, 'colsample_bytree': 0.5043189681676663}. Best is trial 0 with value: 0.331555167099186.\n",
      "[W 2025-01-04 08:56:24,131] Trial 2 failed with parameters: {'learning_rate': 0.2702747729255557, 'n_estimators': 216, 'max_depth': 3, 'l1_regularisation': 0.7025221264262611, 'l2_regularisation': 0.5457656027369642, 'subsample': 0.6032274572862046, 'colsample_bytree': 0.854724283073278} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/tmp/ipykernel_51364/4231632981.py\", line 41, in objective\n",
      "    model.fit(\n",
      "  File \"/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/sklearn.py\", line 2021, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/core.py\", line 726, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"/home/tomaz/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/core.py\", line 2101, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-01-04 08:56:24,132] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 59\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Run the optimization\u001b[39;00m\n\u001b[1;32m     58\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 59\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[1;32m     62\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    480\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    481\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    482\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    483\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    484\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[20], line 41\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     38\u001b[0m groups_train_fold \u001b[38;5;241m=\u001b[39m X_train_fold\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUserID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     39\u001b[0m groups_val_fold \u001b[38;5;241m=\u001b[39m X_val_fold\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUserID\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[0;32m---> 41\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroups_train_fold\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val_fold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val_fold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_group\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mgroups_val_fold\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m decode_predictions(X_val_fold, model)\n\u001b[1;32m     50\u001b[0m relevant_items \u001b[38;5;241m=\u001b[39m decode_targets(X_val_fold, y_val_fold)\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/sklearn.py:2021\u001b[0m, in \u001b[0;36mXGBRanker.fit\u001b[0;34m(self, X, y, group, qid, sample_weight, base_margin, eval_set, eval_group, eval_qid, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   2017\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   2019\u001b[0m model, metric, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_configure_fit(xgb_model, params)\n\u001b[0;32m-> 2021\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2023\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2027\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2032\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2034\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective \u001b[38;5;241m=\u001b[39m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjective\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   2036\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/git/Politecnico/Subjects/recommender-systems/recsys-competition/.venv/lib/python3.10/site-packages/xgboost/core.py:2101\u001b[0m, in \u001b[0;36mBooster.update\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[1;32m   2099\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2100\u001b[0m     _check_call(\n\u001b[0;32m-> 2101\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2102\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[1;32m   2103\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2104\u001b[0m     )\n\u001b[1;32m   2105\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2106\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "def objective(trial: optuna.Trial) -> float:\n",
    "    # Define the hyperparameter search space\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.0, 0.3)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 10, 500)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 2, 10)\n",
    "    l1_regularisation = trial.suggest_float(\"l1_regularisation\", 0.0, 1.0)\n",
    "    l2_regularisation = trial.suggest_float(\"l2_regularisation\", 0.0, 1.0)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "\n",
    "    # Initialize the XGBoost model\n",
    "    model = XGBRanker(\n",
    "        enable_categorical=True,\n",
    "        random_state=42,\n",
    "        objective=\"rank:pairwise\",\n",
    "        eval_metric=\"map@10\",\n",
    "        early_stopping_rounds=10,  # Early stopping patience\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        reg_alpha=l1_regularisation,\n",
    "        reg_lambda=l2_regularisation,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "    )\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    kf = StratifiedKFold(n_splits=5)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train, y_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        groups_train_fold = X_train_fold.groupby(\"UserID\").size().to_numpy()\n",
    "        groups_val_fold = X_val_fold.groupby(\"UserID\").size().to_numpy()\n",
    "\n",
    "        model.fit(\n",
    "            X_train_fold,\n",
    "            y_train_fold,\n",
    "            group=groups_train_fold,\n",
    "            eval_set=[(X_val_fold, y_val_fold)],\n",
    "            eval_group=[groups_val_fold],\n",
    "            verbose=False,\n",
    "        )\n",
    "        recommendations = decode_predictions(X_val_fold, model)\n",
    "        relevant_items = decode_targets(X_val_fold, y_val_fold)\n",
    "        score = map_at_k(recommendations, relevant_items, k=10)\n",
    "        scores.append(score)\n",
    "\n",
    "    return np.mean(scores)\n",
    "\n",
    "\n",
    "# Run the optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>score_score_hybrid</th>\n",
       "      <th>score_23</th>\n",
       "      <th>score_21</th>\n",
       "      <th>score_22</th>\n",
       "      <th>score_20</th>\n",
       "      <th>...</th>\n",
       "      <th>score_max</th>\n",
       "      <th>score_kurtosis</th>\n",
       "      <th>score_skew</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>score_hybrid</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.242614</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>...</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.338719</td>\n",
       "      <td>1.397987</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>score_hybrid</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.216598</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>...</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.561295</td>\n",
       "      <td>1.492638</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>531</td>\n",
       "      <td>score_hybrid</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.206871</td>\n",
       "      <td>0.992778</td>\n",
       "      <td>0.126797</td>\n",
       "      <td>0.307062</td>\n",
       "      <td>1.100397</td>\n",
       "      <td>...</td>\n",
       "      <td>1.100397</td>\n",
       "      <td>-1.456910</td>\n",
       "      <td>0.646918</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>4462</td>\n",
       "      <td>score_hybrid</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.204848</td>\n",
       "      <td>0.874752</td>\n",
       "      <td>0.136127</td>\n",
       "      <td>0.147709</td>\n",
       "      <td>1.172352</td>\n",
       "      <td>...</td>\n",
       "      <td>1.172352</td>\n",
       "      <td>-1.151668</td>\n",
       "      <td>0.806368</td>\n",
       "      <td>22</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>score_hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.200145</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>...</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.922805</td>\n",
       "      <td>1.650838</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144155</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.238147</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>...</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.832299</td>\n",
       "      <td>1.609831</td>\n",
       "      <td>88</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144156</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0.216601</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>...</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>1.020922</td>\n",
       "      <td>1.696938</td>\n",
       "      <td>70</td>\n",
       "      <td>0.004040</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144157</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.248681</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>...</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.903925</td>\n",
       "      <td>1.642833</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003903</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144158</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.222564</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>...</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>-0.268022</td>\n",
       "      <td>1.149794</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2144159</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.216220</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>...</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.135193</td>\n",
       "      <td>1.309474</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2144160 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID  ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    9911      score_hybrid        0                      3   \n",
       "1             0   14888      score_hybrid        1                      5   \n",
       "2             0     531      score_hybrid        2                      2   \n",
       "3             0    4462      score_hybrid        3                      2   \n",
       "4             0     572      score_hybrid        4                      5   \n",
       "...         ...     ...               ...      ...                    ...   \n",
       "2144155   35735   36775  user_wide_hybrid        5                      4   \n",
       "2144156   35735   37660  user_wide_hybrid        6                      3   \n",
       "2144157   35735   36920  user_wide_hybrid        7                      4   \n",
       "2144158   35735   37017  user_wide_hybrid        8                      2   \n",
       "2144159   35735   35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "         score_score_hybrid  score_23  score_21  score_22  score_20  ...  \\\n",
       "0                  0.242614  2.940626  0.226980  0.315740  1.171455  ...   \n",
       "1                  0.216598  3.389925  0.282408  0.327246  1.195710  ...   \n",
       "2                  0.206871  0.992778  0.126797  0.307062  1.100397  ...   \n",
       "3                  0.204848  0.874752  0.136127  0.147709  1.172352  ...   \n",
       "4                  0.200145  3.708066  0.364245  0.184505  0.906074  ...   \n",
       "...                     ...       ...       ...       ...       ...  ...   \n",
       "2144155            0.238147  8.471791  0.328802  0.358924  2.157352  ...   \n",
       "2144156            0.216601  7.323517  0.347563  0.192113  1.368214  ...   \n",
       "2144157            0.248681  7.601600  0.342447  0.263019  1.772518  ...   \n",
       "2144158            0.222564  4.652850  0.303232  0.303558  2.394336  ...   \n",
       "2144159            0.216220  5.464930  0.300776  0.086924  2.287900  ...   \n",
       "\n",
       "         score_max  score_kurtosis  score_skew  item_popularity  \\\n",
       "0         2.940626        0.338719    1.397987               27   \n",
       "1         3.389925        0.561295    1.492638              110   \n",
       "2         1.100397       -1.456910    0.646918               36   \n",
       "3         1.172352       -1.151668    0.806368               22   \n",
       "4         3.708066        0.922805    1.650838               93   \n",
       "...            ...             ...         ...              ...   \n",
       "2144155   8.471791        0.832299    1.609831               88   \n",
       "2144156   7.323517        1.020922    1.696938               70   \n",
       "2144157   7.601600        0.903925    1.642833              147   \n",
       "2144158   4.652850       -0.268022    1.149794               58   \n",
       "2144159   5.464930        0.135193    1.309474               28   \n",
       "\n",
       "         item_similarity  user_profile_len  top_10  top_100  top_1000  \\\n",
       "0               0.000040               114     0.0      1.0       7.0   \n",
       "1               0.000250               114     0.0      1.0       7.0   \n",
       "2               0.000225               114     0.0      1.0       7.0   \n",
       "3               0.000303               114     0.0      1.0       7.0   \n",
       "4               0.000246               114     0.0      1.0       7.0   \n",
       "...                  ...               ...     ...      ...       ...   \n",
       "2144155         0.004034                37     0.0      0.0       0.0   \n",
       "2144156         0.004040                37     0.0      0.0       0.0   \n",
       "2144157         0.003903                37     0.0      0.0       0.0   \n",
       "2144158         0.003937                37     0.0      0.0       0.0   \n",
       "2144159         0.000684                37     0.0      0.0       0.0   \n",
       "\n",
       "         user_similarity  \n",
       "0               0.000183  \n",
       "1               0.000183  \n",
       "2               0.000183  \n",
       "3               0.000183  \n",
       "4               0.000183  \n",
       "...                  ...  \n",
       "2144155         0.000272  \n",
       "2144156         0.000272  \n",
       "2144157         0.000272  \n",
       "2144158         0.000272  \n",
       "2144159         0.000272  \n",
       "\n",
       "[2144160 rows x 24 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_dataframe = pd.read_parquet(\"ranker_submission_data_statistics.parquet\")\n",
    "submission_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{35735: [36034, 36493, 37445, 36773, 37657, 37660, 36917, 36920, 36775, 37017],\n",
       " 35734: [37069, 36168, 36610, 35345, 37067, 37550, 36094, 35093, 37803, 37071],\n",
       " 35733: [37853, 37388, 37372, 38072, 37540, 36056, 28304, 37858, 28418, 37958],\n",
       " 35732: [37317, 27644, 38005, 35437, 27590, 37706, 35079, 31350, 34171, 37671],\n",
       " 35731: [37739, 36263, 35394, 36173, 38027, 37427, 36525, 38049, 28461, 37618],\n",
       " 35730: [28247, 38027, 37874, 37719, 37739, 33330, 27350, 37118, 37098, 36770],\n",
       " 35729: [36844, 35548, 26093, 36527, 27531, 37461, 26794, 36566, 38077, 36802],\n",
       " 35728: [35370, 36665, 35777, 37565, 14090, 28374, 19651, 27510, 27497, 36940],\n",
       " 35727: [37280, 37291, 27520, 37712, 37416, 28088, 28203, 28097, 14664, 37866],\n",
       " 35726: [37851, 27768, 37527, 37940, 37740, 28447, 28234, 37653, 38045, 37538],\n",
       " 35725: [37540, 37431, 28458, 37785, 37924, 36652, 38018, 37661, 38028, 37308],\n",
       " 35724: [28281, 36504, 27346, 37940, 37178, 26869, 36866, 27689, 38077, 36566],\n",
       " 35723: [28247, 28461, 36567, 36065, 37739, 35120, 27161, 35995, 28424, 37211],\n",
       " 35722: [37731, 27593, 37902, 37939, 27364, 35269, 35754, 37690, 20545, 37514],\n",
       " 35721: [37120, 37983, 20107, 37785, 37372, 37958, 37579, 36027, 38018, 37950],\n",
       " 35720: [33877, 28165, 35531, 36676, 35162, 37120, 14660, 33081, 37958, 38028],\n",
       " 35719: [26188, 27505, 26609, 37498, 26225, 35904, 36929, 28306, 27772, 27331],\n",
       " 35718: [34482, 27828, 26917, 28164, 37158, 35566, 37225, 36708, 36038, 37182],\n",
       " 35717: [35951, 35584, 28547, 31577, 27623, 35876, 37222, 37177, 37932, 36433],\n",
       " 35716: [28419, 27751, 28469, 26795, 27328, 35219, 27134, 34174, 32015, 27807],\n",
       " 35715: [37910, 38112, 28133, 28241, 27638, 26351, 37105, 36790, 26105, 37310],\n",
       " 35714: [27807, 27720, 37433, 35561, 26330, 35374, 26424, 26922, 35252, 28334],\n",
       " 35713: [31336, 27815, 27045, 19675, 33919, 34558, 32257, 32226, 27046, 25750],\n",
       " 35712: [32572, 36806, 36579, 38115, 36974, 26357, 27338, 24704, 26429, 25136],\n",
       " 35711: [35016, 30374, 35218, 34421, 36467, 14673, 14462, 33126, 33847, 35240],\n",
       " 35710: [34426, 36902, 26848, 34119, 28012, 28162, 36826, 35017, 33212, 36595],\n",
       " 35709: [34426, 28162, 33617, 26475, 37985, 35945, 37637, 36826, 35017, 30908],\n",
       " 35708: [26794, 27106, 27067, 36083, 28020, 27655, 28292, 28025, 35548, 28316],\n",
       " 35707: [2474, 36743, 37604, 34983, 34985, 27675, 26851, 25591, 26609, 26263],\n",
       " 35706: [37160, 34254, 33570, 37870, 37884, 11040, 26773, 26243, 11041, 35612],\n",
       " 35705: [36844, 36439, 26794, 25417, 25436, 26302, 37510, 28364, 37287, 37178],\n",
       " 35704: [28273, 25415, 27784, 28513, 37880, 27580, 36001, 27709, 28555, 28265],\n",
       " 35703: [27580, 31020, 28306, 27671, 25416, 27190, 25639, 20576, 20574, 27047],\n",
       " 35702: [28262, 27720, 37913, 37527, 38107, 38066, 35539, 26922, 37337, 25414],\n",
       " 35701: [28470, 37731, 27852, 28521, 37607, 28094, 27513, 31947, 27205, 36256],\n",
       " 35700: [27859, 36438, 31045, 26682, 33394, 25418, 32063, 28001, 35254, 26206],\n",
       " 35699: [27205, 33928, 36397, 27485, 37105, 27357, 28177, 27733, 27720, 33814],\n",
       " 35698: [36676, 35438, 36755, 36249, 35650, 36940, 35187, 35876, 26356, 36959],\n",
       " 35697: [35654, 35218, 35016, 34421, 26242, 14673, 33126, 33739, 33569, 33483],\n",
       " 35696: [37382, 27011, 25784, 28025, 37733, 30282, 31038, 24915, 25661, 7964],\n",
       " 35695: [33214, 34833, 27650, 25795, 33708, 34848, 28392, 34004, 28373, 26751],\n",
       " 35694: [38027, 37874, 27426, 35995, 37211, 36065, 37719, 28119, 37706, 36770],\n",
       " 35693: [34201, 34200, 35838, 24936, 25249, 34967, 36475, 34644, 24935, 26084],\n",
       " 35692: [35932, 36991, 28519, 36297, 33825, 26356, 34425, 14643, 34686, 37717],\n",
       " 35691: [20399, 27972, 27135, 25046, 37001, 26972, 26471, 35799, 27423, 28100],\n",
       " 35690: [36635, 34645, 36701, 36548, 36055, 26646, 26429, 36579, 36825, 38005],\n",
       " 35689: [14343, 37925, 24912, 37541, 26364, 24755, 27607, 28361, 27862, 26164],\n",
       " 35688: [37565, 27759, 36144, 36645, 36008, 28432, 36665, 26390, 26932, 28304],\n",
       " 35687: [28466, 28479, 28438, 28323, 35428, 31874, 31875, 27537, 37317, 37337],\n",
       " 35686: [37712, 28413, 27165, 37864, 25077, 37513, 23712, 37561, 37386, 28129],\n",
       " 35685: [26797, 34425, 24878, 34873, 34362, 35404, 28331, 36298, 35169, 34732],\n",
       " 35684: [24878, 26430, 26397, 34425, 35988, 26107, 36980, 26797, 33825, 27008],\n",
       " 35683: [36665, 24629, 36544, 25918, 35370, 36755, 35989, 26906, 33785, 36505],\n",
       " 35682: [28104, 25968, 27348, 37816, 25863, 27290, 20175, 36305, 32666, 20176],\n",
       " 35681: [36355, 20397, 37711, 37108, 36069, 37578, 14681, 36468, 36397, 36637],\n",
       " 35680: [36296, 32380, 31877, 36993, 31875, 31876, 37101, 20397, 37329, 37223],\n",
       " 35679: [28441, 26113, 28442, 28088, 38045, 37997, 38109, 37202, 37790, 37589],\n",
       " 35678: [26217, 25486, 34543, 28229, 26553, 26394, 26453, 26170, 26751, 37541],\n",
       " 35677: [27689, 24186, 28561, 32146, 36866, 27106, 37510, 35548, 33876, 37287],\n",
       " 35676: [34694, 25295, 25570, 26868, 26217, 34684, 32314, 27796, 34543, 31385],\n",
       " 35675: [30927, 37840, 26225, 28416, 33965, 35647, 26827, 28306, 34212, 27030],\n",
       " 35674: [25179, 36536, 34211, 26971, 25500, 27008, 25210, 35077, 36456, 25119],\n",
       " 35673: [24500, 36249, 37268, 27739, 36544, 34211, 37343, 35041, 34892, 25496],\n",
       " 35672: [32718, 24888, 20498, 25440, 24192, 26882, 25854, 8095, 7964, 33263],\n",
       " 35671: [26827, 25435, 26875, 27443, 25234, 20305, 26700, 26471, 25419, 26972],\n",
       " 35670: [23846, 36439, 23841, 33514, 25419, 25418, 25411, 25426, 25434, 23712],\n",
       " 35669: [37984, 30169, 34167, 27783, 37913, 27626, 27067, 28008, 27784, 30300],\n",
       " 35668: [25286, 33791, 25465, 25466, 25301, 33850, 26652, 26206, 24942, 33766],\n",
       " 35667: [28519, 34795, 36144, 35370, 36536, 36061, 37837, 36893, 34290, 36357],\n",
       " 35666: [34543, 35414, 37186, 24773, 27128, 37319, 28501, 34790, 30954, 30951],\n",
       " 35665: [34135, 27032, 35875, 35687, 25246, 35400, 28298, 27741, 25243, 24553],\n",
       " 35664: [34118, 33734, 32843, 24771, 36002, 36344, 34340, 35671, 32890, 34471],\n",
       " 35663: [25565, 30914, 33220, 33159, 30916, 31325, 26513, 22819, 30918, 24717],\n",
       " 35662: [34206, 26809, 27575, 36083, 27655, 27579, 37940, 36738, 27345, 36174],\n",
       " 35661: [25055, 24538, 37379, 34790, 24384, 24958, 36595, 28019, 27424, 24408],\n",
       " 35660: [26875, 26513, 26298, 31811, 25352, 26113, 31813, 22170, 24912, 27118],\n",
       " 35659: [22208, 22217, 22190, 22067, 22188, 22200, 22109, 22249, 22237, 22107],\n",
       " 35658: [37041, 31021, 27225, 25436, 26330, 26424, 26712, 28389, 27067, 34845],\n",
       " 35657: [37108, 35784, 38042, 34127, 28219, 27110, 35847, 33824, 28239, 27475],\n",
       " 35656: [27575, 31846, 31849, 34602, 25392, 27577, 28551, 24774, 28131, 25590],\n",
       " 35655: [27502, 25106, 27105, 35629, 20084, 33908, 34802, 34770, 28315, 20595],\n",
       " 35654: [31999, 34324, 31998, 32063, 28110, 31997, 34186, 32545, 34728, 25136],\n",
       " 35653: [25486, 26868, 25208, 25565, 27800, 25246, 25243, 27426, 34135, 32557],\n",
       " 35652: [28065, 28226, 26254, 36453, 27231, 37341, 21095, 22783, 37640, 28137],\n",
       " 35651: [35012, 14652, 34212, 34415, 37994, 36635, 20488, 28251, 26214, 20487],\n",
       " 35650: [27844, 37592, 25426, 28200, 37546, 28226, 37791, 36876, 28415, 25699],\n",
       " 35649: [30828, 30827, 26501, 30955, 23847, 27509, 24388, 35326, 36449, 36039],\n",
       " 35648: [27318, 37985, 23845, 30893, 36468, 35012, 28050, 36612, 27580, 35444],\n",
       " 35647: [27611, 31020, 37432, 36223, 25426, 36612, 28252, 20397, 37872, 14579],\n",
       " 35646: [35897, 26134, 35530, 34849, 26639, 26680, 25572, 28285, 34176, 25571],\n",
       " 35645: [36906, 34747, 14620, 37535, 36355, 28357, 28470, 26886, 28442, 37527],\n",
       " 35644: [27578, 37622, 37883, 20488, 37436, 30855, 20487, 37667, 35304, 37960],\n",
       " 35643: [36806, 37515, 28192, 37712, 37527, 36974, 38118, 28353, 37970, 28097],\n",
       " 35642: [37913, 24182, 28466, 37108, 28323, 28490, 38069, 37775, 36877, 28154],\n",
       " 35641: [36157, 28100, 33965, 28213, 27732, 35647, 27917, 28203, 34674, 27231],\n",
       " 35640: [28053, 20766, 37341, 38006, 27208, 28245, 28295, 31877, 31876, 14621],\n",
       " 35639: [26038, 32624, 32368, 33245, 33706, 33277, 26773, 25570, 12335, 25051],\n",
       " 35638: [36806, 37168, 31885, 28100, 37871, 37416, 37291, 31887, 20748, 34166],\n",
       " 35637: [28101, 28353, 25224, 28212, 27289, 25716, 34658, 27288, 28395, 38033],\n",
       " 35636: [37653, 38016, 37689, 28441, 31037, 31036, 37242, 37486, 38109, 36502],\n",
       " 35635: [34841, 37800, 28354, 28464, 37515, 27989, 28226, 20576, 32071, 36093],\n",
       " 35634: [20739, 27111, 38117, 27709, 31181, 33698, 31180, 28100, 34481, 27172],\n",
       " 35633: [26131, 37132, 14654, 37416, 20766, 37919, 37291, 36832, 34539, 37026],\n",
       " 35632: [26785, 28100, 36468, 27190, 27732, 27745, 27520, 37930, 25420, 28097],\n",
       " 35631: [37984, 27675, 37148, 37009, 28029, 37716, 20488, 28354, 38092, 36995],\n",
       " 35630: [37622, 27709, 37713, 28129, 20718, 37424, 28208, 35793, 28020, 37807],\n",
       " 35629: [37280, 27917, 27732, 28353, 38100, 28100, 34997, 28464, 28020, 36448],\n",
       " 35628: [32916, 27091, 20488, 20487, 26141, 27989, 25085, 34129, 26199, 28486],\n",
       " 35627: [38092, 37768, 37721, 30961, 37667, 30963, 20488, 35611, 32081, 20487],\n",
       " 35626: [37209, 38007, 32104, 35845, 32114, 32000, 37769, 26730, 37014, 32453],\n",
       " 35625: [28252, 19938, 28097, 38115, 36999, 25415, 19939, 14709, 37930, 37291],\n",
       " 35624: [27423, 31975, 28100, 37667, 37741, 26770, 28353, 37310, 20488, 26922],\n",
       " 35623: [24455, 26647, 24382, 34963, 25039, 36005, 37187, 25243, 36489, 25246],\n",
       " 35622: [35591, 27696, 20740, 27963, 26851, 36622, 37400, 28328, 28517, 31854],\n",
       " 35621: [14621, 28158, 28550, 27092, 37774, 27891, 35012, 28128, 38057, 37148],\n",
       " 35620: [37930, 31584, 37497, 38116, 31583, 27583, 31582, 28448, 31580, 20740],\n",
       " 35619: [37491, 20740, 38022, 37341, 28318, 37319, 30954, 37065, 37550, 36129],\n",
       " 35618: [27193, 28306, 37101, 32055, 37329, 28097, 28397, 27917, 36308, 36038],\n",
       " 35617: [37893, 26780, 35521, 37241, 35520, 27841, 37317, 14655, 36463, 28323],\n",
       " 35616: [36361, 28359, 37257, 37712, 14709, 35253, 20677, 27768, 28025, 37871],\n",
       " 35615: [36877, 31583, 31581, 32069, 37101, 31585, 14612, 20305, 19980, 20728],\n",
       " 35614: [35900, 23893, 35468, 36645, 35584, 26016, 37222, 34783, 36231, 36052],\n",
       " 35613: [37527, 35708, 37713, 26937, 36569, 14654, 38066, 27208, 34613, 20575],\n",
       " 35612: [36427, 31876, 26909, 28197, 28353, 27047, 27443, 28337, 25435, 28100],\n",
       " 35611: [37574, 37362, 27376, 36541, 27289, 14657, 31037, 28063, 27805, 28357],\n",
       " 35610: [37813, 35160, 32050, 27298, 26302, 38045, 37902, 28555, 28551, 27170],\n",
       " 35609: [20634, 20635, 37864, 25699, 30503, 28562, 37793, 28442, 37865, 28441],\n",
       " 35608: [27769, 27236, 37774, 31765, 27278, 27374, 28548, 27242, 37053, 37526],\n",
       " 35607: [28353, 14621, 36047, 27812, 28205, 38030, 28549, 27145, 27805, 27543],\n",
       " 35606: [28349, 20632, 28476, 27935, 27607, 27963, 27709, 27304, 36107, 28353],\n",
       " 35605: [25518, 27122, 31967, 26885, 27596, 27105, 25606, 31847, 34819, 34968],\n",
       " 35604: [26727, 37886, 35556, 38117, 36488, 35308, 36006, 27891, 36784, 35846],\n",
       " 35603: [27092, 27923, 27784, 27221, 36108, 28194, 35521, 20633, 15330, 36937],\n",
       " 35602: [20635, 28246, 24179, 36260, 37526, 28008, 25363, 27390, 20122, 25362],\n",
       " 35601: [28065, 20696, 35664, 27154, 36570, 27647, 36397, 27992, 37105, 35495],\n",
       " 35600: [29856, 36825, 31963, 28110, 25566, 31721, 31720, 31608, 31723, 26747],\n",
       " 35599: [37108, 26298, 25039, 36658, 27601, 32520, 27424, 32844, 37996, 36958],\n",
       " 35598: [28405, 37515, 20575, 38039, 20574, 31584, 31033, 28479, 31034, 28114],\n",
       " 35597: [36876, 37998, 37041, 37895, 37880, 14640, 20574, 20575, 38094, 27709],\n",
       " 35596: [31975, 28504, 37223, 28100, 37329, 38102, 19986, 37741, 37428, 20575],\n",
       " 35595: [27190, 28265, 28353, 20575, 20305, 36504, 36738, 37930, 27917, 25594],\n",
       " 35594: [36397, 28474, 36004, 28065, 37920, 27295, 36570, 28395, 31980, 37672],\n",
       " 35593: [37689, 27706, 37515, 27959, 36950, 36832, 37310, 37527, 37948, 38106],\n",
       " 35592: [27831, 28456, 20633, 28100, 27616, 20575, 20632, 28540, 27423, 28137],\n",
       " 35591: [27677, 27709, 21728, 27784, 27690, 28353, 20575, 25423, 21729, 36636],\n",
       " 35590: [36570, 27791, 27579, 28065, 26254, 36069, 31020, 27696, 36397, 20575],\n",
       " 35589: [36110, 20574, 37515, 37836, 28226, 34902, 37910, 25369, 14654, 20724],\n",
       " 35588: [14654, 27289, 20724, 28131, 25343, 25416, 25560, 25590, 35607, 28080],\n",
       " 35587: [28474, 36123, 37895, 37864, 27978, 28472, 28521, 27955, 28063, 28373],\n",
       " 35586: [28466, 28490, 28438, 20575, 36694, 28472, 37984, 38107, 31020, 35491],\n",
       " 35585: [20576, 37925, 25591, 37331, 27917, 20767, 28537, 37947, 25435, 28131],\n",
       " 35584: [20634, 26818, 31961, 31962, 36745, 31719, 35715, 31720, 31963, 31722],\n",
       " 35583: [37913, 37290, 25416, 37592, 38107, 27812, 28097, 37420, 27878, 37574],\n",
       " 35582: [27706, 27356, 28252, 24415, 27090, 29593, 28562, 26298, 35088, 25431],\n",
       " 35581: [14664, 37424, 20574, 37417, 28363, 36957, 11134, 27785, 36751, 28096],\n",
       " 35580: [35524, 35626, 20575, 26533, 34696, 25795, 34684, 37317, 34695, 26309],\n",
       " 35579: [27693, 20576, 28100, 14645, 27447, 37467, 28275, 26619, 27318, 14621],\n",
       " 35578: [20576, 14568, 37745, 36227, 35765, 35315, 36474, 34909, 12829, 28226],\n",
       " 35577: [36364, 20564, 26217, 20565, 27979, 26208, 25486, 36805, 33467, 24178],\n",
       " 35576: [35207, 24896, 19675, 33983, 31336, 33249, 25750, 23846, 32710, 34658],\n",
       " 35575: [20574, 20576, 37737, 27262, 28104, 20555, 27709, 37775, 28353, 27745],\n",
       " 35574: [28470, 31026, 20644, 35254, 35521, 36439, 25418, 25434, 31033, 27495],\n",
       " 35573: [26928, 27135, 26298, 27744, 31810, 35939, 27785, 27655, 27979, 20566],\n",
       " 35572: [28262, 28479, 26761, 28490, 28466, 28507, 28527, 20676, 26767, 28316],\n",
       " 35571: [26368, 37579, 27957, 37099, 28331, 35169, 32670, 26749, 26427, 35429],\n",
       " 35570: [27926, 28008, 28323, 28368, 31732, 37423, 28474, 20535, 37535, 37026],\n",
       " 35569: [36982, 35217, 35847, 27423, 37039, 26959, 37985, 28100, 26269, 21095],\n",
       " 35568: [27785, 31852, 20637, 37058, 27135, 24423, 28267, 25077, 36695, 37517],\n",
       " 35567: [27675, 28264, 27579, 28065, 37960, 36844, 28282, 27769, 27831, 20532],\n",
       " 35566: [20574, 33354, 20576, 20529, 27345, 28025, 27455, 25389, 25392, 28026],\n",
       " 35565: [27506, 14654, 27231, 20675, 26875, 25415, 27761, 26827, 20723, 27030],\n",
       " 35564: [37497, 28481, 28428, 28049, 37259, 31582, 37684, 31581, 28226, 37807],\n",
       " 35563: [27785, 27236, 25415, 27649, 26254, 36663, 25167, 28389, 31978, 26712],\n",
       " 35562: [37510, 36844, 28281, 37636, 37481, 27633, 31994, 32057, 34835, 20730],\n",
       " 35561: [28292, 20677, 27774, 36170, 35328, 34747, 25419, 36438, 25167, 26420],\n",
       " 35560: [36078, 31345, 36560, 20632, 20554, 20563, 27167, 27745, 31343, 27262],\n",
       " 35559: [27255, 28248, 34702, 37062, 35370, 36008, 37388, 36652, 27481, 34067],\n",
       " 35558: [37432, 37371, 35985, 28088, 12442, 35296, 37925, 27693, 14586, 25438],\n",
       " 35557: [36052, 37881, 35584, 37847, 35777, 28547, 35370, 35988, 36458, 27739],\n",
       " 35556: [26351, 27831, 28088, 37423, 27723, 38057, 27693, 28479, 28387, 34403],\n",
       " 35555: [30755, 27805, 36873, 25716, 20499, 27577, 28353, 20388, 36898, 24192],\n",
       " 35554: [27607, 36123, 28332, 27179, 31765, 27858, 28368, 37038, 28318, 35893],\n",
       " 35553: [37497, 36984, 37742, 20500, 36750, 20633, 35278, 31580, 31581, 31582],\n",
       " 35552: [27580, 28353, 21095, 25416, 25077, 25591, 37432, 20495, 28554, 38025],\n",
       " 35551: [36299, 27504, 35831, 36509, 36572, 21095, 36558, 35436, 35797, 37261],\n",
       " 35550: [32057, 31031, 31026, 26399, 31034, 31020, 31032, 14615, 25423, 38039],\n",
       " 35549: [36397, 26960, 20555, 26813, 37813, 14546, 28268, 35943, 25591, 20375],\n",
       " 35548: [26984, 27786, 28213, 28005, 14673, 37037, 35435, 15332, 28038, 27785],\n",
       " 35547: [27092, 28387, 26938, 35304, 20607, 36004, 27709, 26276, 28100, 27654],\n",
       " 35546: [38024, 36866, 36744, 37940, 32701, 35548, 28364, 36527, 27003, 37216],\n",
       " 35545: [20483, 20632, 31021, 20485, 28476, 27835, 28038, 28192, 14579, 36616],\n",
       " 35544: [28401, 14615, 14671, 20607, 26379, 20484, 21730, 26339, 25418, 20606],\n",
       " 35543: [31567, 28353, 27977, 26803, 35160, 24495, 27675, 20479, 26041, 27231],\n",
       " 35542: [20574, 25076, 20594, 27779, 25437, 25392, 28025, 28306, 25591, 27298],\n",
       " 35541: [14586, 27262, 37286, 37592, 37314, 33518, 37791, 28226, 27254, 20685],\n",
       " 35540: [20704, 35218, 34805, 34569, 37014, 14673, 35016, 14462, 35240, 35012],\n",
       " 35539: [26298, 26619, 26194, 14579, 20305, 25417, 25392, 25343, 26854, 27030],\n",
       " 35538: [14317, 24965, 26467, 18282, 26501, 25701, 20305, 35160, 23846, 23847],\n",
       " 35537: [27864, 25179, 36841, 31825, 27497, 37595, 33877, 36591, 36061, 27672],\n",
       " 35536: [27798, 36397, 37105, 26170, 26480, 33660, 35396, 27650, 28390, 14343],\n",
       " 35535: [37913, 35879, 20397, 23703, 20457, 37813, 38016, 38069, 28337, 27455],\n",
       " 35534: [26552, 37026, 26715, 27064, 14709, 20457, 28129, 37807, 26820, 27784],\n",
       " 35533: [32388, 27524, 25233, 25508, 20457, 24800, 24768, 30755, 25231, 33235],\n",
       " 35532: [25853, 35807, 24686, 30755, 25140, 26778, 33823, 38012, 23841, 25187],\n",
       " 35531: [34104, 34213, 34833, 26474, 27054, 25862, 20290, 28006, 26164, 36330],\n",
       " 35530: [28371, 37833, 35648, 37631, 37646, 35431, 31977, 27814, 26018, 35576],\n",
       " 35529: [28273, 20632, 20575, 38094, 28100, 37259, 37864, 37432, 27709, 37791],\n",
       " 35528: [30184, 27231, 37742, 37173, 37038, 20435, 33813, 37376, 33530, 20500],\n",
       " 35527: [20574, 28456, 28554, 27709, 32055, 27423, 28349, 20548, 20748, 37375],\n",
       " 35526: [20546, 27300, 37484, 27374, 26886, 26505, 27978, 24388, 20420, 25437],\n",
       " 35525: [28200, 35160, 27784, 31947, 28226, 28551, 28537, 34427, 28354, 25437],\n",
       " 35524: [36336, 37139, 27403, 28436, 28208, 20526, 28550, 26883, 26025, 37035],\n",
       " 35523: [26835, 24416, 25380, 20404, 20401, 20402, 26744, 27917, 20406, 31913],\n",
       " 35522: [36608, 26750, 34791, 19255, 28504, 37588, 32065, 28523, 37951, 36813],\n",
       " 35521: [27525, 36806, 28252, 37666, 27455, 36004, 38115, 36069, 27172, 27818],\n",
       " 35520: [36397, 37472, 20550, 35350, 27154, 27221, 36937, 27129, 15330, 20551],\n",
       " 35519: [27193, 27977, 26803, 20575, 20574, 20392, 24416, 27074, 20566, 28250],\n",
       " 35518: [32047, 27923, 20633, 27165, 27374, 25411, 28226, 37866, 20392, 38120],\n",
       " 35517: [36677, 37837, 20107, 37520, 36233, 37215, 26606, 28502, 36757, 37914],\n",
       " 35516: [20387, 37291, 36213, 20717, 28180, 37156, 28353, 37416, 36083, 38087],\n",
       " 35515: [20714, 28464, 25398, 25397, 27236, 36921, 20715, 37479, 20387, 20718],\n",
       " 35514: [38027, 20566, 27930, 25226, 37807, 34409, 37381, 11135, 37386, 28096],\n",
       " 35513: [34200, 27356, 36573, 34672, 37864, 37720, 28552, 20575, 35393, 27089],\n",
       " 35512: [20575, 27859, 20593, 25416, 26254, 20576, 20386, 27345, 25415, 36738],\n",
       " 35511: [26357, 20386, 20716, 25566, 28048, 27390, 36825, 24704, 27337, 28110],\n",
       " 35510: [37535, 28114, 27401, 26535, 28474, 28470, 20388, 20714, 28472, 20479],\n",
       " 35509: [20606, 27047, 27745, 27030, 20714, 24965, 37527, 31045, 20388, 38066],\n",
       " 35508: [37640, 36107, 27423, 27057, 27647, 36570, 28241, 36749, 28353, 26332],\n",
       " 35507: [20576, 26886, 20376, 25436, 27978, 20305, 26992, 27298, 33994, 26861],\n",
       " 35506: [26624, 27561, 31883, 26852, 31880, 31887, 27595, 20673, 31886, 37156],\n",
       " 35505: [28110, 36825, 24455, 34135, 35332, 26429, 26202, 20481, 37182, 20362],\n",
       " 35504: [28008, 28100, 26631, 33906, 26886, 27709, 27423, 26505, 34775, 32081],\n",
       " 35503: [20532, 25968, 37955, 33394, 27450, 31160, 25471, 25465, 26206, 25411],\n",
       " 35502: [20632, 27675, 28476, 20344, 26269, 28236, 14546, 27575, 24495, 20727],\n",
       " 35501: [36872, 20698, 27250, 20344, 14654, 20576, 27236, 37497, 20575, 25411],\n",
       " 35500: [28474, 20343, 27852, 28114, 35797, 26535, 20580, 25590, 24574, 25716],\n",
       " 35499: [24495, 28029, 28200, 25077, 28537, 24388, 14338, 23712, 25352, 20345],\n",
       " 35498: [34843, 25090, 32763, 26951, 27518, 25486, 20339, 26208, 27796, 36364],\n",
       " 35497: [26395, 20340, 26008, 35490, 26842, 27031, 28111, 28257, 25965, 27521],\n",
       " 35496: [35282, 33887, 35047, 28368, 28323, 37252, 21729, 35877, 21826, 28438],\n",
       " 35495: [30911, 32898, 30915, 34305, 36707, 30916, 30918, 30917, 34775, 35298],\n",
       " 35494: [28504, 28523, 32606, 37666, 38102, 20325, 38007, 37209, 33014, 32159],\n",
       " 35493: [34695, 33708, 34728, 34696, 34168, 33933, 34694, 35086, 27776, 20325],\n",
       " 35492: [36426, 30293, 35849, 28256, 37567, 34848, 33214, 26645, 33068, 28424],\n",
       " 35491: [26819, 36004, 27298, 27891, 37038, 37551, 37742, 24191, 25889, 27441],\n",
       " 35490: [28015, 36318, 38004, 35956, 26203, 27645, 20718, 34135, 7905, 30763],\n",
       " 35489: [26923, 26254, 26033, 26548, 20511, 26501, 27375, 27509, 28025, 28066],\n",
       " 35488: [36002, 25458, 33091, 37740, 25583, 37287, 28561, 27650, 28282, 25397],\n",
       " 35487: [25419, 25418, 25436, 25392, 25417, 23840, 36185, 25167, 25411, 23841],\n",
       " 35486: [37777, 37329, 37428, 34427, 32056, 25435, 32055, 36308, 20564, 32057],\n",
       " 35485: [25436, 23929, 25640, 25415, 35092, 27074, 11128, 27118, 11110, 34014],\n",
       " 35484: [37642, 25435, 26609, 25699, 26244, 27517, 37083, 20575, 24574, 27837],\n",
       " 35483: [20574, 14683, 36069, 20576, 25435, 24416, 37105, 24415, 36740, 27154],\n",
       " 35482: [25365, 26717, 20635, 37498, 27208, 31996, 25434, 25211, 25408, 27745],\n",
       " 35481: [34773, 26515, 26657, 35251, 36977, 26923, 26535, 37146, 35428, 36996],\n",
       " 35480: [28020, 27143, 25417, 25435, 36438, 20575, 36439, 25436, 27583, 26420],\n",
       " 35479: [20593, 34064, 36281, 27374, 27318, 28226, 20298, 20299, 27709, 27208],\n",
       " 35478: [37798, 20652, 34658, 28562, 26230, 35805, 31031, 20299, 20300, 27188],\n",
       " 35477: [24192, 26515, 20499, 35078, 27485, 20525, 37742, 31766, 35566, 27720],\n",
       " 35476: [25541, 33823, 14317, 30755, 25234, 23840, 27004, 25701, 26653, 37395],\n",
       " 35475: [33933, 33214, 30293, 32015, 33068, 30326, 34213, 19720, 30905, 34324],\n",
       " 35474: [27407, 20575, 27771, 36108, 20576, 27462, 28097, 35012, 36020, 34415],\n",
       " 35473: [24988, 27072, 25953, 34318, 33912, 33743, 33814, 20289, 34359, 20481],\n",
       " 35472: [25876, 26217, 26208, 26453, 25567, 24178, 25295, 25486, 25570, 26929],\n",
       " 35471: [31993, 35127, 25908, 23601, 31996, 34283, 33023, 33816, 33634, 33988],\n",
       " 35470: [33961, 33742, 34318, 35525, 34359, 20479, 32070, 20481, 32071, 33766],\n",
       " 35469: [32067, 32069, 33961, 20481, 20633, 27137, 27485, 35332, 25392, 27978],\n",
       " 35468: [36549, 28048, 26480, 37182, 25953, 37984, 27797, 37994, 27072, 27798],\n",
       " 35467: [20277, 35067, 26052, 36523, 20294, 30949, 36045, 31882, 27298, 30950],\n",
       " 35466: [35769, 36919, 31996, 25219, 37506, 28316, 26263, 14635, 26755, 25375],\n",
       " 35465: [28476, 37331, 38112, 28354, 28275, 14645, 36691, 14680, 14621, 35251],\n",
       " 35464: [27395, 20261, 27090, 36489, 36682, 36729, 36977, 20576, 28060, 28333],\n",
       " 35463: [27342, 26342, 27438, 24412, 24768, 27062, 25965, 30934, 25393, 24705],\n",
       " 35462: [20490, 26744, 30888, 25578, 27355, 27289, 37516, 25736, 35292, 25523],\n",
       " 35461: [20300, 34658, 26080, 27078, 26825, 27367, 27074, 27288, 27977, 25701],\n",
       " 35460: [26552, 26886, 20697, 28025, 20757, 27457, 27852, 26505, 27172, 27583],\n",
       " 35459: [35444, 31877, 27771, 31874, 34742, 21094, 28423, 31875, 35901, 30893],\n",
       " 35458: [28405, 28470, 28190, 28273, 37880, 27047, 28354, 14654, 36394, 26827],\n",
       " 35457: [27734, 20935, 20325, 34844, 20245, 34403, 20326, 31182, 31185, 35362],\n",
       " 35456: [14343, 27650, 26035, 26351, 22899, 27176, 20575, 36974, 30907, 37541],\n",
       " 35455: [25838, 35308, 34483, 27604, 28192, 34865, 34646, 27593, 27134, 36010],\n",
       " 35454: [28112, 20575, 28361, 27176, 27001, 27231, 20576, 22265, 36823, 35315],\n",
       " 35453: [20500, 20574, 20576, 38100, 32074, 27844, 27583, 36069, 25437, 34530],\n",
       " 35452: [35922, 27981, 28270, 27785, 31979, 26977, 36362, 35861, 37022, 31975],\n",
       " 35451: [25076, 20479, 25426, 14654, 27779, 26854, 27844, 20392, 25392, 25423],\n",
       " 35450: [34232, 33589, 25507, 27300, 27250, 24416, 37108, 25392, 28230, 34317],\n",
       " 35449: [27067, 27693, 28353, 37331, 27859, 27216, 28275, 14621, 21728, 37877],\n",
       " 35448: [20574, 37675, 38100, 37866, 28337, 31847, 28226, 35968, 27607, 27254],\n",
       " 35447: [34303, 35491, 20632, 28169, 36397, 28476, 35521, 32583, 35630, 34991],\n",
       " 35446: [37888, 25090, 26607, 27800, 25055, 28501, 26208, 20676, 25486, 37291],\n",
       " 35445: [34120, 37739, 28429, 37341, 20677, 37939, 37902, 36490, 20489, 34261],\n",
       " 35444: [37402, 37427, 27140, 28349, 37201, 38022, 31383, 37799, 28480, 36761],\n",
       " 35443: [27898, 27556, 25210, 20107, 34851, 38023, 37621, 36757, 34439, 35041],\n",
       " 35442: [20479, 34201, 14654, 27106, 35393, 36697, 34200, 27457, 27844, 36475],\n",
       " 35441: [20507, 27963, 20587, 28544, 27786, 26984, 27123, 35742, 28019, 27463],\n",
       " 35440: [28476, 35326, 37454, 30950, 38045, 30955, 28128, 36737, 27466, 20500],\n",
       " 35439: [20594, 20124, 27420, 26254, 27861, 28154, 25435, 25417, 27419, 28132],\n",
       " 35438: [20484, 27089, 26590, 27090, 34810, 35088, 28333, 28562, 28364, 37521],\n",
       " 35437: [27943, 28252, 27445, 37882, 28273, 37880, 38115, 38087, 27756, 27420],\n",
       " 35436: [26038, 25571, 34689, 32739, 34696, 34128, 33349, 34694, 32875, 26309],\n",
       " 35435: [36001, 25362, 25366, 34343, 36382, 20124, 27768, 7897, 20125, 27777],\n",
       " 35434: [27771, 37675, 35012, 34415, 25889, 27443, 28423, 20747, 27047, 25362],\n",
       " 35433: [35777, 35429, 37388, 27258, 35989, 35370, 35277, 35125, 37654, 35531],\n",
       " 35432: [36346, 37853, 37661, 38028, 37924, 38081, 38018, 37372, 37950, 36676],\n",
       " 35431: [26064, 37344, 37404, 37983, 35650, 34149, 26692, 32370, 37748, 14660],\n",
       " 35430: [30842, 36034, 27852, 36918, 25435, 27074, 38000, 20298, 26601, 25948],\n",
       " 35429: [27723, 31033, 28097, 34166, 31031, 31026, 28306, 26225, 37740, 31029],\n",
       " 35428: [35072, 30556, 34532, 25567, 34964, 25794, 25569, 25572, 26361, 25806],\n",
       " 35427: [26932, 35024, 27026, 25131, 26606, 34067, 14227, 5843, 35619, 35349],\n",
       " 35426: [33926, 19588, 35404, 34149, 35760, 34686, 27481, 34749, 20106, 35650],\n",
       " 35425: [34524, 35746, 33751, 37914, 33464, 35876, 33655, 36061, 34332, 35390],\n",
       " 35424: [34749, 34290, 20107, 35749, 35429, 26698, 35470, 34732, 34362, 27026],\n",
       " 35423: [24878, 27739, 35125, 33964, 33825, 34425, 35749, 26427, 35179, 34980],\n",
       " 35422: [34689, 34004, 34695, 25039, 29705, 33339, 26647, 33507, 34168, 25295],\n",
       " 35421: [20294, 20073, 20704, 33717, 36707, 33744, 30761, 34767, 20501, 20031],\n",
       " 35420: [20030, 36643, 26453, 31879, 37186, 26572, 27800, 31606, 20339, 31882],\n",
       " 35419: [31336, 36530, 26038, 36303, 27602, 20616, 20183, 36447, 35601, 26836],\n",
       " 35418: [33143, 37850, 36297, 35963, 35185, 35992, 36061, 26411, 36240, 34332],\n",
       " 35417: [37851, 33044, 36743, 36427, 27072, 20479, 20575, 38109, 36825, 33394],\n",
       " 35416: [24455, 35956, 28015, 35400, 27776, 28014, 34460, 22818, 28298, 22812],\n",
       " 35415: [20175, 33264, 27518, 26951, 27340, 27128, 36020, 26509, 33947, 31797],\n",
       " 35414: [24993, 27822, 30872, 20487, 20633, 26547, 32081, 36449, 31973, 27525],\n",
       " 35413: [20574, 33892, 25389, 20479, 20576, 37510, 25390, 27534, 27331, 28306],\n",
       " 35412: [19986, 31976, 31974, 38045, 31979, 37592, 37791, 20576, 26039, 36409],\n",
       " 35411: [33570, 31979, 31976, 31974, 31980, 36727, 37870, 26243, 36388, 26666],\n",
       " 35410: [27709, 20575, 36906, 28353, 25415, 36504, 35444, 36738, 35367, 27583],\n",
       " 35409: [34318, 19982, 24415, 27078, 19985, 26597, 34548, 31973, 24417, 27298],\n",
       " 35408: [20675, 19982, 31973, 35174, 19984, 37675, 35647, 31974, 31567, 19985],\n",
       " 35407: [20378, 19966, 26803, 25639, 19965, 36069, 25640, 36994, 19964, 36014],\n",
       " 35406: [20511, 19966, 25577, 26085, 25889, 27910, 26528, 20305, 24574, 20575],\n",
       " 35405: [20376, 24415, 19966, 20511, 31854, 20748, 20392, 25591, 28133, 20378],\n",
       " 35404: [20377, 25639, 19965, 35196, 36409, 27959, 19964, 28080, 28546, 36607],\n",
       " 35403: [37814, 19964, 25979, 25180, 25545, 32042, 27668, 27154, 36362, 25168],\n",
       " 35402: [28074, 35600, 37481, 27064, 37992, 27891, 20499, 27675, 38117, 36548],\n",
       " 35401: [20086, 20085, 31385, 31383, 20089, 30828, 35022, 20091, 20088, 19619],\n",
       " 35400: [26495, 19938, 27937, 26301, 26835, 27760, 25640, 27298, 26552, 20705],\n",
       " 35399: [27137, 19938, 26715, 27888, 20511, 37716, 28025, 35302, 20705, 20376],\n",
       " 35398: [19938, 31883, 26298, 27785, 20525, 20705, 28337, 27930, 31886, 28229],\n",
       " 35397: [27580, 22779, 33487, 28265, 20633, 33983, 19939, 28476, 37010, 20705],\n",
       " 35396: [33961, 20740, 20581, 33814, 28441, 28029, 25392, 35601, 27058, 20580],\n",
       " 35395: [31852, 27785, 20705, 27649, 26619, 36663, 37786, 27656, 36356, 28537],\n",
       " 35394: [37178, 36530, 27295, 27689, 26960, 27345, 26795, 37461, 31581, 35548],\n",
       " 35393: [37880, 37041, 21095, 20546, 25423, 20545, 28200, 37530, 19939, 20576],\n",
       " 35392: [27616, 36863, 38057, 36107, 20343, 20686, 36714, 28478, 37780, 27543],\n",
       " 35391: [27190, 27835, 14341, 36049, 27852, 26886, 37713, 27216, 36798, 26505],\n",
       " 35390: [27067, 26550, 19939, 26818, 32701, 26776, 36579, 14681, 27656, 27137],\n",
       " 35389: [34170, 23601, 24553, 33525, 35908, 33507, 33023, 32954, 35838, 33961],\n",
       " 35388: [20526, 31847, 26993, 37035, 28492, 34836, 31849, 27092, 32255, 27431],\n",
       " 35387: [36373, 28318, 36902, 37321, 37874, 37838, 37531, 28462, 35856, 2383],\n",
       " 35386: [26501, 27231, 25435, 2476, 27118, 25594, 24388, 20413, 27807, 21094],\n",
       " 35385: [27050, 26950, 19915, 27912, 19939, 27208, 31581, 25435, 27685, 2461],\n",
       " 35384: [31326, 26533, 25964, 27003, 26879, 26001, 27650, 26256, 37421, 26751],\n",
       " 35383: [35584, 36052, 35988, 25119, 19588, 34534, 31613, 35938, 35579, 35429],\n",
       " 35382: [26624, 25295, 26868, 27994, 27896, 25215, 27981, 27703, 24838, 26852],\n",
       " 35381: [32886, 34128, 35414, 32557, 27064, 25139, 33487, 33983, 36303, 24638],\n",
       " 35380: [20339, 35561, 25582, 20338, 20731, 37921, 19869, 36110, 25581, 26424],\n",
       " 35379: [26688, 28310, 14636, 35162, 20106, 36536, 26417, 26016, 26427, 25500],\n",
       " 35378: [27739, 34430, 28290, 26417, 24246, 34399, 33873, 35412, 26688, 26016],\n",
       " 35377: [35932, 37858, 19837, 36233, 27623, 35142, 37372, 37272, 37654, 20107],\n",
       " 35376: [34290, 37714, 19834, 20038, 19816, 20601, 19832, 29847, 25179, 19836],\n",
       " 35375: [33926, 26692, 35179, 20022, 37579, 34524, 19816, 33964, 20106, 35370],\n",
       " 35374: [26015, 25591, 34669, 27163, 27030, 31180, 26609, 33059, 26665, 27304],\n",
       " 35373: [26131, 19790, 25343, 37712, 19791, 25392, 28353, 24416, 28025, 37291],\n",
       " 35372: [20339, 20365, 27994, 35326, 34521, 34261, 26204, 20072, 37927, 26492],\n",
       " 35371: [28177, 27295, 35556, 27469, 14096, 27203, 36069, 36083, 28250, 37525],\n",
       " 35370: [35192, 27685, 25508, 35165, 28187, 25491, 26394, 20325, 28169, 31797],\n",
       " 35369: [24965, 33413, 33030, 20071, 20297, 20294, 20072, 33056, 20363, 25898],\n",
       " 35368: [19766, 24930, 25807, 20640, 37249, 31292, 34006, 32310, 24223, 20641],\n",
       " 35367: [36616, 27831, 28205, 37807, 36013, 27424, 28264, 35362, 37464, 36585],\n",
       " 35366: [24449, 35131, 30449, 33724, 27356, 27427, 27735, 27878, 28353, 35088],\n",
       " 35365: [30907, 19720, 33395, 27768, 30092, 30334, 26105, 26351, 31726, 31725],\n",
       " 35364: [27745, 25560, 20576, 26827, 27030, 25639, 31045, 28187, 28488, 28200],\n",
       " 35363: [27318, 35251, 33737, 28050, 36499, 28400, 35374, 20633, 27831, 28132],\n",
       " 35362: [34363, 24855, 31953, 26784, 34731, 25077, 25833, 33095, 23712, 24473],\n",
       " 35361: [27556, 35992, 28310, 37404, 27759, 28083, 26100, 36693, 27790, 31576],\n",
       " 35360: [34524, 36452, 35370, 28290, 37220, 35397, 36755, 33197, 35882, 37268],\n",
       " 35359: [26430, 34290, 33825, 34342, 37062, 24878, 36817, 35404, 34067, 26397],\n",
       " 35358: [20016, 36888, 34873, 35077, 36231, 35125, 34290, 31824, 19651, 35169],\n",
       " 35357: [25295, 32309, 24894, 24556, 27800, 24705, 25215, 27659, 26453, 33966],\n",
       " 35356: [26217, 34689, 34694, 31741, 24544, 19690, 27800, 26868, 34684, 21920],\n",
       " 35355: [33821, 32738, 33855, 20176, 24404, 34919, 32763, 33487, 26717, 24412],\n",
       " 35354: [35992, 27255, 37215, 35229, 36665, 35906, 35397, 28499, 34702, 36249],\n",
       " 35353: [31980, 19986, 31974, 19938, 37379, 19939, 27111, 36595, 20487, 35304],\n",
       " 35352: [30605, 24176, 35377, 33531, 24642, 33187, 32645, 32995, 33734, 32778],\n",
       " 35351: [20390, 36991, 35397, 20038, 28248, 36591, 36346, 34524, 34892, 36893],\n",
       " 35350: [25564, 27164, 27258, 34342, 26016, 26430, 19635, 26397, 27957, 27024],\n",
       " 35349: [35526, 34332, 36027, 35385, 35370, 36959, 37918, 23677, 34748, 36693],\n",
       " 35348: [31961, 37592, 28104, 37998, 37720, 20575, 24774, 20576, 28260, 33350],\n",
       " 35347: [28349, 30828, 26189, 27910, 14681, 27805, 26609, 25233, 25435, 36381],\n",
       " 35346: [27613, 36570, 25417, 25436, 26682, 36291, 38114, 26970, 27818, 24774],\n",
       " 35345: [28438, 28490, 28447, 28479, 24382, 24383, 34629, 35060, 27449, 28349],\n",
       " 35344: [24382, 24865, 32307, 35836, 35968, 24408, 28096, 28447, 34629, 27449],\n",
       " 35343: [28094, 27016, 20622, 37607, 34766, 31020, 32001, 32748, 31996, 27577],\n",
       " 35342: [20301, 25938, 31678, 32402, 34052, 32577, 31159, 30893, 31658, 31662],\n",
       " 35341: [19619, 34909, 20547, 37484, 30827, 15966, 20545, 31663, 35160, 20589],\n",
       " 35340: [35127, 36004, 38096, 37448, 27733, 36331, 27205, 25136, 37191, 26429],\n",
       " 35339: [28466, 28364, 36876, 28349, 38030, 38102, 37864, 28368, 36866, 37526],\n",
       " 35338: [35169, 34267, 26356, 27258, 33825, 27026, 35125, 26797, 35550, 26314],\n",
       " 35337: [4074, 25582, 25125, 32612, 34763, 35325, 24875, 14563, 32251, 35819],\n",
       " 35336: [37968, 27751, 37201, 37988, 35219, 34848, 28349, 35144, 32015, 32014],\n",
       " 35335: [14311, 31994, 26105, 31993, 14294, 27173, 35325, 33850, 34166, 33466],\n",
       " 35334: [26907, 14411, 26084, 37028, 25568, 25569, 25806, 14478, 26038, 25001],\n",
       " 35333: [19588, 35932, 35385, 27957, 36233, 35650, 36693, 28290, 36676, 28064],\n",
       " 35332: [24415, 27374, 14414, 28029, 27675, 14215, 26923, 37053, 19483, 27208],\n",
       " 35331: [26217, 32738, 34790, 25968, 36805, 36364, 19581, 26387, 20103, 32739],\n",
       " 35330: [33825, 34399, 26427, 34732, 34173, 35531, 26368, 28064, 24801, 14260],\n",
       " 35329: [26356, 20106, 26698, 35531, 20107, 34369, 26107, 14260, 24803, 26688],\n",
       " 35328: [36902, 31386, 28119, 35784, 31381, 31383, 37317, 36512, 36911, 35363],\n",
       " 35327: [20380, 19965, 20377, 25507, 20376, 20379, 19967, 20023, 26309, 26332],\n",
       " 35326: [20390, 27255, 27510, 35470, 32692, 28432, 19651, 27961, 36403, 36249],\n",
       " 35325: [27624, 34149, 27556, 34326, 36703, 33877, 20106, 28324, 35650, 26104],\n",
       " 35324: [26932, 27759, 26107, 25918, 33877, 33468, 28116, 35650, 33926, 20107],\n",
       " 35323: [35988, 34607, 35185, 37595, 38050, 33785, 28432, 27821, 38072, 26430],\n",
       " 35322: [33197, 33877, 35531, 35357, 37654, 27481, 36771, 27139, 35397, 33464],\n",
       " 35321: [27255, 28310, 25179, 37318, 36591, 27510, 27026, 34290, 34702, 27957],\n",
       " 35320: [37715, 20646, 35531, 26430, 33765, 31826, 26397, 38072, 27008, 20474],\n",
       " 35319: [24642, 24383, 32995, 24771, 28448, 33531, 34118, 34340, 35005, 33131],\n",
       " 35318: [36373, 25467, 37531, 27756, 35245, 25466, 32775, 24655, 37225, 25471],\n",
       " 35317: [20244, 34843, 32763, 26224, 27044, 20245, 20755, 34759, 24961, 20760],\n",
       " 35316: [25210, 36629, 26430, 34534, 32370, 31829, 27719, 37343, 36238, 36048],\n",
       " 35315: [36299, 26918, 37081, 34844, 34322, 38057, 27831, 34031, 28205, 28264],\n",
       " 35314: [25564, 34290, 26430, 26016, 34173, 26390, 34581, 26944, 27864, 26107],\n",
       " 35313: [35370, 28499, 27672, 37404, 27481, 35470, 31613, 35760, 35531, 37208],\n",
       " 35312: [34267, 33825, 36591, 33197, 33713, 33888, 34248, 25909, 19635, 36016],\n",
       " 35311: [32504, 19470, 35370, 34326, 25918, 24801, 34581, 33888, 29820, 35412],\n",
       " 35310: [31385, 31678, 37888, 36761, 29858, 36583, 24177, 30955, 24383, 35324],\n",
       " 35309: [36806, 19439, 20721, 33064, 34431, 37228, 35538, 25489, 28025, 37171],\n",
       " 35308: [37958, 37620, 36676, 37120, 37540, 38072, 37608, 36458, 35772, 37914],\n",
       " 35307: [36850, 26712, 20575, 20607, 35119, 36107, 25435, 25640, 22783, 24416],\n",
       " 35306: [35601, 37105, 36069, 26977, 26675, 20698, 27583, 27783, 26467, 27926],\n",
       " 35305: [36956, 19835, 36452, 14090, 36841, 35954, 35532, 36839, 38079, 37220],\n",
       " 35304: [37715, 35932, 27898, 27255, 36233, 35777, 31825, 20107, 37388, 28116],\n",
       " 35303: [20652, 34658, 35805, 26498, 28416, 26817, 25929, 38002, 27688, 26663],\n",
       " 35302: [35992, 14127, 26944, 34290, 25496, 37620, 35179, 34578, 27957, 14636],\n",
       " 35301: [35900, 27389, 25500, 33765, 26734, 35584, 20657, 37847, 37093, 26971],\n",
       " 35300: [14090, 36591, 35882, 28502, 36841, 38072, 37958, 36346, 36819, 36956],\n",
       " 35299: [33825, 25564, 26430, 24878, 35125, 14182, 26822, 36458, 24785, 28331],\n",
       " 35298: [36249, 33765, 32370, 30980, 37268, 31578, 37565, 37892, 31575, 37093],\n",
       " 35297: [32982, 25166, 25118, 25228, 27140, 33123, 34144, 33688, 25898, 25124],\n",
       " 35296: [37858, 27726, 20107, 35906, 36433, 37372, 27957, 20106, 27739, 37924],\n",
       " 35295: [28418, 36905, 35650, 36665, 20153, 26692, 31612, 28290, 35954, 37785],\n",
       " 35294: [37810, 37557, 37809, 37651, 36204, 19085, 32019, 36334, 38113, 36387],\n",
       " 35293: [34524, 26606, 28248, 37093, 14326, 37715, 35526, 28083, 28310, 27276],\n",
       " 35292: [34355, 34783, 36061, 34934, 31575, 37353, 35349, 34332, 32832, 37850],\n",
       " 35291: [27790, 35526, 27024, 15554, 34749, 27258, 16165, 26698, 27759, 27008],\n",
       " 35290: [34702, 37654, 19302, 36458, 34369, 36144, 36309, 37372, 36757, 24465],\n",
       " 35289: [25496, 31575, 25846, 36231, 35619, 26104, 37222, 37413, 37847, 37430],\n",
       " 35288: [31445, 24500, 34267, 25179, 34399, 24830, 25536, 24629, 34342, 19304],\n",
       " 35287: [37120, 37344, 36645, 37744, 28165, 37861, 28547, 37185, 14090, 38079],\n",
       " 35286: [28290, 35370, 37088, 36676, 36839, 37149, 36841, 37476, 36693, 19651],\n",
       " 35285: [24629, 25245, 28331, 37792, 36867, 36703, 32370, 37274, 36991, 35989],\n",
       " 35284: [35882, 36819, 36226, 35229, 37540, 36452, 14509, 36591, 24953, 19303],\n",
       " 35283: [32579, 33253, 31187, 23589, 14042, 31529, 27478, 31990, 31921, 21109],\n",
       " 35282: [35556, 37864, 20635, 26513, 20564, 27768, 35653, 25369, 27365, 25389],\n",
       " 35281: [26921, 27487, 26795, 33879, 28224, 20344, 25435, 37925, 27807, 36214],\n",
       " 35280: [22215, 22225, 22223, 22167, 22122, 22154, 22190, 22168, 22157, 22228],\n",
       " 35279: [37081, 20773, 27530, 27732, 36974, 31978, 37363, 28088, 24613, 28097],\n",
       " 35278: [28177, 37515, 20773, 37420, 37574, 38118, 28026, 20636, 37026, 36541],\n",
       " 35277: [27861, 20632, 37997, 37486, 37387, 20773, 37851, 38073, 26970, 37948],\n",
       " 35276: [25180, 26581, 25979, 26969, 26093, 35119, 27047, 27910, 36020, 25435],\n",
       " 35275: [19967, 26434, 27834, 19966, 35821, 20633, 37075, 27455, 28208, 34116],\n",
       " 35274: [25435, 26298, 27163, 37046, 26609, 36475, 35326, 26827, 35630, 27030],\n",
       " 35273: [37527, 37864, 14681, 27661, 28513, 27583, 27455, 35150, 28226, 20740],\n",
       " 35272: [25246, 26910, 37832, 34135, 24455, 24553, 28015, 25431, 36948, 27211],\n",
       " 35271: [15332, 28230, 28537, 27675, 28226, 37700, 20749, 27575, 37709, 27749],\n",
       " 35270: [25979, 34497, 37700, 36449, 27170, 26909, 25370, 27894, 28517, 27047],\n",
       " 35269: [36004, 27118, 28425, 32074, 38006, 25420, 37994, 27030, 37310, 27313],\n",
       " 35268: [27310, 34497, 37196, 36397, 28065, 38041, 36069, 27154, 37640, 28464],\n",
       " 35267: [24993, 27236, 31580, 20380, 31582, 25435, 25365, 25853, 31813, 31796],\n",
       " 35266: [20063, 28373, 29029, 24590, 31764, 14050, 16666, 27007, 25574, 27962],\n",
       " 35265: [24192, 24191, 28216, 14546, 28268, 25423, 36697, 37491, 28020, 35546],\n",
       " 35264: [27771, 27940, 35630, 37498, 37883, 28423, 20548, 28560, 36397, 19254],\n",
       " 35263: [27940, 28359, 35520, 35734, 36573, 15966, 24418, 36718, 34631, 36747],\n",
       " 35262: [36573, 27374, 27685, 20343, 27675, 26851, 20551, 20125, 25417, 25416],\n",
       " 35261: [26039, 35815, 25968, 27776, 25863, 24234, 26930, 14050, 33611, 24887],\n",
       " 35260: [20305, 25808, 20377, 20376, 25426, 20378, 25417, 25352, 35790, 26332],\n",
       " 35259: [30332, 22819, 22812, 24887, 24474, 26105, 22817, 19719, 22816, 30905],\n",
       " 35258: [20278, 20279, 32625, 32680, 19758, 19228, 33258, 14351, 33275, 14439],\n",
       " 35257: [30334, 32205, 19719, 27582, 30616, 31711, 30332, 31010, 30766, 30905],\n",
       " 35256: [26013, 20554, 36529, 14615, 31032, 38061, 31031, 38039, 26709, 31033],\n",
       " 35255: [37904, 27518, 27340, 37769, 24174, 37402, 20759, 27893, 24171, 37778],\n",
       " 35254: [30755, 33791, 33823, 34805, 14462, 34110, 33928, 35016, 34695, 34684],\n",
       " 35253: [37887, 37809, 38098, 32019, 36037, 36387, 36908, 38101, 38113, 36842],\n",
       " 35252: [35923, 32019, 36204, 38101, 38113, 36123, 26917, 36607, 35669, 36908],\n",
       " 35251: [36386, 36334, 38000, 19751, 37448, 26814, 32041, 37441, 38034, 37445],\n",
       " 35250: [26558, 20712, 26633, 30615, 35739, 30613, 30145, 24276, 31480, 35686],\n",
       " 35249: [17555, 19001, 21300, 28926, 19035, 17558, 21385, 18968, 9543, 19007],\n",
       " 35248: [17555, 21408, 21395, 21398, 19389, 18970, 21385, 29413, 18992, 18997],\n",
       " 35247: [25243, 27032, 30763, 28015, 35956, 27223, 28014, 27517, 35617, 25973],\n",
       " 35246: [26165, 25224, 28212, 25736, 27108, 25566, 20526, 24685, 28211, 24809],\n",
       " 35245: [26452, 24575, 34687, 26202, 26163, 26113, 35525, 25471, 25301, 25246],\n",
       " 35244: [25877, 25883, 25875, 34852, 8158, 27517, 34195, 34755, 32895, 36334],\n",
       " 35243: [11837, 25947, 27206, 30801, 23095, 20406, 36302, 20400, 37312, 31872],\n",
       " 35242: [18824, 22245, 22225, 22117, 28872, 22155, 22153, 22113, 30248, 22092],\n",
       " 35241: [22219, 22225, 22164, 22165, 22106, 22190, 22109, 22245, 22062, 22089],\n",
       " 35240: [22106, 22206, 22190, 22045, 22060, 22200, 22180, 22217, 22067, 22119],\n",
       " 35239: [23851, 27802, 25731, 36973, 34762, 26187, 31872, 24872, 31199, 20223],\n",
       " 35238: [28344, 37223, 36844, 32055, 35653, 32057, 28441, 20701, 20566, 26361],\n",
       " 35237: [27893, 25968, 19915, 28362, 35571, 27123, 24474, 37028, 31680, 24234],\n",
       " 35236: [34318, 24474, 26879, 32068, 26646, 20480, 33912, 24249, 33814, 36825],\n",
       " 35235: [20576, 27225, 25140, 26298, 31854, 31029, 25434, 25417, 26420, 35307],\n",
       " 35234: [36776, 36779, 36031, 30888, 36777, 38034, 36968, 36264, 37192, 35709],\n",
       " 35233: [28480, 37635, 36474, 37432, 24553, 28298, 27799, 27709, 37925, 37331],\n",
       " 35232: [37534, 37328, 35556, 34902, 37864, 35639, 38076, 28020, 27656, 14681],\n",
       " 35231: [20484, 26093, 25435, 24412, 37521, 20340, 27074, 27531, 25415, 25718],\n",
       " 35230: [25224, 25637, 32583, 28211, 34181, 18390, 24685, 26963, 26429, 26165],\n",
       " 35229: [25973, 20400, 31343, 20403, 10552, 14272, 20402, 18894, 8069, 35617],\n",
       " 35228: [31581, 18285, 19628, 24416, 33272, 14654, 31583, 36750, 20767, 26600],\n",
       " 35227: [27579, 34696, 37156, 34684, 35807, 20740, 34694, 36069, 37716, 27583],\n",
       " 35226: [34698, 27143, 20124, 26810, 26851, 36108, 28500, 36413, 24411, 20740],\n",
       " 35225: [27745, 25716, 19966, 28541, 37083, 28353, 28297, 31973, 28554, 31974],\n",
       " 35224: [36750, 31580, 24191, 24192, 20575, 34339, 31585, 26361, 31586, 38116],\n",
       " 35223: [33323, 36467, 14462, 33847, 33739, 37368, 37864, 14673, 26408, 24456],\n",
       " 35222: [36773, 27783, 37193, 36266, 36779, 36031, 36164, 27926, 37019, 37191],\n",
       " 35221: [28074, 20696, 35793, 36368, 20715, 27745, 20388, 20387, 35188, 25434],\n",
       " 35220: [19766, 19768, 23889, 35540, 34943, 24759, 24716, 31958, 27366, 11245],\n",
       " 35219: [26503, 30510, 34790, 26327, 25090, 28172, 34324, 27650, 32243, 35086],\n",
       " 35218: [36509, 26813, 35893, 27455, 27723, 37380, 38087, 32070, 35943, 37530],\n",
       " 35217: [25246, 26185, 27032, 34135, 28298, 37496, 33776, 24553, 34065, 26202],\n",
       " 35216: [31874, 24473, 35842, 31877, 25411, 25426, 31875, 25581, 25583, 26384],\n",
       " 35215: [17851, 17878, 17893, 17911, 17900, 17895, 17898, 17884, 17909, 17886],\n",
       " 35214: [25932, 24716, 33500, 25100, 25197, 28233, 20565, 25184, 19988, 24759],\n",
       " 35213: [22217, 22156, 28861, 22189, 22180, 22245, 22239, 22192, 18840, 22226],\n",
       " 35212: [35304, 32081, 32508, 31704, 26633, 31711, 33582, 30991, 30037, 30772],\n",
       " 35211: [17700, 11618, 26904, 24280, 5443, 24459, 27153, 20277, 24533, 26897],\n",
       " 35210: [27207, 27124, 17699, 17705, 26114, 21477, 25844, 35930, 30532, 25001],\n",
       " 35209: [28262, 28438, 37423, 37798, 20575, 20486, 34611, 37337, 37793, 20576],\n",
       " 35208: [38007, 26840, 37769, 37885, 37392, 27223, 37050, 37511, 36489, 33521],\n",
       " 35207: [33991, 28233, 19253, 25197, 14595, 825, 27150, 24594, 36432, 8083],\n",
       " 35206: [20638, 27134, 34415, 35444, 31847, 35952, 33432, 28025, 35251, 35846],\n",
       " 35205: [19453, 23087, 23111, 23081, 23075, 19988, 23113, 21245, 35335, 21244],\n",
       " 35204: [19034, 21360, 21411, 21400, 21404, 18964, 19001, 21301, 21414, 19008],\n",
       " 35203: [19034, 18968, 4505, 29386, 21556, 29303, 18989, 29365, 29361, 4742],\n",
       " 35202: [17555, 18964, 21385, 19007, 17552, 21317, 18990, 19016, 21314, 18952],\n",
       " 35201: [19031, 17531, 18964, 18995, 21329, 4772, 17530, 17551, 29487, 29747],\n",
       " 35200: [21323, 19034, 29427, 19014, 19004, 29453, 19016, 18970, 21909, 18956],\n",
       " 35199: [17552, 9543, 21903, 17555, 19014, 18998, 29451, 18937, 29422, 29424],\n",
       " 35198: [17996, 17833, 17850, 17974, 17823, 17999, 18003, 17817, 17995, 17933],\n",
       " 35197: [21903, 21404, 21540, 19389, 21400, 29507, 29331, 21364, 19034, 29388],\n",
       " 35196: [19034, 18964, 21385, 17560, 21379, 19018, 21378, 18970, 21328, 17532],\n",
       " 35195: [17407, 30523, 25140, 17429, 20607, 17415, 37947, 26825, 25415, 25431],\n",
       " 35194: [28428, 27888, 27488, 37716, 27282, 17323, 28200, 37766, 20774, 37505],\n",
       " 35193: [26590, 19982, 31974, 31971, 37287, 35088, 28364, 28306, 36729, 19986],\n",
       " 35192: [36412, 26105, 31762, 34341, 17335, 17322, 19939, 17321, 27030, 26609],\n",
       " 35191: [17312, 24402, 25648, 27771, 22783, 24383, 35869, 35444, 36791, 19659],\n",
       " 35190: [36876, 28106, 17261, 17249, 36368, 20500, 27891, 28260, 32074, 20499],\n",
       " 35189: [20498, 20632, 20500, 25363, 20122, 36865, 28476, 37038, 34343, 36260],\n",
       " 35188: [17261, 31708, 26351, 30619, 30641, 27111, 30993, 14414, 27971, 33303],\n",
       " 35187: [21404, 19034, 29389, 21390, 29424, 21545, 21415, 18997, 18941, 21598],\n",
       " 35186: [26288, 26661, 30448, 33395, 25470, 27859, 24403, 35422, 26875, 35776],\n",
       " 35185: [17501, 21586, 23115, 30689, 30809, 17504, 30810, 29554, 17902, 18159],\n",
       " 35184: [17829, 17994, 17874, 16784, 17869, 17905, 16783, 17906, 17835, 16862],\n",
       " 35183: [17861, 17865, 16785, 17878, 17909, 17851, 16783, 17974, 17916, 17893],\n",
       " 35182: [20693, 17895, 17501, 31957, 29295, 17892, 29904, 17902, 17998, 17851],\n",
       " 35181: [28872, 22225, 22133, 16827, 22114, 22218, 22209, 21579, 22226, 16664],\n",
       " 35180: [17835, 16819, 16676, 17833, 29877, 16720, 30868, 17989, 17949, 17850],\n",
       " 35179: [18964, 17555, 21909, 29440, 29487, 18992, 19008, 18991, 17557, 19001],\n",
       " 35178: [24237, 27873, 27027, 27383, 28349, 37052, 28158, 34225, 37526, 20585],\n",
       " 35177: [16828, 16827, 16801, 16862, 16823, 16714, 16840, 16704, 16656, 16769],\n",
       " 35176: [16803, 21557, 17555, 18964, 19003, 18930, 18935, 18955, 16694, 18931],\n",
       " 35175: [27756, 32675, 32248, 34894, 33380, 36262, 27132, 16669, 36543, 28180],\n",
       " 35174: [32701, 25507, 32665, 33982, 25571, 25215, 32262, 32739, 26039, 32473],\n",
       " 35173: [27568, 16752, 23299, 23136, 27569, 16828, 17908, 36522, 16754, 23297],\n",
       " 35172: [21385, 21597, 19034, 16770, 16788, 29407, 18773, 23150, 29401, 23295],\n",
       " 35171: [16662, 16782, 16860, 16713, 16785, 16828, 16757, 16650, 16840, 16783],\n",
       " 35170: [19034, 29289, 16657, 16656, 29411, 16697, 16784, 16785, 29378, 16737],\n",
       " 35169: [16803, 16656, 16784, 16691, 16769, 19034, 16701, 16819, 16802, 16785],\n",
       " 35168: [16657, 16753, 16780, 16703, 16782, 16697, 16819, 16737, 16846, 16833],\n",
       " 35167: [19034, 16779, 16803, 17543, 21385, 16712, 18023, 21383, 29375, 29453],\n",
       " 35166: [17862, 17830, 17835, 16723, 17833, 17818, 16657, 17839, 17864, 17978],\n",
       " 35165: [16679, 16657, 16695, 16737, 16697, 16758, 19007, 16675, 16727, 16760],\n",
       " 35164: [16783, 16840, 16779, 16782, 16866, 16827, 16771, 16763, 16713, 16857],\n",
       " 35163: [16802, 16754, 16819, 16784, 16785, 16722, 16783, 16857, 16810, 16758],\n",
       " 35162: [16609, 16635, 16686, 16785, 16638, 16725, 16620, 16674, 16684, 16862],\n",
       " 35161: [16780, 18964, 29480, 29424, 29411, 16716, 18999, 16779, 16647, 18989],\n",
       " 35160: [16819, 23297, 16676, 16722, 16802, 16811, 16771, 16766, 16799, 16801],\n",
       " 35159: [16785, 18992, 17555, 16656, 19016, 16698, 16862, 16827, 21254, 29407],\n",
       " 35158: [16860, 16862, 16703, 16819, 16657, 16754, 16857, 16658, 16713, 16776],\n",
       " 35157: [16656, 16736, 16784, 16785, 16779, 16838, 16657, 16747, 16866, 16776],\n",
       " 35156: [16657, 17971, 16827, 16697, 16776, 16722, 16779, 16802, 29400, 16784],\n",
       " 35155: [16819, 17882, 17879, 17836, 17811, 17997, 17899, 17955, 17849, 18001],\n",
       " 35154: [16780, 16671, 16723, 16638, 16725, 16609, 16643, 16620, 16728, 16669],\n",
       " 35153: [16705, 16627, 16620, 16728, 16781, 16679, 16696, 16650, 16691, 16675],\n",
       " 35152: [16815, 16671, 16728, 16635, 16727, 16708, 16638, 16827, 16657, 16769],\n",
       " 35151: [16728, 16670, 16620, 16669, 16727, 16722, 16708, 16749, 16837, 16801],\n",
       " 35150: [16686, 16671, 16725, 16816, 16670, 16635, 18939, 16802, 16620, 16703],\n",
       " 35149: [17942, 18008, 17949, 16759, 17996, 25664, 33313, 19641, 13192, 16583],\n",
       " 35148: [16661, 16780, 16724, 16615, 16764, 16818, 16863, 16856, 16656, 16776],\n",
       " 35147: [18770, 16656, 16785, 16784, 16742, 16779, 16676, 16769, 16699, 16661],\n",
       " 35146: [33263, 17917, 15508, 26951, 17966, 32973, 8111, 16872, 16724, 16889],\n",
       " 35145: [15508, 19511, 19513, 35842, 16670, 28595, 16688, 16723, 33313, 16620],\n",
       " 35144: [35842, 17920, 16669, 8373, 32515, 32973, 16749, 20015, 18008, 33597],\n",
       " 35143: [26503, 27231, 20325, 22441, 22437, 24046, 23372, 15518, 22322, 27871],\n",
       " 35142: [29846, 31445, 31572, 19834, 19832, 29847, 19836, 19893, 20656, 29830],\n",
       " 35141: [27342, 37764, 26201, 36384, 18285, 28292, 37901, 24388, 35916, 35723],\n",
       " 35140: [28429, 28332, 37874, 36474, 37146, 36567, 37739, 37494, 36941, 35570],\n",
       " 35139: [27709, 34645, 28465, 20484, 27179, 20543, 37135, 26505, 37574, 20485],\n",
       " 35138: [28332, 36649, 37874, 36263, 27675, 37277, 36065, 37118, 36770, 36173],\n",
       " 35137: [36323, 36033, 37304, 35914, 36772, 36610, 35915, 36779, 35181, 36773],\n",
       " 35136: [26303, 17881, 26635, 26527, 26525, 20414, 27117, 27653, 20735, 26451],\n",
       " 35135: [27840, 27045, 26183, 27796, 35022, 32994, 34176, 31967, 28399, 31879],\n",
       " 35134: [26188, 25842, 27910, 20525, 16197, 25393, 27709, 16238, 16196, 27235],\n",
       " 35133: [20487, 35304, 27582, 30175, 31704, 28251, 37768, 33951, 38092, 32081],\n",
       " 35132: [31038, 27033, 37386, 37712, 27376, 36920, 36931, 37033, 14664, 35658],\n",
       " 35131: [30615, 35562, 20488, 36804, 30619, 30145, 26558, 26490, 30651, 31008],\n",
       " 35130: [34702, 19470, 14636, 20107, 34276, 26517, 20601, 20476, 26688, 15552],\n",
       " 35129: [31999, 22814, 20361, 27485, 22816, 22817, 22806, 19985, 22822, 19982],\n",
       " 35128: [37778, 26170, 37541, 26351, 37321, 28392, 28119, 33068, 36577, 26503],\n",
       " 35127: [28519, 37715, 37343, 28508, 37390, 37124, 36696, 36198, 37717, 19458],\n",
       " 35126: [31385, 27650, 34543, 27612, 36579, 28485, 21753, 35990, 35639, 29858],\n",
       " 35125: [20470, 32082, 20681, 31876, 35990, 31647, 36988, 36639, 20682, 20678],\n",
       " 35124: [27492, 20210, 32015, 28229, 10943, 36900, 26914, 27328, 20061, 34668],\n",
       " 35123: [29867, 29872, 29620, 23061, 17967, 17921, 29870, 29877, 29878, 16688],\n",
       " 35122: [37349, 36996, 36701, 34171, 37706, 37873, 34426, 35944, 20595, 14377],\n",
       " 35121: [28432, 34267, 35470, 27026, 24878, 25506, 27008, 34940, 34581, 35277],\n",
       " 35120: [33965, 27224, 31020, 26225, 34766, 20565, 33214, 33645, 28020, 28025],\n",
       " 35119: [37880, 19985, 28273, 28481, 19984, 31974, 37895, 27807, 19986, 37416],\n",
       " 35118: [26750, 28097, 27375, 27805, 27485, 27451, 26548, 24403, 37930, 36713],\n",
       " 35117: [26581, 36381, 27923, 24415, 26861, 35782, 27111, 27732, 27208, 27374],\n",
       " 35116: [25987, 25803, 24556, 33855, 24404, 26572, 22701, 27384, 26387, 33244],\n",
       " 35115: [26609, 24412, 25560, 26254, 27250, 25808, 25343, 26923, 25640, 35302],\n",
       " 35114: [18282, 26854, 24412, 36336, 36049, 20565, 37139, 26436, 27074, 20479],\n",
       " 35113: [26854, 27236, 20393, 31854, 20394, 19939, 26501, 27675, 31581, 3213],\n",
       " 35112: [23846, 25419, 23847, 35254, 25343, 24388, 35561, 26420, 25434, 25435],\n",
       " 35111: [27374, 27300, 27057, 28552, 36001, 26851, 37083, 24412, 20420, 28339],\n",
       " 35110: [26412, 28362, 27893, 37635, 27303, 25964, 35159, 24898, 24935, 27741],\n",
       " 35109: [32104, 19618, 32114, 30827, 16197, 20334, 31657, 31662, 25624, 31658],\n",
       " 35108: [28323, 28096, 27190, 38057, 28205, 28265, 27649, 36005, 37510, 37423],\n",
       " 35107: [34267, 34430, 31825, 36189, 26430, 34248, 35179, 24878, 36893, 27024],\n",
       " 35106: [33403, 36318, 7309, 25571, 31381, 26762, 24783, 25139, 33091, 19869],\n",
       " 35105: [28285, 27438, 27472, 33685, 31847, 26810, 36832, 31849, 21109, 33178],\n",
       " 35104: [26738, 15826, 26682, 26519, 20042, 27105, 25466, 26191, 33908, 26384],\n",
       " 35103: [26733, 15550, 27315, 19854, 32006, 26911, 33122, 27870, 28233, 22464],\n",
       " 35102: [16660, 16658, 16737, 16679, 16820, 16703, 16779, 16828, 16801, 16697],\n",
       " 35101: [18989, 21398, 29375, 29487, 19039, 15015, 18964, 21360, 22746, 21399],\n",
       " 35100: [35876, 28491, 29833, 32567, 35397, 26107, 20602, 29847, 26662, 33877],\n",
       " 35099: [32738, 25571, 25573, 25578, 25071, 37028, 24620, 25574, 25575, 34858],\n",
       " 35098: [25875, 25883, 16583, 25887, 22928, 8372, 16595, 31606, 16879, 8373],\n",
       " 35097: [14199, 26392, 35043, 36769, 16670, 19767, 20496, 19768, 18006, 31292],\n",
       " 35096: [18830, 18832, 22060, 22110, 22158, 18824, 22208, 28867, 17892, 22190],\n",
       " 35095: [22062, 18830, 18840, 22198, 22196, 22245, 22215, 17728, 22089, 22148],\n",
       " 35094: [18792, 23093, 23114, 22449, 17967, 31193, 22061, 22152, 29411, 31195],\n",
       " 35093: [16583, 17973, 16690, 19513, 17881, 15508, 17972, 17836, 17859, 17849],\n",
       " 35092: [30200, 17844, 17940, 17948, 17859, 17998, 17895, 17947, 17836, 17827],\n",
       " 35091: [17832, 17843, 17835, 17908, 17865, 17899, 17916, 17859, 17819, 17853],\n",
       " 35090: [16664, 16861, 16770, 16777, 16703, 16859, 30202, 16808, 16751, 16798],\n",
       " 35089: [28867, 18964, 28862, 28872, 21385, 28868, 19034, 17555, 21300, 18970],\n",
       " 35088: [18964, 29718, 16671, 29714, 21391, 16609, 18970, 29350, 16686, 16705],\n",
       " 35087: [19034, 18970, 18964, 21553, 29346, 21385, 17530, 17107, 18986, 17554],\n",
       " 35086: [36564, 36964, 20696, 20507, 28441, 31567, 28459, 28049, 27989, 37537],\n",
       " 35085: [37515, 30755, 25419, 37895, 36791, 36439, 33514, 28203, 27577, 37746],\n",
       " 35084: [26875, 28063, 27846, 28397, 27374, 27254, 27831, 27520, 26909, 25929],\n",
       " 35083: [20498, 38112, 37592, 37998, 32074, 27785, 35547, 27649, 35451, 26891],\n",
       " 35082: [35774, 34790, 27324, 36170, 25090, 26624, 37466, 37342, 26309, 25055],\n",
       " 35081: [28466, 28158, 28438, 28074, 28244, 14669, 28267, 37526, 28523, 36136],\n",
       " 35080: [20397, 20594, 25076, 27509, 34507, 14681, 28079, 24430, 37693, 31582],\n",
       " 35079: [31973, 27764, 28416, 31979, 28100, 31980, 37657, 19986, 19982, 31972],\n",
       " 35078: [32067, 20305, 26148, 36873, 25436, 37864, 25167, 36439, 25434, 25418],\n",
       " 35077: [36974, 27378, 20551, 36342, 26254, 24613, 28395, 28548, 35225, 11135],\n",
       " 35076: [28213, 36529, 37930, 28025, 27917, 27732, 31977, 19233, 28226, 20576],\n",
       " 35075: [20574, 20375, 27236, 20576, 28416, 14546, 21095, 36439, 27745, 25419],\n",
       " 35074: [28213, 27812, 28097, 27917, 36602, 35624, 36361, 35225, 28389, 36439],\n",
       " 35073: [37041, 36509, 27403, 27520, 25437, 24388, 38100, 27298, 25699, 2461],\n",
       " 35072: [22714, 29964, 15539, 15293, 17785, 21378, 17779, 22576, 22565, 22652],\n",
       " 35071: [32853, 24671, 19653, 27374, 20638, 36439, 35254, 25434, 20637, 25196],\n",
       " 35070: [17552, 17555, 21385, 21901, 21299, 17554, 18939, 19035, 18963, 29480],\n",
       " 35069: [17555, 18964, 19018, 19020, 19056, 18995, 29492, 19009, 19035, 29502],\n",
       " 35068: [16679, 16635, 16769, 16723, 16643, 18964, 16727, 16677, 16614, 29364],\n",
       " 35067: [19034, 18934, 29747, 29500, 19044, 21334, 18931, 19015, 19035, 18932],\n",
       " 35066: [34060, 25102, 26407, 22825, 22819, 27054, 35580, 26474, 34796, 26470],\n",
       " 35065: [30826, 30827, 14981, 8400, 24874, 24988, 26038, 31816, 24991, 28468],\n",
       " 35064: [27190, 37159, 27064, 37016, 26820, 36468, 26581, 28128, 24237, 37882],\n",
       " 35063: [33990, 25189, 14311, 24770, 14294, 16886, 19091, 24695, 19447, 19339],\n",
       " 35062: [28500, 37813, 26977, 35715, 20740, 37730, 35062, 36698, 26854, 35601],\n",
       " 35061: [37695, 37091, 38101, 11879, 10973, 10981, 37038, 37742, 20500, 20499],\n",
       " 35060: [37250, 33244, 35086, 32898, 25090, 32701, 37180, 36364, 35298, 30913],\n",
       " 35059: [37561, 20574, 27784, 37851, 37712, 37026, 38087, 36529, 14692, 28332],\n",
       " 35058: [37908, 38016, 27777, 38003, 37959, 37948, 37242, 27633, 20603, 37939],\n",
       " 35057: [27693, 38030, 37331, 26638, 36107, 27744, 14678, 27193, 25161, 34481],\n",
       " 35056: [26330, 28459, 26909, 34941, 27579, 26950, 36708, 34834, 36478, 25416],\n",
       " 35055: [36183, 26977, 20740, 27583, 20633, 36884, 26836, 27822, 37105, 36413],\n",
       " 35054: [27649, 14674, 27930, 36974, 37416, 37712, 36784, 36695, 31999, 36663],\n",
       " 35053: [19986, 20487, 27114, 20386, 20715, 8327, 33589, 19983, 20716, 34212],\n",
       " 35052: [20757, 20244, 31854, 36214, 20245, 27785, 20758, 34759, 24427, 24425],\n",
       " 35051: [28507, 28368, 28323, 28438, 28262, 37423, 18286, 37337, 28462, 28517],\n",
       " 35050: [28466, 28507, 28262, 20500, 28527, 37038, 27067, 37231, 28413, 34611],\n",
       " 35049: [33772, 34190, 30963, 26367, 33597, 20712, 33161, 32916, 32356, 30960],\n",
       " 35048: [35000, 35347, 35710, 35750, 30854, 26574, 35707, 34994, 31766, 35912],\n",
       " 35047: [37774, 25434, 35254, 36448, 36740, 37526, 37484, 25418, 27661, 27835],\n",
       " 35046: [14620, 37561, 27709, 28554, 20633, 28276, 14714, 37622, 27423, 37840],\n",
       " 35045: [28008, 26297, 26886, 14714, 27763, 37016, 3102, 27495, 25392, 28026],\n",
       " 35044: [20704, 20380, 14714, 27128, 20379, 35836, 28229, 37763, 31973, 37172],\n",
       " 35043: [31386, 37898, 26524, 26038, 33551, 25039, 25968, 30555, 26868, 34543],\n",
       " 35042: [27575, 36006, 20344, 24416, 37864, 28562, 37384, 14338, 37451, 37886],\n",
       " 35041: [36110, 14669, 28465, 20633, 27756, 28264, 27176, 27831, 28205, 27286],\n",
       " 35040: [36693, 14643, 28519, 36126, 36991, 37214, 27510, 37654, 37924, 37983],\n",
       " 35039: [24374, 20654, 14329, 30545, 30277, 14302, 30503, 14665, 25794, 24664],\n",
       " 35038: [38094, 14675, 25397, 20748, 28337, 18286, 28200, 35993, 30827, 34482],\n",
       " 35037: [32074, 28180, 37971, 26814, 28558, 28560, 36691, 33138, 33895, 26362],\n",
       " 35036: [30690, 31988, 18006, 16669, 28595, 15484, 16879, 17942, 20693, 17945],\n",
       " 35035: [30301, 25784, 26330, 8158, 24800, 25343, 23712, 26065, 25426, 30300],\n",
       " 35034: [27154, 36448, 20575, 38120, 37196, 37738, 37677, 20574, 27298, 24416],\n",
       " 35033: [14633, 26052, 27374, 36802, 27831, 27455, 27520, 27628, 37733, 25563],\n",
       " 35032: [27420, 27390, 27506, 27318, 26962, 28100, 27656, 28132, 32788, 26712],\n",
       " 35031: [20208, 37930, 27423, 27696, 35384, 27917, 27732, 28200, 28100, 37960],\n",
       " 35030: [26875, 24415, 38076, 25395, 27231, 24417, 31584, 27656, 14681, 27298],\n",
       " 35029: [31973, 31978, 27530, 14654, 31976, 28349, 27513, 19986, 31979, 37631],\n",
       " 35028: [27709, 27785, 28097, 28554, 27503, 34346, 27917, 37551, 20386, 28038],\n",
       " 35027: [20287, 14701, 27847, 26873, 20286, 24558, 24977, 14366, 27086, 26638],\n",
       " 35026: [26928, 20378, 25301, 28555, 37894, 20554, 20376, 25471, 37315, 27534],\n",
       " 35025: [14695, 26548, 27575, 20576, 36530, 31029, 20748, 31026, 31031, 31032],\n",
       " 35024: [14677, 20345, 28049, 25736, 36570, 37677, 28114, 25426, 25343, 36872],\n",
       " 35023: [35521, 31975, 14654, 31979, 19939, 24622, 20705, 20555, 31974, 20575],\n",
       " 35022: [20550, 20574, 27420, 27419, 28050, 28425, 27208, 20667, 26113, 36882],\n",
       " 35021: [36261, 14677, 36069, 26189, 37105, 35561, 37894, 26191, 35967, 37196],\n",
       " 35020: [23929, 25435, 23846, 26501, 23847, 25076, 25411, 23844, 37315, 20298],\n",
       " 35019: [20632, 28476, 25415, 25431, 28292, 27543, 20576, 20574, 20575, 25392],\n",
       " 35018: [25363, 20122, 27390, 37498, 14683, 36260, 37315, 34343, 26962, 38092],\n",
       " 35017: [37242, 37589, 26960, 37790, 20675, 35095, 37486, 26085, 37315, 37997],\n",
       " 35016: [28476, 37371, 34810, 37592, 27709, 37315, 37791, 35167, 28295, 28100],\n",
       " 35015: [28267, 37515, 27114, 27670, 31020, 37730, 26609, 37291, 37930, 14549],\n",
       " 35014: [20733, 36804, 38092, 30616, 27971, 36344, 30963, 27904, 30650, 31009],\n",
       " 35013: [27154, 37105, 37808, 20387, 20388, 37845, 32011, 20718, 20717, 20716],\n",
       " 35012: [27445, 28387, 28147, 28088, 26583, 14680, 14645, 36642, 34884, 34922],\n",
       " 35011: [37202, 27221, 26875, 26610, 26473, 27182, 20715, 20388, 32050, 20661],\n",
       " 35010: [36069, 27580, 25431, 27706, 15330, 19938, 25413, 36108, 19939, 32081],\n",
       " 35009: [20546, 26495, 27300, 37484, 37864, 27675, 27784, 37730, 37786, 35302],\n",
       " 35008: [37385, 36982, 36958, 37597, 36974, 37108, 35398, 37765, 37435, 37876],\n",
       " 35007: [36366, 20434, 14664, 36974, 36784, 27709, 36658, 35768, 37424, 27601],\n",
       " 35006: [34821, 20713, 27709, 36620, 35968, 35365, 14096, 27543, 27423, 28353],\n",
       " 35005: [37534, 37984, 37866, 27841, 28169, 37893, 27517, 20488, 37560, 35708],\n",
       " 35004: [27785, 27530, 35591, 36663, 27649, 36974, 37335, 36784, 14640, 24388],\n",
       " 35003: [20575, 24417, 26093, 25415, 37720, 24430, 27531, 25431, 27163, 35225],\n",
       " 35002: [37423, 36020, 37026, 28252, 36974, 37765, 36859, 37876, 27785, 37895],\n",
       " 35001: [27575, 21717, 36361, 27859, 26875, 36602, 27172, 28292, 27517, 27784],\n",
       " 35000: [37014, 14462, 35218, 26105, 32453, 34805, 24287, 36467, 35016, 32061],\n",
       " 34999: [35654, 33126, 28200, 14462, 38092, 35240, 37368, 36803, 20705, 33847],\n",
       " 34998: [26835, 27675, 37432, 36205, 27735, 37592, 37014, 27807, 14462, 27356],\n",
       " 34997: [28476, 27783, 33174, 36364, 27456, 27626, 36508, 37291, 14462, 33364],\n",
       " 34996: [20632, 26105, 27935, 36803, 27607, 30907, 27675, 27304, 36612, 28354],\n",
       " 34995: [27236, 36361, 20670, 20574, 20714, 27760, 31026, 27709, 26977, 20388],\n",
       " 34994: [26950, 27647, 27416, 26425, 20575, 34834, 37105, 26619, 37845, 36004],\n",
       " 34993: [28177, 28368, 15326, 26901, 38036, 28323, 28262, 14369, 37423, 36852],\n",
       " 34992: [25417, 25435, 25402, 26651, 25392, 27074, 36282, 14215, 25437, 25343],\n",
       " 34991: [15326, 31717, 27763, 20527, 31892, 25426, 24389, 25411, 35380, 35069],\n",
       " 34990: [35774, 31884, 20031, 31880, 36580, 20339, 20457, 20338, 20456, 20731],\n",
       " 34989: [33655, 14636, 26390, 34399, 34342, 36061, 36557, 35650, 24416, 27009],\n",
       " 34988: [37595, 37958, 20154, 38081, 37983, 37120, 37308, 37579, 36928, 33646],\n",
       " 34987: [35876, 27258, 37476, 37744, 34940, 36652, 35084, 27026, 35906, 37372],\n",
       " 34986: [33825, 28432, 34399, 33873, 35277, 35899, 34749, 35951, 26397, 34732],\n",
       " 34985: [36008, 35992, 34578, 33358, 26430, 35397, 35876, 35404, 34686, 36849],\n",
       " 34984: [25564, 26397, 27008, 35749, 26314, 35579, 28064, 27024, 24877, 26822],\n",
       " 34983: [36839, 37388, 36693, 35777, 36905, 36458, 37565, 37858, 36591, 28454],\n",
       " 34982: [27497, 34524, 26368, 24465, 35801, 35357, 28499, 35084, 20107, 35397],\n",
       " 34981: [34212, 27445, 20393, 37882, 37081, 20566, 28260, 25970, 28389, 35174],\n",
       " 34980: [28260, 26581, 37959, 28187, 28540, 27143, 27591, 28525, 37033, 35601],\n",
       " 34979: [26276, 37992, 27619, 27709, 28353, 37886, 27242, 28100, 36583, 37042],\n",
       " 34978: [37729, 14654, 31567, 20644, 34658, 28554, 20523, 27709, 27423, 27614],\n",
       " 34977: [34064, 27908, 36814, 14676, 36150, 26918, 24742, 27601, 34602, 34860],\n",
       " 34976: [36405, 36806, 25966, 27812, 36150, 32643, 38058, 34507, 36931, 24429],\n",
       " 34975: [20324, 26811, 20326, 28162, 26013, 28119, 35217, 22826, 37985, 35396],\n",
       " 34974: [25224, 33863, 29029, 27216, 28212, 17964, 37498, 32719, 27915, 25637],\n",
       " 34973: [28126, 36702, 37827, 37592, 27540, 28555, 37791, 37998, 28260, 14640],\n",
       " 34972: [20593, 26712, 30169, 35307, 28219, 28389, 28337, 36720, 27537, 34232],\n",
       " 34971: [36336, 25415, 36934, 25431, 27575, 26727, 36697, 28226, 36123, 36069],\n",
       " 34970: [32226, 28100, 28048, 31994, 32001, 31999, 27239, 27709, 14613, 38021],\n",
       " 34969: [35928, 37989, 27345, 27216, 27943, 28561, 27191, 37740, 28281, 37246],\n",
       " 34968: [36249, 35882, 36452, 14090, 26606, 35438, 37579, 37748, 37215, 14643],\n",
       " 34967: [27739, 35988, 37792, 28068, 37853, 37579, 26906, 37776, 37344, 26390],\n",
       " 34966: [32082, 20684, 20469, 28132, 37908, 31033, 37997, 37851, 28470, 14671],\n",
       " 34965: [37039, 28363, 36816, 35127, 35175, 38019, 37833, 26919, 26015, 37345],\n",
       " 34964: [28443, 27859, 35624, 14664, 36655, 36405, 37291, 37424, 37017, 27393],\n",
       " 34963: [37681, 33724, 34896, 27908, 31979, 28504, 36984, 37774, 27989, 28349],\n",
       " 34962: [26394, 20340, 26395, 20731, 36105, 33780, 27264, 27004, 32550, 36860],\n",
       " 34961: [27191, 28126, 37827, 20752, 27199, 28334, 12829, 20526, 20606, 37866],\n",
       " 34960: [27732, 25416, 20575, 37575, 28106, 36463, 20576, 25423, 37763, 27377],\n",
       " 34959: [27910, 26188, 27374, 34714, 27375, 37380, 20511, 36530, 20530, 36463],\n",
       " 34958: [14654, 20137, 20608, 37845, 27583, 28500, 26977, 20740, 20479, 36129],\n",
       " 34957: [20574, 37515, 20724, 37713, 27378, 20723, 31031, 37793, 27768, 38039],\n",
       " 34956: [20723, 34902, 36844, 25392, 20725, 36070, 38045, 12565, 36636, 28282],\n",
       " 34955: [20388, 20715, 37515, 36005, 26610, 20724, 36873, 28273, 20386, 25432],\n",
       " 34954: [37387, 20633, 20724, 28077, 27935, 27607, 37675, 36020, 19939, 27304],\n",
       " 34953: [27427, 31581, 20576, 26590, 27298, 35088, 36750, 37808, 37497, 31584],\n",
       " 34952: [27575, 14654, 20392, 28226, 38069, 28531, 37763, 14338, 28455, 21096],\n",
       " 34951: [37058, 27313, 20724, 20723, 26559, 28097, 26225, 26827, 14683, 37217],\n",
       " 34950: [26810, 27407, 35556, 37058, 20723, 37168, 20637, 31979, 26969, 27067],\n",
       " 34949: [28527, 37640, 26410, 35160, 20723, 28480, 38115, 35302, 20615, 37337],\n",
       " 34948: [28438, 37423, 37178, 20724, 20575, 28364, 20723, 28281, 37984, 27750],\n",
       " 34947: [28509, 28158, 28459, 36919, 34343, 37813, 35919, 36260, 35911, 20125],\n",
       " 34946: [20574, 20576, 31975, 19986, 31977, 14338, 21096, 38092, 36872, 36064],\n",
       " 34945: [20575, 27236, 20566, 28226, 31977, 31973, 26750, 19983, 26254, 31972],\n",
       " 34944: [37527, 31350, 20574, 37713, 20576, 37984, 28333, 34791, 24416, 20725],\n",
       " 34943: [34767, 28428, 28251, 20712, 36402, 30037, 27989, 38092, 37721, 20733],\n",
       " 34942: [28164, 27575, 37432, 34623, 37530, 35967, 28441, 37791, 31994, 27756],\n",
       " 34941: [31678, 31722, 37851, 35556, 20634, 20576, 28260, 38073, 31978, 31679],\n",
       " 34940: [25102, 28172, 28301, 37026, 27588, 28129, 28267, 37130, 28097, 26653],\n",
       " 34939: [36582, 28077, 28208, 38107, 37491, 20485, 28158, 20739, 19938, 20210],\n",
       " 34938: [27201, 32081, 36804, 37667, 36402, 37254, 26754, 20777, 37768, 35562],\n",
       " 34937: [30331, 20705, 20392, 28292, 27675, 37451, 37725, 25431, 25392, 30855],\n",
       " 34936: [27295, 27445, 28180, 36373, 20713, 27831, 28400, 37217, 36798, 37531],\n",
       " 34935: [27154, 28349, 36397, 37526, 27439, 37845, 27403, 26936, 27561, 36904],\n",
       " 34934: [28476, 31978, 36261, 31980, 37677, 37737, 28104, 27647, 28349, 37551],\n",
       " 34933: [37289, 37578, 37711, 26820, 19939, 28100, 37791, 14632, 36583, 28137],\n",
       " 34932: [20575, 32068, 20137, 20594, 14654, 37534, 20344, 14579, 27298, 38115],\n",
       " 34931: [31765, 28368, 37423, 27709, 36919, 28438, 32041, 28353, 27423, 28459],\n",
       " 34930: [37462, 37026, 37432, 37960, 36781, 28089, 14680, 38087, 36248, 28402],\n",
       " 34929: [31763, 35625, 36210, 19467, 19253, 25962, 12060, 17399, 31699, 35156],\n",
       " 34928: [29847, 14689, 37717, 27164, 23677, 37412, 31574, 37850, 37861, 27983],\n",
       " 34927: [35370, 36126, 28374, 27497, 27510, 14636, 37792, 26688, 35531, 27255],\n",
       " 34926: [35468, 34211, 36703, 34290, 34783, 20105, 34851, 14260, 35169, 20476],\n",
       " 34925: [28454, 27164, 34332, 35992, 28432, 33785, 35397, 36849, 37023, 36178],\n",
       " 34924: [36800, 34372, 33751, 37215, 36629, 14482, 34382, 14418, 33831, 36238],\n",
       " 34923: [37388, 26606, 34795, 26944, 24246, 28331, 35229, 20107, 35932, 25210],\n",
       " 34922: [36529, 36362, 28065, 27785, 36784, 27649, 38013, 37712, 28518, 37105],\n",
       " 34921: [37026, 30872, 28106, 27580, 14546, 31979, 31976, 31975, 28268, 27701],\n",
       " 34920: [28401, 28282, 37041, 28049, 37813, 37178, 26559, 37793, 37816, 28364],\n",
       " 34919: [38094, 30808, 37537, 27696, 27732, 37712, 37416, 37720, 28203, 20713],\n",
       " 34918: [27575, 31563, 28309, 26422, 27805, 25389, 27495, 27607, 36383, 36554],\n",
       " 34917: [31565, 26424, 27750, 38030, 37798, 22783, 20125, 35308, 37525, 35850],\n",
       " 34916: [37108, 27079, 26597, 28200, 28097, 36740, 37863, 28025, 28226, 37490],\n",
       " 34915: [19939, 35521, 34397, 34631, 28436, 15966, 20375, 15330, 27552, 24405],\n",
       " 34914: [37289, 35879, 36616, 20635, 27756, 37718, 36499, 37561, 28294, 28180],\n",
       " 34913: [28476, 37791, 37041, 36069, 28554, 27709, 27423, 37832, 20575, 27723],\n",
       " 34912: [27760, 28053, 20739, 27647, 26619, 37886, 27744, 28104, 36570, 28323],\n",
       " 34911: [20575, 24575, 27675, 27111, 27231, 25423, 20675, 37530, 27067, 27575],\n",
       " 34910: [37840, 37259, 37592, 35793, 37791, 36368, 37763, 28260, 20675, 37845],\n",
       " 34909: [20388, 20714, 27163, 28226, 28415, 25435, 25436, 20305, 20715, 25437],\n",
       " 34908: [27616, 20632, 37472, 26436, 36948, 34470, 36714, 38057, 28549, 36726],\n",
       " 34907: [27525, 28078, 28441, 20575, 27458, 37793, 28333, 36729, 20574, 25591],\n",
       " 34906: [34573, 20632, 37998, 20575, 28333, 28562, 20576, 37335, 37793, 28516],\n",
       " 34905: [36394, 37108, 37622, 37840, 36872, 20727, 19939, 19938, 26886, 20344],\n",
       " 34904: [27888, 20633, 20632, 36272, 35780, 37960, 36529, 35193, 38118, 27675],\n",
       " 34903: [31725, 34561, 35393, 20397, 31723, 28479, 27337, 31181, 31179, 26429],\n",
       " 34902: [27888, 37774, 28065, 36107, 20766, 37640, 27027, 37526, 37990, 37716],\n",
       " 34901: [28476, 37791, 20575, 37335, 37998, 26559, 26269, 27289, 28397, 20725],\n",
       " 34900: [31350, 24993, 27636, 28292, 24415, 25908, 34810, 27665, 35715, 20748],\n",
       " 34899: [19938, 19936, 28441, 32068, 27844, 27750, 31980, 25406, 19935, 20705],\n",
       " 34898: [31989, 36616, 27610, 26960, 31336, 33983, 35365, 27835, 26476, 33227],\n",
       " 34897: [30950, 30951, 36737, 37319, 36546, 26827, 24774, 37454, 36370, 24638],\n",
       " 34896: [20494, 26960, 27270, 25352, 37636, 27543, 28555, 27720, 23712, 34397],\n",
       " 34895: [28442, 36230, 28364, 37731, 20576, 37510, 37727, 26818, 32009, 37168],\n",
       " 34894: [26688, 14636, 37206, 36233, 36800, 24629, 34332, 27009, 36061, 25546],\n",
       " 34893: [35185, 31612, 28071, 31577, 34226, 19475, 19477, 19588, 33785, 20645],\n",
       " 34892: [20015, 35187, 35771, 37715, 26944, 26688, 15552, 35179, 27864, 28071],\n",
       " 34891: [28374, 28310, 37062, 34067, 26944, 33358, 26688, 34382, 32832, 27255],\n",
       " 34890: [24878, 26797, 26430, 26944, 27008, 35169, 19458, 36830, 35579, 26688],\n",
       " 34889: [33197, 23677, 26688, 26944, 36340, 36178, 24629, 36841, 36597, 37353],\n",
       " 34888: [14182, 34399, 25564, 34940, 37088, 37785, 36297, 35988, 36980, 14689],\n",
       " 34887: [26390, 37206, 35370, 25210, 27510, 19458, 27759, 35412, 37621, 34342],\n",
       " 34886: [28547, 38081, 28304, 26688, 37344, 37206, 37390, 35283, 25564, 37540],\n",
       " 34885: [27864, 27739, 37120, 28083, 26932, 35876, 27726, 32038, 26944, 35650],\n",
       " 34884: [36233, 37620, 36676, 25884, 35370, 36505, 37206, 37995, 36346, 27157],\n",
       " 34883: [27487, 20705, 36749, 27242, 28224, 36342, 20500, 27047, 20498, 24192],\n",
       " 34882: [27616, 27280, 28482, 28222, 21111, 14596, 34253, 28503, 28205, 28518],\n",
       " 34881: [36806, 36570, 27647, 26332, 36261, 37466, 37561, 25343, 37513, 25639],\n",
       " 34880: [20575, 27744, 37466, 14682, 37315, 34135, 20576, 34857, 37016, 20498],\n",
       " 34879: [36840, 20704, 25416, 27530, 36784, 14567, 27709, 27423, 36480, 14682],\n",
       " 34878: [26664, 27469, 24885, 27140, 26330, 26163, 33480, 20469, 35428, 25515],\n",
       " 34877: [25286, 20412, 27785, 27349, 25465, 14682, 35253, 25415, 27649, 25466],\n",
       " 34876: [27137, 26918, 20574, 36129, 28097, 27777, 20576, 27143, 26851, 28187],\n",
       " 34875: [27193, 37515, 28213, 27917, 27135, 27732, 27723, 14682, 37725, 20748],\n",
       " 34874: [28349, 27622, 37561, 28194, 37895, 31966, 35939, 38115, 31967, 28524],\n",
       " 34873: [25365, 28100, 27505, 25413, 34397, 20479, 25406, 26918, 27768, 34997],\n",
       " 34872: [26962, 14683, 20633, 28337, 19939, 28137, 35157, 27756, 35952, 25049],\n",
       " 34871: [20338, 35601, 28500, 20731, 36884, 26516, 20740, 20698, 3108, 27608],\n",
       " 34870: [35889, 19629, 26597, 25039, 14502, 14663, 26018, 27892, 36650, 28279],\n",
       " 34869: [36738, 37940, 36844, 27345, 36866, 28561, 37525, 37989, 35548, 38106],\n",
       " 34868: [28262, 20575, 14615, 14671, 31034, 26909, 37423, 27443, 27693, 31028],\n",
       " 34867: [27485, 28507, 27047, 33961, 33976, 24575, 26922, 20481, 27616, 20290],\n",
       " 34866: [28549, 28088, 20576, 20633, 36642, 27744, 27959, 37925, 37331, 37664],\n",
       " 34865: [14654, 20723, 31020, 37665, 28537, 26085, 28200, 37763, 26214, 37903],\n",
       " 34864: [36750, 31580, 31581, 31585, 28275, 14621, 26886, 37148, 25582, 27365],\n",
       " 34863: [28264, 28260, 28275, 37832, 14645, 37864, 28549, 35793, 37782, 28128],\n",
       " 34862: [37712, 37998, 28164, 28275, 27675, 37960, 37622, 28252, 37807, 37840],\n",
       " 34861: [27403, 27583, 35734, 35520, 36129, 14621, 20551, 14714, 37864, 27143],\n",
       " 34860: [20575, 31582, 31580, 28275, 35307, 37479, 27721, 20209, 28549, 36993],\n",
       " 34859: [36069, 36409, 20576, 20740, 27143, 28147, 36884, 28294, 37845, 26851],\n",
       " 34858: [28275, 27917, 32050, 37041, 20485, 27625, 15966, 35521, 32063, 27812],\n",
       " 34857: [28549, 27580, 28554, 27723, 27709, 35366, 20575, 20484, 31726, 27423],\n",
       " 34856: [38093, 36699, 37139, 27057, 28285, 27963, 37083, 38010, 37001, 31797],\n",
       " 34855: [28549, 37880, 27588, 26342, 37432, 28267, 38094, 28349, 26126, 28158],\n",
       " 34854: [32069, 20748, 37472, 27783, 14645, 36642, 27926, 38057, 14680, 36781],\n",
       " 34853: [20485, 28476, 19234, 37925, 36781, 19232, 37331, 14645, 28517, 14680],\n",
       " 34852: [36993, 20574, 37428, 37329, 35653, 31020, 31947, 20567, 20566, 14579],\n",
       " 34851: [36806, 37108, 20632, 27575, 31021, 28476, 26977, 27783, 27723, 28275],\n",
       " 34850: [36726, 28052, 14621, 14680, 37832, 28441, 28402, 28104, 37737, 36247],\n",
       " 34849: [35841, 36950, 37012, 27723, 28275, 20484, 36682, 37883, 24958, 24553],\n",
       " 34848: [37882, 31585, 31582, 26809, 31580, 31581, 28088, 26126, 24416, 31586],\n",
       " 34847: [26960, 37472, 27771, 27693, 37925, 14645, 36863, 25140, 35012, 34415],\n",
       " 34846: [36570, 20499, 27831, 20498, 28264, 28065, 24192, 37038, 36881, 28205],\n",
       " 34845: [37888, 36726, 37832, 14677, 38066, 28441, 37634, 28077, 28275, 37535],\n",
       " 34844: [31327, 37481, 17313, 27654, 28158, 37499, 28349, 28177, 20499, 28456],\n",
       " 34843: [36123, 28409, 37105, 37723, 28476, 20696, 28053, 28416, 36373, 28275],\n",
       " 34842: [28158, 37882, 14621, 28334, 28241, 36383, 37315, 37310, 26369, 37622],\n",
       " 34841: [31382, 36961, 31385, 28104, 26501, 31021, 20124, 28288, 36761, 34543],\n",
       " 34840: [36948, 28275, 28496, 28049, 36480, 14680, 28402, 28200, 36642, 37882],\n",
       " 34839: [37331, 14621, 27693, 36247, 36107, 38045, 28128, 28357, 37664, 28298],\n",
       " 34838: [38117, 37561, 37895, 27580, 28252, 37925, 37331, 37960, 38094, 28273],\n",
       " 34837: [28459, 37081, 28264, 26163, 27140, 37371, 28275, 27811, 28169, 35708],\n",
       " 34836: [20574, 28549, 36069, 36397, 25077, 20344, 27917, 14338, 28226, 21096],\n",
       " 34835: [28275, 36726, 37925, 28402, 36642, 20633, 27709, 37832, 37882, 28476],\n",
       " 34834: [36150, 27374, 23846, 27579, 14714, 20305, 26959, 11134, 28275, 36957],\n",
       " 34833: [36988, 27774, 32082, 21826, 36781, 14462, 21717, 35654, 20679, 36895],\n",
       " 34832: [27830, 28285, 26766, 24237, 31606, 34225, 31968, 27423, 32666, 26664],\n",
       " 34831: [20757, 33706, 20756, 20754, 20295, 20073, 34352, 33717, 31879, 20296],\n",
       " 34830: [25851, 14620, 28063, 37832, 36616, 38038, 27140, 26163, 37723, 36948],\n",
       " 34829: [23175, 28436, 24382, 28126, 31383, 37530, 24384, 31386, 36992, 28550],\n",
       " 34828: [28368, 20638, 14620, 20617, 20705, 38027, 37423, 28344, 20210, 28490],\n",
       " 34827: [20484, 27830, 28456, 28554, 37472, 36714, 38087, 37521, 37156, 36546],\n",
       " 34826: [31567, 27575, 20608, 27912, 31581, 28353, 27208, 31580, 26712, 35302],\n",
       " 34825: [35742, 35914, 28355, 35557, 35050, 36323, 37758, 36324, 36089, 36878],\n",
       " 34824: [27599, 38044, 28256, 32068, 37462, 28172, 27967, 38042, 26188, 34972],\n",
       " 34823: [24993, 26501, 27172, 14317, 25563, 24405, 19964, 25436, 26886, 25417],\n",
       " 34822: [28549, 26387, 31034, 31027, 37930, 14615, 27723, 31028, 27290, 37310],\n",
       " 34821: [37289, 28132, 37592, 37998, 31033, 31035, 31029, 14671, 27110, 27420],\n",
       " 34820: [38119, 28474, 14671, 26835, 28413, 26379, 26861, 28323, 28368, 27978],\n",
       " 34819: [28353, 28038, 25431, 27106, 37472, 36714, 25415, 37920, 37960, 27709],\n",
       " 34818: [25362, 31027, 26541, 14676, 31029, 26254, 20125, 31026, 31032, 31978],\n",
       " 34817: [31034, 28438, 31027, 37423, 14671, 31025, 31030, 14588, 26379, 37337],\n",
       " 34816: [20483, 31563, 24416, 31031, 31035, 38039, 31033, 20575, 38119, 37521],\n",
       " 34815: [37105, 31034, 31025, 31027, 26886, 37960, 37712, 31032, 26505, 31035],\n",
       " 34814: [26712, 31027, 31032, 31035, 14714, 20511, 14671, 28108, 28097, 31028],\n",
       " 34813: [38039, 36439, 25418, 30301, 25432, 25661, 14626, 26420, 26379, 14659],\n",
       " 34812: [36608, 26040, 20633, 31034, 27675, 28050, 14623, 20638, 31035, 27231],\n",
       " 34811: [28474, 31033, 28476, 14671, 31032, 31028, 26379, 31035, 38039, 37315],\n",
       " 34810: [28527, 28262, 31029, 28438, 31035, 31034, 14615, 38039, 14671, 31028],\n",
       " 34809: [20638, 36397, 14680, 20377, 36642, 28402, 28088, 37925, 32068, 20378],\n",
       " 34808: [27649, 27709, 28287, 34674, 14612, 33965, 28137, 36397, 31980, 31977],\n",
       " 34807: [35458, 26486, 34812, 28174, 26993, 27113, 30851, 28492, 19990, 30808],\n",
       " 34806: [27831, 36463, 20633, 37870, 36214, 37241, 28476, 28264, 36840, 25608],\n",
       " 34805: [31034, 31026, 37178, 20575, 36844, 37882, 14615, 36708, 28282, 14671],\n",
       " 34804: [24991, 26480, 24949, 37075, 14582, 36021, 25953, 14563, 28390, 33778],\n",
       " 34803: [26963, 25136, 27001, 35527, 26661, 19718, 37834, 31725, 35422, 26336],\n",
       " 34802: [27739, 26698, 26016, 27026, 33785, 28499, 35330, 36017, 37222, 36755],\n",
       " 34801: [27624, 37062, 30980, 35229, 26932, 27510, 36178, 27890, 38056, 28458],\n",
       " 34800: [26794, 36863, 23840, 14681, 27216, 20686, 35253, 27520, 37498, 14623],\n",
       " 34799: [26959, 31854, 37022, 26909, 27541, 27917, 28108, 37622, 28097, 37153],\n",
       " 34798: [26298, 25415, 23712, 21095, 32655, 32812, 27709, 25435, 25392, 28020],\n",
       " 34797: [26107, 36538, 27892, 26427, 33271, 36593, 27814, 25496, 14663, 14572],\n",
       " 34796: [26194, 35149, 14602, 35773, 33947, 20462, 33626, 36637, 33428, 20305],\n",
       " 34795: [26522, 36637, 37930, 26509, 31020, 26528, 14598, 26085, 27917, 28306],\n",
       " 34794: [31606, 26794, 36069, 27647, 27345, 19939, 37105, 27724, 31881, 35587],\n",
       " 34793: [32067, 20632, 36806, 34212, 27452, 27723, 32069, 28476, 26254, 27231],\n",
       " 34792: [27583, 28250, 25392, 20387, 28029, 31885, 31884, 24800, 25187, 31887],\n",
       " 34791: [26207, 20723, 31021, 27300, 20546, 37484, 26992, 31581, 20547, 14579],\n",
       " 34790: [20575, 27300, 25426, 27225, 25943, 25434, 26946, 33432, 25418, 25417],\n",
       " 34789: [20684, 20681, 26505, 36988, 32082, 27495, 20305, 36381, 32048, 26422],\n",
       " 34788: [37120, 27790, 36144, 37149, 35882, 36665, 36226, 35650, 37748, 26606],\n",
       " 34787: [24922, 26084, 24936, 14411, 25962, 24935, 26894, 35509, 26904, 37807],\n",
       " 34786: [31372, 32597, 35453, 11245, 10520, 19767, 20496, 19766, 31373, 5651],\n",
       " 34785: [28364, 28368, 28262, 31035, 31034, 26697, 14593, 37880, 31027, 38119],\n",
       " 34784: [14593, 31026, 27760, 27427, 14627, 38039, 14625, 26541, 26254, 14544],\n",
       " 34783: [31033, 31035, 14625, 14623, 14588, 31025, 14659, 20316, 26262, 14544],\n",
       " 34782: [14590, 31994, 37416, 19899, 20576, 19900, 31027, 19869, 14659, 14588],\n",
       " 34781: [31029, 14615, 31035, 14544, 31032, 38039, 26379, 14588, 20530, 31028],\n",
       " 34780: [27626, 36151, 32158, 14671, 31033, 38119, 31031, 31032, 14615, 31034],\n",
       " 34779: [14591, 31027, 24993, 27374, 31032, 31035, 20594, 21717, 37290, 14544],\n",
       " 34778: [14627, 14623, 19938, 27530, 37720, 32048, 14671, 14544, 27709, 14588],\n",
       " 34777: [14625, 31028, 14588, 14544, 14651, 14430, 38099, 26686, 26541, 14646],\n",
       " 34776: [31027, 31032, 38039, 14588, 14544, 31028, 38119, 31025, 26379, 14651],\n",
       " 34775: [26697, 14430, 31035, 31026, 31029, 14588, 38039, 14544, 20575, 25419],\n",
       " 34774: [14671, 14591, 14626, 26697, 38039, 38119, 14588, 31025, 14659, 14544],\n",
       " 34773: [31029, 14623, 14588, 14659, 14544, 31025, 26379, 31030, 14651, 14430],\n",
       " 34772: [31029, 14615, 14591, 14593, 14659, 26379, 31028, 14544, 14588, 31030],\n",
       " 34771: [36595, 38119, 14659, 34119, 31028, 14588, 14544, 31025, 26379, 35830],\n",
       " 34770: [31033, 14625, 31027, 38119, 31028, 14659, 14588, 28368, 28323, 14544],\n",
       " 34769: [14593, 31034, 31035, 14623, 14588, 14659, 14544, 31030, 14651, 26686],\n",
       " 34768: [14625, 31028, 14544, 14588, 31025, 31030, 38099, 14651, 26379, 26686],\n",
       " 34767: [14590, 38039, 31034, 28523, 28504, 31025, 37908, 26541, 14588, 14659],\n",
       " 34766: [31033, 31026, 38039, 14590, 14659, 31028, 14588, 14544, 31025, 31030],\n",
       " 34765: [31996, 26709, 27917, 14591, 31034, 31994, 14615, 31031, 33355, 27732],\n",
       " 34764: [31027, 14615, 14659, 31028, 31025, 14588, 14544, 31030, 14651, 26379],\n",
       " 34763: [14627, 31026, 31996, 14626, 31032, 31993, 36694, 38039, 14623, 31027],\n",
       " 34762: [14591, 31034, 31027, 31035, 36844, 38119, 14544, 28472, 28282, 14588],\n",
       " 34761: [37116, 35928, 27345, 27943, 28349, 33963, 20667, 37463, 37774, 27172],\n",
       " 34760: [28282, 36504, 35548, 37287, 38013, 27689, 27420, 36174, 27419, 14544],\n",
       " 34759: [28405, 27462, 28368, 20574, 14544, 26715, 25471, 25286, 20576, 28479],\n",
       " 34758: [27784, 14544, 23929, 27030, 27772, 27163, 11078, 34409, 27137, 12458],\n",
       " 34757: [27037, 14544, 20705, 26619, 35302, 27170, 19967, 25415, 26188, 27910],\n",
       " 34756: [31033, 14615, 26697, 14627, 14625, 14544, 31032, 31025, 31035, 38039],\n",
       " 34755: [27706, 14544, 26351, 34791, 31033, 14671, 25431, 14626, 38039, 31032],\n",
       " 34754: [21728, 27135, 24427, 34941, 21730, 24425, 20494, 24428, 14519, 14521],\n",
       " 34753: [30950, 35414, 30952, 37065, 19731, 30954, 37454, 30956, 31581, 37497],\n",
       " 34752: [30951, 30950, 26856, 37454, 30954, 27466, 24836, 28147, 36039, 20532],\n",
       " 34751: [37042, 38115, 20343, 25643, 19254, 37432, 24427, 36103, 26859, 26923],\n",
       " 34750: [14639, 20727, 36570, 27677, 28023, 31021, 27852, 14338, 27661, 25428],\n",
       " 34749: [19868, 19898, 31985, 37396, 28117, 28024, 36291, 19731, 27187, 37729],\n",
       " 34748: [37428, 26682, 32074, 14563, 32055, 34641, 36308, 32056, 34482, 28048],\n",
       " 34747: [35654, 28110, 14462, 35218, 25545, 26963, 30780, 14582, 35435, 36579],\n",
       " 34746: [35270, 27390, 14563, 28048, 24949, 20499, 36708, 26285, 26330, 37350],\n",
       " 34745: [36463, 14563, 37241, 26354, 25187, 25797, 14567, 14613, 26172, 27517],\n",
       " 34744: [14613, 26351, 14563, 20315, 31723, 35527, 31725, 20317, 27001, 27607],\n",
       " 34743: [14690, 27231, 28014, 31725, 14563, 34135, 28192, 27032, 31973, 27675],\n",
       " 34742: [25369, 33650, 20500, 28353, 20386, 28004, 27632, 20714, 37038, 20715],\n",
       " 34741: [27304, 26861, 26759, 27001, 25365, 27040, 25369, 27652, 14490, 25413],\n",
       " 34740: [26891, 20575, 35435, 26861, 26424, 26619, 25417, 14546, 27110, 35451],\n",
       " 34739: [27356, 20511, 19967, 31581, 34573, 37604, 19938, 14654, 27505, 27878],\n",
       " 34738: [36608, 28389, 27675, 20748, 20574, 20575, 28200, 28537, 14498, 30775],\n",
       " 34737: [28158, 31021, 20485, 37790, 37997, 32057, 20484, 28281, 37589, 38016],\n",
       " 34736: [27375, 20574, 20576, 14654, 37763, 20723, 28200, 20767, 14498, 14486],\n",
       " ...}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_prediction_dict = decode_predictions(\n",
    "    submission_dataframe[categorical_training_dataframe.columns.drop(\"Label\")],\n",
    "    XGB_model,\n",
    "    drop_ids=False,\n",
    ")\n",
    "submission_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_recommendation(recommendation: list[str]) -> str:\n",
    "    return \" \".join([str(item) for item in recommendation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7547 572 14888 1425 7703 9911 8505 14931 11966...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6348 13766 14748 13733 11875 11149 15600 18964...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>22714 29656 29964 22589 22625 16255 29963 1938...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25079 25140 6827 25643 9742 11753 23712 3207 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17624 9812 9447 8612 15902 18304 18647 3454 26...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34226</th>\n",
       "      <td>35729</td>\n",
       "      <td>36844 35548 26093 36527 27531 37461 26794 3656...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34227</th>\n",
       "      <td>35730</td>\n",
       "      <td>28247 38027 37874 37719 37739 33330 27350 3711...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34228</th>\n",
       "      <td>35731</td>\n",
       "      <td>37739 36263 35394 36173 38027 37427 36525 3804...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34229</th>\n",
       "      <td>35734</td>\n",
       "      <td>37069 36168 36610 35345 37067 37550 36094 3509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34230</th>\n",
       "      <td>35735</td>\n",
       "      <td>36034 36493 37445 36773 37657 37660 36917 3692...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34231 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                                          item_list\n",
       "0            0  7547 572 14888 1425 7703 9911 8505 14931 11966...\n",
       "1            1  6348 13766 14748 13733 11875 11149 15600 18964...\n",
       "2            2  22714 29656 29964 22589 22625 16255 29963 1938...\n",
       "3            3  25079 25140 6827 25643 9742 11753 23712 3207 3...\n",
       "4            4  17624 9812 9447 8612 15902 18304 18647 3454 26...\n",
       "...        ...                                                ...\n",
       "34226    35729  36844 35548 26093 36527 27531 37461 26794 3656...\n",
       "34227    35730  28247 38027 37874 37719 37739 33330 27350 3711...\n",
       "34228    35731  37739 36263 35394 36173 38027 37427 36525 3804...\n",
       "34229    35734  37069 36168 36610 35345 37067 37550 36094 3509...\n",
       "34230    35735  36034 36493 37445 36773 37657 37660 36917 3692...\n",
       "\n",
       "[34231 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"item_list\"] = [\n",
    "    encode_recommendation(recommendation)\n",
    "    for recommendation in pd.Series(submission_prediction_dict).loc[test_df[\"user_id\"]]\n",
    "]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(SUBMISSION_PATH, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
