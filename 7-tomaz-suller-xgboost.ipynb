{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to use XGBoost in RecSys\n",
    "* Run your best algorithm and select a number of recommendations higher than the target cutoff, for example if you have to compute MAP@10, get 20 recommendations\n",
    "* Build a dataframe whose samples are the user-item recommendations\n",
    "* Add for each interaction some content features: item features, user features\n",
    "* Add for each interaction some features derived by other algorithms: CBF prediction, hybrid prediction\n",
    "* Add for each interaction other miscellaneous information: profile length, item popularity .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import scipy.sparse as sps\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm.notebook import tqdm\n",
    "from xgboost import XGBRanker\n",
    "\n",
    "from Data_manager.competition import load, load_raw\n",
    "from Recommenders.BaseRecommender import BaseRecommender\n",
    "from Recommenders.Similarity.Compute_Similarity import Compute_Similarity\n",
    "from Recommenders.Hybrid import UserWideHybridRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_FOLDS = 10\n",
    "CUTOFF = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MODELS_DIR = Path() / \"models\" / \"all\"\n",
    "MODELS_DIR.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34226</th>\n",
       "      <td>35729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34227</th>\n",
       "      <td>35730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34228</th>\n",
       "      <td>35731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34229</th>\n",
       "      <td>35734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34230</th>\n",
       "      <td>35735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34231 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id\n",
       "0            0\n",
       "1            1\n",
       "2            2\n",
       "3            3\n",
       "4            4\n",
       "...        ...\n",
       "34226    35729\n",
       "34227    35730\n",
       "34228    35731\n",
       "34229    35734\n",
       "34230    35735\n",
       "\n",
       "[34231 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_ID_PATH = Path() / \"Data_manager_split_datasets\" / \"competition\" / \"data_target_users_test.csv\"\n",
    "test_df = pd.read_csv(TEST_ID_PATH)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBMISSION_PATH = Path(\"submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35736 38121\n"
     ]
    }
   ],
   "source": [
    "icm_df, urm_df = load_raw()\n",
    "number_users = urm_df[\"user_id\"].nunique()\n",
    "number_items = icm_df[\"item_id\"].nunique()\n",
    "print(number_users, number_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "icm_matrix, urm_all, urm_train, urm_validation, urm_test = load()\n",
    "ranker_urm = urm_validation + urm_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_user_dicts(user_dicts: list[dict]) -> dict:\n",
    "    return  {\n",
    "        user_dict[\"UserID\"]: user_dict[\"ItemID\"][0]\n",
    "        for user_dict in user_dicts\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def item_to_list() -> pl.Expr:\n",
    "    return pl.col(\"ItemID\").implode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_predictions(input_df: pd.DataFrame, drop_ids: bool = False) -> dict[int, list]:\n",
    "    output_df = input_df[[\"UserID\", \"ItemID\"]].copy()\n",
    "    if drop_ids:\n",
    "        input_df = input_df.drop(columns=[\"UserID\", \"ItemID\"])\n",
    "    output_df[\"Score\"] = XGB_model.predict(input_df)\n",
    "\n",
    "    output_dicts = (\n",
    "        pl.from_pandas(output_df)\n",
    "        .group_by(\"UserID\", \"ItemID\")\n",
    "        .agg(pl.mean(\"Score\"))\n",
    "        .sort(\"UserID\", \"Score\", descending=True)\n",
    "        .group_by(\"UserID\")\n",
    "        .head(10)\n",
    "        .group_by(\"UserID\")\n",
    "        .agg(item_to_list())\n",
    "        .to_dicts()\n",
    "    )\n",
    "    return encode_user_dicts(output_dicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER_GROUPS_USER_WIDE_HYBRID = 10\n",
    "\n",
    "\n",
    "def build_user_wide_hybrid(urm: sps.csr_matrix, models: dict[str, BaseRecommender]):\n",
    "    profile_lengths = np.ediff1d(urm.indptr)\n",
    "    sorted_users = np.argsort(profile_lengths)\n",
    "    block_size = len(sorted_users) // NUMBER_GROUPS_USER_WIDE_HYBRID\n",
    "    group_users = {}\n",
    "    for group in range(NUMBER_GROUPS_USER_WIDE_HYBRID + 1):\n",
    "        group_users[group] = sorted_users[group * block_size : (group + 1) * block_size]\n",
    "    group_recommenders = {\n",
    "        group: models.pop(str(group)) for group in range(NUMBER_GROUPS_USER_WIDE_HYBRID + 1)\n",
    "    }\n",
    "    return UserWideHybridRecommender(urm, group_users, group_recommenders)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d5a185142e49599938b9fadda0e574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fold:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "736b5365f8f640e7827eaff55ef877bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fold_training_dataframes: dict[int, pd.DataFrame] = {}\n",
    "for i, (train_indices, val_indices) in tqdm(\n",
    "    enumerate(KFold(NUMBER_FOLDS, shuffle=True, random_state=42).split(urm_df)),\n",
    "    total=NUMBER_FOLDS,\n",
    "    desc=\"Fold\",\n",
    "):\n",
    "    fold_urm_train_df = urm_df.iloc[train_indices]\n",
    "    fold_urm_train  = sps.csr_matrix(\n",
    "        (fold_urm_train_df.data, (fold_urm_train_df.user_id, fold_urm_train_df.item_id)),\n",
    "        shape=(number_users, number_items),\n",
    "    )\n",
    "\n",
    "    fold_models_dir = MODELS_DIR / str(i)\n",
    "    models: dict[str, BaseRecommender] = {\n",
    "        path.stem: pickle.load(path.open(\"rb\"))\n",
    "        for path in fold_models_dir.glob(\"*.pkl\")\n",
    "    }\n",
    "    if \"user_wide_hybrid\" not in models:\n",
    "        fold_user_wide_hybrid = build_user_wide_hybrid(fold_urm_train, models)\n",
    "        models[\"user_wide_hybrid\"] = fold_user_wide_hybrid\n",
    "\n",
    "    training_dataframe = pd.DataFrame(index=range(0, number_users), columns=[\"ItemID\"])\n",
    "    training_dataframe.index.name = \"UserID\"\n",
    "\n",
    "    recommendations_list = []\n",
    "    recommenders_list = []\n",
    "    rank_list = []\n",
    "    for user_id in tqdm(range(number_users), desc=\"User (candidate)\"):\n",
    "        user_recommendations = []\n",
    "        user_recommenders = []\n",
    "        user_rankings = []\n",
    "        for name, recommender in models.items():\n",
    "            user_recommendations.extend(\n",
    "                recommender.recommend(\n",
    "                    user_id,\n",
    "                    cutoff=CUTOFF,\n",
    "                    remove_seen_flag=True,\n",
    "                )\n",
    "            )\n",
    "            user_recommenders.extend([name] * CUTOFF)\n",
    "            user_rankings.extend(list(range(CUTOFF)))\n",
    "        recommendations_list.append(user_recommendations)\n",
    "        recommenders_list.append(user_recommenders)\n",
    "        rank_list.append(user_rankings)\n",
    "\n",
    "    training_dataframe[\"ItemID\"] = recommendations_list\n",
    "    training_dataframe[\"Recommender\"] = recommenders_list\n",
    "    training_dataframe[\"Ranking\"] = rank_list\n",
    "\n",
    "    exploded_recommender = training_dataframe[\"Recommender\"].explode()\n",
    "    exploded_ranking = training_dataframe[\"Ranking\"].explode()\n",
    "    training_dataframe = training_dataframe.explode(\"ItemID\")\n",
    "    training_dataframe[\"Recommender\"] = exploded_recommender\n",
    "    training_dataframe[\"Ranking\"] = exploded_ranking.astype(\"int\")\n",
    "\n",
    "    recommender_agreement = (\n",
    "        training_dataframe.reset_index()[[\"UserID\", \"ItemID\"]]\n",
    "        .groupby([\"UserID\", \"ItemID\"])\n",
    "        .value_counts()\n",
    "    )\n",
    "    training_dataframe[\"recommender_agreement\"] = recommender_agreement.loc[\n",
    "        list(zip(training_dataframe.index, training_dataframe[\"ItemID\"]))\n",
    "    ].to_numpy()\n",
    "\n",
    "    fold_urm_val_df = urm_df.iloc[val_indices]\n",
    "    fold_urm_val  = sps.csr_matrix(\n",
    "        (fold_urm_val_df.data, (fold_urm_val_df.user_id, fold_urm_val_df.item_id)),\n",
    "        shape=(number_users, number_items),\n",
    "    )\n",
    "    fold_urm_coo = sps.coo_matrix(fold_urm_val)\n",
    "    correct_recommendations = pd.DataFrame(\n",
    "        {\"UserID\": fold_urm_coo.row, \"ItemID\": fold_urm_coo.col}\n",
    "    )\n",
    "    training_dataframe = training_dataframe.merge(\n",
    "        correct_recommendations,\n",
    "        on=[\"UserID\", \"ItemID\"],\n",
    "        how=\"left\",\n",
    "        indicator=\"Exist\",\n",
    "    )\n",
    "    training_dataframe[\"Label\"] = training_dataframe[\"Exist\"] == \"both\"\n",
    "    training_dataframe = training_dataframe.drop(columns=[\"Exist\"])\n",
    "\n",
    "    training_dataframe = training_dataframe.set_index(\"UserID\")\n",
    "    for user_id in tqdm(training_dataframe.index.unique(), desc=\"User (score)\"):\n",
    "        for rec_label, rec_instance in models.items():\n",
    "            item_list = training_dataframe.loc[user_id, \"ItemID\"].to_list()\n",
    "\n",
    "            all_item_scores = rec_instance._compute_item_score(\n",
    "                [user_id], items_to_compute=item_list\n",
    "            )\n",
    "\n",
    "            training_dataframe.loc[user_id, rec_label] = all_item_scores[0, item_list]\n",
    "\n",
    "    training_dataframe = training_dataframe.reset_index()\n",
    "    training_dataframe = training_dataframe.rename(columns={\"index\": \"UserID\"})\n",
    "\n",
    "    training_dataframe[\"fold\"] = i\n",
    "    fold_training_dataframes[i] = training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>Label</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>3.110688</td>\n",
       "      <td>0.239450</td>\n",
       "      <td>0.206285</td>\n",
       "      <td>0.740719</td>\n",
       "      <td>0.144743</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2.772010</td>\n",
       "      <td>0.219615</td>\n",
       "      <td>0.148456</td>\n",
       "      <td>0.641081</td>\n",
       "      <td>0.263636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>3055</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>2.486904</td>\n",
       "      <td>0.125511</td>\n",
       "      <td>0.207595</td>\n",
       "      <td>0.236244</td>\n",
       "      <td>0.265044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>7703</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2.452576</td>\n",
       "      <td>0.332619</td>\n",
       "      <td>0.356510</td>\n",
       "      <td>0.552886</td>\n",
       "      <td>0.265612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>2.382515</td>\n",
       "      <td>0.152765</td>\n",
       "      <td>0.517510</td>\n",
       "      <td>0.776470</td>\n",
       "      <td>0.197812</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>37445</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "      <td>6.829084</td>\n",
       "      <td>0.397035</td>\n",
       "      <td>0.381556</td>\n",
       "      <td>2.114357</td>\n",
       "      <td>1.075880</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>36917</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>7.840089</td>\n",
       "      <td>0.360952</td>\n",
       "      <td>0.282539</td>\n",
       "      <td>1.754302</td>\n",
       "      <td>1.034486</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>6.126834</td>\n",
       "      <td>0.287594</td>\n",
       "      <td>0.349424</td>\n",
       "      <td>1.712431</td>\n",
       "      <td>1.022785</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>5.761028</td>\n",
       "      <td>0.382223</td>\n",
       "      <td>0.175502</td>\n",
       "      <td>1.817523</td>\n",
       "      <td>0.937134</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>3.779285</td>\n",
       "      <td>0.325988</td>\n",
       "      <td>0.111000</td>\n",
       "      <td>2.019372</td>\n",
       "      <td>0.925783</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17868000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      3   \n",
       "1             0  14888                23        1                      3   \n",
       "2             0   3055                23        2                      2   \n",
       "3             0   7703                23        3                      3   \n",
       "4             0    512                23        4                      3   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  37445  user_wide_hybrid        5                      5   \n",
       "1786796   35735  36917  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36775  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      3   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      3   \n",
       "\n",
       "         Label        23        21        22        20  user_wide_hybrid  fold  \n",
       "0        False  3.110688  0.239450  0.206285  0.740719          0.144743     0  \n",
       "1        False  2.772010  0.219615  0.148456  0.641081          0.263636     0  \n",
       "2        False  2.486904  0.125511  0.207595  0.236244          0.265044     0  \n",
       "3        False  2.452576  0.332619  0.356510  0.552886          0.265612     0  \n",
       "4        False  2.382515  0.152765  0.517510  0.776470          0.197812     0  \n",
       "...        ...       ...       ...       ...       ...               ...   ...  \n",
       "1786795  False  6.829084  0.397035  0.381556  2.114357          1.075880     9  \n",
       "1786796  False  7.840089  0.360952  0.282539  1.754302          1.034486     9  \n",
       "1786797  False  6.126834  0.287594  0.349424  1.712431          1.022785     9  \n",
       "1786798  False  5.761028  0.382223  0.175502  1.817523          0.937134     9  \n",
       "1786799  False  3.779285  0.325988  0.111000  2.019372          0.925783     9  \n",
       "\n",
       "[17868000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "training_dataframe = pd.concat(fold_training_dataframes.values())\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee6b46d3b84a4c7ab2627ec1f2c7ddf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (candidate):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0132fe01d52d482589dfabc2c312924c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "User (score):   0%|          | 0/35736 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273  \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018  \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547  \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901  \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573  \n",
       "...           ...       ...       ...       ...               ...  \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134  \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393  \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799  \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921  \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385  \n",
       "\n",
       "[1786800 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_models_dir = Path() / \"models\" / \"all\" / \"0\"\n",
    "models: dict[str, BaseRecommender] = {\n",
    "    path.stem: pickle.load(path.open(\"rb\"))\n",
    "    for path in submit_models_dir.glob(\"*.pkl\")\n",
    "}\n",
    "\n",
    "submission_dataframe = pd.DataFrame(index=range(0, number_users), columns=[\"ItemID\"])\n",
    "submission_dataframe.index.name = \"UserID\"\n",
    "\n",
    "recommendations_list = []\n",
    "recommenders_list = []\n",
    "rank_list = []\n",
    "for user_id in tqdm(range(number_users), desc=\"User (candidate)\"):\n",
    "    user_recommendations = []\n",
    "    user_recommenders = []\n",
    "    user_rankings = []\n",
    "    for name, recommender in models.items():\n",
    "        user_recommendations.extend(\n",
    "            recommender.recommend(\n",
    "                user_id,\n",
    "                cutoff=CUTOFF,\n",
    "                remove_seen_flag=True,\n",
    "            )\n",
    "        )\n",
    "        user_recommenders.extend([name] * CUTOFF)\n",
    "        user_rankings.extend(list(range(CUTOFF)))\n",
    "    recommendations_list.append(user_recommendations)\n",
    "    recommenders_list.append(user_recommenders)\n",
    "    rank_list.append(user_rankings)\n",
    "\n",
    "submission_dataframe[\"ItemID\"] = recommendations_list\n",
    "submission_dataframe[\"Recommender\"] = recommenders_list\n",
    "submission_dataframe[\"Ranking\"] = rank_list\n",
    "\n",
    "exploded_recommender = submission_dataframe[\"Recommender\"].explode()\n",
    "exploded_ranking = submission_dataframe[\"Ranking\"].explode()\n",
    "submission_dataframe = submission_dataframe.explode(\"ItemID\")\n",
    "submission_dataframe[\"Recommender\"] = exploded_recommender\n",
    "submission_dataframe[\"Ranking\"] = exploded_ranking.astype(\"int\")\n",
    "\n",
    "recommender_agreement = (\n",
    "    submission_dataframe.reset_index()[[\"UserID\", \"ItemID\"]]\n",
    "    .groupby([\"UserID\", \"ItemID\"])\n",
    "    .value_counts()\n",
    ")\n",
    "submission_dataframe[\"recommender_agreement\"] = recommender_agreement.loc[\n",
    "    list(zip(submission_dataframe.index, submission_dataframe[\"ItemID\"]))\n",
    "].to_numpy()\n",
    "\n",
    "\n",
    "for user_id in tqdm(submission_dataframe.index.unique(), desc=\"User (score)\"):\n",
    "    for rec_label, rec_instance in models.items():\n",
    "        item_list = submission_dataframe.loc[user_id, \"ItemID\"].to_list()\n",
    "\n",
    "        all_item_scores = rec_instance._compute_item_score(\n",
    "            [user_id], items_to_compute=item_list\n",
    "        )\n",
    "\n",
    "        submission_dataframe.loc[user_id, rec_label] = all_item_scores[0, item_list]\n",
    "\n",
    "submission_dataframe = submission_dataframe.reset_index()\n",
    "submission_dataframe = submission_dataframe.rename(columns={\"index\": \"UserID\"})\n",
    "submission_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273  \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018  \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547  \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901  \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573  \n",
       "...           ...       ...       ...       ...               ...  \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134  \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393  \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799  \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921  \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385  \n",
       "\n",
       "[1786800 rows x 10 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = submission_dataframe\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Item features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Item popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_popularity = np.ediff1d(sps.csc_matrix(urm_all).indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  \n",
       "0                     93  \n",
       "1                    110  \n",
       "2                    120  \n",
       "3                     27  \n",
       "4                    107  \n",
       "...                  ...  \n",
       "1786795               88  \n",
       "1786796               70  \n",
       "1786797              147  \n",
       "1786798               58  \n",
       "1786799               28  \n",
       "\n",
       "[1786800 rows x 11 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe[\"item_popularity\"] = item_popularity[\n",
    "    training_dataframe[\"ItemID\"].to_numpy().astype(int)\n",
    "]\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance to closest items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 38121 (100.0%), 934.83 column/sec. Elapsed time 40.78 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 3812100 stored elements and shape (38121, 38121)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_similarity = Compute_Similarity(icm_matrix.T).compute_similarity()\n",
    "item_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38116</th>\n",
       "      <td>0.000397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38117</th>\n",
       "      <td>0.007546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38118</th>\n",
       "      <td>0.005463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38119</th>\n",
       "      <td>0.000602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38120</th>\n",
       "      <td>0.002821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>38121 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_similarity\n",
       "0             0.000046\n",
       "1             0.000309\n",
       "2             0.000140\n",
       "3             0.000105\n",
       "4             0.000015\n",
       "...                ...\n",
       "38116         0.000397\n",
       "38117         0.007546\n",
       "38118         0.005463\n",
       "38119         0.000602\n",
       "38120         0.002821\n",
       "\n",
       "[38121 rows x 1 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_item_similarity_dict = {i: row.mean() for i, row in enumerate(item_similarity)}\n",
    "mean_item_similarity: pd.DataFrame = pd.Series(mean_item_similarity_dict).to_frame(name=\"item_similarity\")\n",
    "mean_item_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  item_similarity  \n",
       "0                     93         0.000246  \n",
       "1                    110         0.000250  \n",
       "2                    120         0.000545  \n",
       "3                     27         0.000040  \n",
       "4                    107         0.000224  \n",
       "...                  ...              ...  \n",
       "1786795               88         0.003954  \n",
       "1786796               70         0.003902  \n",
       "1786797              147         0.003986  \n",
       "1786798               58         0.003902  \n",
       "1786799               28         0.000684  \n",
       "\n",
       "[1786800 rows x 12 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = training_dataframe.join(mean_item_similarity, on=\"ItemID\")\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_popularity = np.ediff1d(sps.csr_matrix(urm_all).indptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  \n",
       "0                     93         0.000246               114  \n",
       "1                    110         0.000250               114  \n",
       "2                    120         0.000545               114  \n",
       "3                     27         0.000040               114  \n",
       "4                    107         0.000224               114  \n",
       "...                  ...              ...               ...  \n",
       "1786795               88         0.003954                37  \n",
       "1786796               70         0.003902                37  \n",
       "1786797              147         0.003986                37  \n",
       "1786798               58         0.003902                37  \n",
       "1786799               28         0.000684                37  \n",
       "\n",
       "[1786800 rows x 13 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe[\"user_profile_len\"] = user_popularity[\n",
    "    training_dataframe[\"UserID\"].to_numpy().astype(int)\n",
    "]\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User popularity bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Measure of how much popularity influences the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11146, 25392,  4601, ...,  8491, 21675,  8152])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_popularity_ranking = item_popularity.argsort()[::-1]\n",
    "item_popularity_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764602</th>\n",
       "      <td>35735</td>\n",
       "      <td>37802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764603</th>\n",
       "      <td>35735</td>\n",
       "      <td>37803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764604</th>\n",
       "      <td>35735</td>\n",
       "      <td>37805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764605</th>\n",
       "      <td>35735</td>\n",
       "      <td>38000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764606</th>\n",
       "      <td>35735</td>\n",
       "      <td>38034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1764607 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id\n",
       "0              0        0\n",
       "1              0        2\n",
       "2              0      120\n",
       "3              0      128\n",
       "4              0      211\n",
       "...          ...      ...\n",
       "1764602    35735    37802\n",
       "1764603    35735    37803\n",
       "1764604    35735    37805\n",
       "1764605    35735    38000\n",
       "1764606    35735    38034\n",
       "\n",
       "[1764607 rows x 2 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_id_df = urm_df[[\"user_id\", \"item_id\"]]\n",
    "item_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_POPULAR_THRESHOLDS = (10, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>211</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764602</th>\n",
       "      <td>35735</td>\n",
       "      <td>37802</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764603</th>\n",
       "      <td>35735</td>\n",
       "      <td>37803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764604</th>\n",
       "      <td>35735</td>\n",
       "      <td>37805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764605</th>\n",
       "      <td>35735</td>\n",
       "      <td>38000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1764606</th>\n",
       "      <td>35735</td>\n",
       "      <td>38034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1764607 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  item_id  top_10  top_100  top_1000\n",
       "0              0        0     0.0      0.0       0.0\n",
       "1              0        2     0.0      0.0       0.0\n",
       "2              0      120     0.0      0.0       0.0\n",
       "3              0      128     0.0      0.0       0.0\n",
       "4              0      211     0.0      0.0       1.0\n",
       "...          ...      ...     ...      ...       ...\n",
       "1764602    35735    37802     0.0      0.0       0.0\n",
       "1764603    35735    37803     0.0      0.0       0.0\n",
       "1764604    35735    37805     0.0      0.0       0.0\n",
       "1764605    35735    38000     0.0      0.0       0.0\n",
       "1764606    35735    38034     0.0      0.0       0.0\n",
       "\n",
       "[1764607 rows x 5 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for k in TOP_POPULAR_THRESHOLDS:\n",
    "    top_k_popular = item_popularity_ranking[:k]\n",
    "    item_id_df.loc[item_id_df[\"item_id\"].isin(top_k_popular), f\"top_{k}\"] = 1\n",
    "item_id_df = item_id_df.fillna(0)\n",
    "item_id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35733</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35735</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35736 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         top_10  top_100  top_1000\n",
       "user_id                           \n",
       "0           0.0      1.0       7.0\n",
       "1           2.0      3.0      10.0\n",
       "2           0.0      0.0       0.0\n",
       "3           1.0      4.0      11.0\n",
       "4           0.0      3.0      29.0\n",
       "...         ...      ...       ...\n",
       "35731       0.0      0.0       0.0\n",
       "35732       0.0      0.0       1.0\n",
       "35733       0.0      0.0       0.0\n",
       "35734       0.0      0.0       0.0\n",
       "35735       0.0      0.0       0.0\n",
       "\n",
       "[35736 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_top_k_df = item_id_df.groupby(\"user_id\").aggregate({f\"top_{k}\": \"sum\" for k in TOP_POPULAR_THRESHOLDS})\n",
    "user_top_k_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  top_10  top_100  \\\n",
       "0                     93         0.000246               114     0.0      1.0   \n",
       "1                    110         0.000250               114     0.0      1.0   \n",
       "2                    120         0.000545               114     0.0      1.0   \n",
       "3                     27         0.000040               114     0.0      1.0   \n",
       "4                    107         0.000224               114     0.0      1.0   \n",
       "...                  ...              ...               ...     ...      ...   \n",
       "1786795               88         0.003954                37     0.0      0.0   \n",
       "1786796               70         0.003902                37     0.0      0.0   \n",
       "1786797              147         0.003986                37     0.0      0.0   \n",
       "1786798               58         0.003902                37     0.0      0.0   \n",
       "1786799               28         0.000684                37     0.0      0.0   \n",
       "\n",
       "         top_1000  \n",
       "0             7.0  \n",
       "1             7.0  \n",
       "2             7.0  \n",
       "3             7.0  \n",
       "4             7.0  \n",
       "...           ...  \n",
       "1786795       0.0  \n",
       "1786796       0.0  \n",
       "1786797       0.0  \n",
       "1786798       0.0  \n",
       "1786799       0.0  \n",
       "\n",
       "[1786800 rows x 16 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = training_dataframe.join(user_top_k_df, on=\"UserID\")\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance to closest users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity column 35736 (100.0%), 5494.00 column/sec. Elapsed time 6.50 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'float32'\n",
       "\twith 3573591 stored elements and shape (35736, 35736)>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_similarity = Compute_Similarity(urm_all.T).compute_similarity()\n",
    "user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35731</th>\n",
       "      <td>0.000204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35732</th>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35733</th>\n",
       "      <td>0.000267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35734</th>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35735</th>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35736 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_similarity\n",
       "0             0.000183\n",
       "1             0.000357\n",
       "2             0.000161\n",
       "3             0.000158\n",
       "4             0.001004\n",
       "...                ...\n",
       "35731         0.000204\n",
       "35732         0.000333\n",
       "35733         0.000267\n",
       "35734         0.000341\n",
       "35735         0.000272\n",
       "\n",
       "[35736 rows x 1 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_user_similarity_dict = {i: row.mean() for i, row in enumerate(user_similarity)}\n",
    "mean_user_similarity: pd.DataFrame = pd.Series(mean_user_similarity_dict).to_frame(name=\"user_similarity\")\n",
    "mean_user_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.708066</td>\n",
       "      <td>0.364245</td>\n",
       "      <td>0.184505</td>\n",
       "      <td>0.906074</td>\n",
       "      <td>0.288273</td>\n",
       "      <td>93</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3.389925</td>\n",
       "      <td>0.282408</td>\n",
       "      <td>0.327246</td>\n",
       "      <td>1.195710</td>\n",
       "      <td>0.312018</td>\n",
       "      <td>110</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>452</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3.183915</td>\n",
       "      <td>0.180780</td>\n",
       "      <td>0.072435</td>\n",
       "      <td>0.279713</td>\n",
       "      <td>0.242547</td>\n",
       "      <td>120</td>\n",
       "      <td>0.000545</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>23</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2.940626</td>\n",
       "      <td>0.226980</td>\n",
       "      <td>0.315740</td>\n",
       "      <td>1.171455</td>\n",
       "      <td>0.176901</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14931</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.921493</td>\n",
       "      <td>0.238371</td>\n",
       "      <td>0.189480</td>\n",
       "      <td>0.695994</td>\n",
       "      <td>0.246573</td>\n",
       "      <td>107</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37660</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>7.323517</td>\n",
       "      <td>0.347563</td>\n",
       "      <td>0.192113</td>\n",
       "      <td>1.368214</td>\n",
       "      <td>0.588393</td>\n",
       "      <td>70</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36920</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7.601600</td>\n",
       "      <td>0.342447</td>\n",
       "      <td>0.263019</td>\n",
       "      <td>1.772518</td>\n",
       "      <td>0.581799</td>\n",
       "      <td>147</td>\n",
       "      <td>0.003986</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>37017</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>4.652850</td>\n",
       "      <td>0.303232</td>\n",
       "      <td>0.303558</td>\n",
       "      <td>2.394336</td>\n",
       "      <td>0.573921</td>\n",
       "      <td>58</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>35753</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5.464930</td>\n",
       "      <td>0.300776</td>\n",
       "      <td>0.086924</td>\n",
       "      <td>2.287900</td>\n",
       "      <td>0.509385</td>\n",
       "      <td>28</td>\n",
       "      <td>0.000684</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0    572                23        0                      4   \n",
       "1             0  14888                23        1                      4   \n",
       "2             0    452                23        2                      1   \n",
       "3             0   9911                23        3                      2   \n",
       "4             0  14931                23        4                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37660  user_wide_hybrid        6                      3   \n",
       "1786797   35735  36920  user_wide_hybrid        7                      3   \n",
       "1786798   35735  37017  user_wide_hybrid        8                      2   \n",
       "1786799   35735  35753  user_wide_hybrid        9                      2   \n",
       "\n",
       "               23        21        22        20  user_wide_hybrid  \\\n",
       "0        3.708066  0.364245  0.184505  0.906074          0.288273   \n",
       "1        3.389925  0.282408  0.327246  1.195710          0.312018   \n",
       "2        3.183915  0.180780  0.072435  0.279713          0.242547   \n",
       "3        2.940626  0.226980  0.315740  1.171455          0.176901   \n",
       "4        2.921493  0.238371  0.189480  0.695994          0.246573   \n",
       "...           ...       ...       ...       ...               ...   \n",
       "1786795  8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796  7.323517  0.347563  0.192113  1.368214          0.588393   \n",
       "1786797  7.601600  0.342447  0.263019  1.772518          0.581799   \n",
       "1786798  4.652850  0.303232  0.303558  2.394336          0.573921   \n",
       "1786799  5.464930  0.300776  0.086924  2.287900          0.509385   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  top_10  top_100  \\\n",
       "0                     93         0.000246               114     0.0      1.0   \n",
       "1                    110         0.000250               114     0.0      1.0   \n",
       "2                    120         0.000545               114     0.0      1.0   \n",
       "3                     27         0.000040               114     0.0      1.0   \n",
       "4                    107         0.000224               114     0.0      1.0   \n",
       "...                  ...              ...               ...     ...      ...   \n",
       "1786795               88         0.003954                37     0.0      0.0   \n",
       "1786796               70         0.003902                37     0.0      0.0   \n",
       "1786797              147         0.003986                37     0.0      0.0   \n",
       "1786798               58         0.003902                37     0.0      0.0   \n",
       "1786799               28         0.000684                37     0.0      0.0   \n",
       "\n",
       "         top_1000  user_similarity  \n",
       "0             7.0         0.000183  \n",
       "1             7.0         0.000183  \n",
       "2             7.0         0.000183  \n",
       "3             7.0         0.000183  \n",
       "4             7.0         0.000183  \n",
       "...           ...              ...  \n",
       "1786795       0.0         0.000272  \n",
       "1786796       0.0         0.000272  \n",
       "1786797       0.0         0.000272  \n",
       "1786798       0.0         0.000272  \n",
       "1786799       0.0         0.000272  \n",
       "\n",
       "[1786800 rows x 17 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = training_dataframe.join(mean_user_similarity, on=\"UserID\")\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-ranker data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion to categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6166</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142024</td>\n",
       "      <td>0.421410</td>\n",
       "      <td>0.353835</td>\n",
       "      <td>0.270525</td>\n",
       "      <td>129</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11966</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145097</td>\n",
       "      <td>0.267107</td>\n",
       "      <td>0.893614</td>\n",
       "      <td>0.283992</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2743</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.452733</td>\n",
       "      <td>0.195061</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>0.521364</td>\n",
       "      <td>0.284803</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2637</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197307</td>\n",
       "      <td>0.381694</td>\n",
       "      <td>0.790003</td>\n",
       "      <td>0.218590</td>\n",
       "      <td>67</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>738</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.694155</td>\n",
       "      <td>0.103107</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.318969</td>\n",
       "      <td>0.093946</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37445</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.411239</td>\n",
       "      <td>0.408742</td>\n",
       "      <td>0.455056</td>\n",
       "      <td>3.137702</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36917</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.380329</td>\n",
       "      <td>0.453475</td>\n",
       "      <td>0.383239</td>\n",
       "      <td>2.259961</td>\n",
       "      <td>0.839466</td>\n",
       "      <td>76</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>36034</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.576296</td>\n",
       "      <td>0.430645</td>\n",
       "      <td>0.403139</td>\n",
       "      <td>2.485576</td>\n",
       "      <td>1.015675</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>36493</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11.521591</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.614241</td>\n",
       "      <td>2.720541</td>\n",
       "      <td>1.047983</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0             0   6166  user_wide_hybrid        7                      2   \n",
       "1             0  11966  user_wide_hybrid        6                      1   \n",
       "2             0   2743  user_wide_hybrid        5                      1   \n",
       "3             0   2637                22        8                      1   \n",
       "4             0    738                22        9                      1   \n",
       "...         ...    ...               ...      ...                    ...   \n",
       "1786795   35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796   35735  37445  user_wide_hybrid        4                      5   \n",
       "1786797   35735  36917  user_wide_hybrid        3                      5   \n",
       "1786798   35735  36034  user_wide_hybrid        2                      5   \n",
       "1786799   35735  36493  user_wide_hybrid        1                      5   \n",
       "\n",
       "                23        21        22        20  user_wide_hybrid  \\\n",
       "0         0.000000  0.142024  0.421410  0.353835          0.270525   \n",
       "1         0.000000  0.145097  0.267107  0.893614          0.283992   \n",
       "2         1.452733  0.195061  0.273309  0.521364          0.284803   \n",
       "3         0.000000  0.197307  0.381694  0.790003          0.218590   \n",
       "4         1.694155  0.103107  0.370141  0.318969          0.093946   \n",
       "...            ...       ...       ...       ...               ...   \n",
       "1786795   8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796   7.411239  0.408742  0.455056  3.137702          0.680556   \n",
       "1786797   8.380329  0.453475  0.383239  2.259961          0.839466   \n",
       "1786798  10.576296  0.430645  0.403139  2.485576          1.015675   \n",
       "1786799  11.521591  0.512244  0.614241  2.720541          1.047983   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  top_10  top_100  \\\n",
       "0                    129         0.000371               114     0.0      1.0   \n",
       "1                     52         0.000568               114     0.0      1.0   \n",
       "2                     39         0.000069               114     0.0      1.0   \n",
       "3                     67         0.000177               114     0.0      1.0   \n",
       "4                     29         0.000474               114     0.0      1.0   \n",
       "...                  ...              ...               ...     ...      ...   \n",
       "1786795               88         0.003954                37     0.0      0.0   \n",
       "1786796               27         0.000132                37     0.0      0.0   \n",
       "1786797               76         0.004296                37     0.0      0.0   \n",
       "1786798               81         0.000403                37     0.0      0.0   \n",
       "1786799               33         0.000083                37     0.0      0.0   \n",
       "\n",
       "         top_1000  user_similarity  \n",
       "0             7.0         0.000183  \n",
       "1             7.0         0.000183  \n",
       "2             7.0         0.000183  \n",
       "3             7.0         0.000183  \n",
       "4             7.0         0.000183  \n",
       "...           ...              ...  \n",
       "1786795       0.0         0.000272  \n",
       "1786796       0.0         0.000272  \n",
       "1786797       0.0         0.000272  \n",
       "1786798       0.0         0.000272  \n",
       "1786799       0.0         0.000272  \n",
       "\n",
       "[1786800 rows x 17 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_dataframe = training_dataframe.sort_values(\"UserID\").reset_index(drop=True)\n",
    "training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1786800 entries, 0 to 1786799\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   UserID                 int64  \n",
      " 1   ItemID                 object \n",
      " 2   Recommender            object \n",
      " 3   Ranking                int64  \n",
      " 4   recommender_agreement  int64  \n",
      " 5   23                     float32\n",
      " 6   21                     float32\n",
      " 7   22                     float32\n",
      " 8   20                     float32\n",
      " 9   user_wide_hybrid       float32\n",
      " 10  item_popularity        int32  \n",
      " 11  item_similarity        float32\n",
      " 12  user_profile_len       int32  \n",
      " 13  top_10                 float64\n",
      " 14  top_100                float64\n",
      " 15  top_1000               float64\n",
      " 16  user_similarity        float32\n",
      "dtypes: float32(7), float64(3), int32(2), int64(3), object(2)\n",
      "memory usage: 170.4+ MB\n"
     ]
    }
   ],
   "source": [
    "training_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1786800 entries, 0 to 1786799\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   UserID                 int64  \n",
      " 1   ItemID                 object \n",
      " 2   Recommender            object \n",
      " 3   Ranking                int64  \n",
      " 4   recommender_agreement  int64  \n",
      " 5   23                     float32\n",
      " 6   21                     float32\n",
      " 7   22                     float32\n",
      " 8   20                     float32\n",
      " 9   user_wide_hybrid       float32\n",
      " 10  item_popularity        int32  \n",
      " 11  item_similarity        float32\n",
      " 12  user_profile_len       int32  \n",
      " 13  top_10                 float64\n",
      " 14  top_100                float64\n",
      " 15  top_1000               float64\n",
      " 16  user_similarity        float32\n",
      "dtypes: float32(7), float64(3), int32(2), int64(3), object(2)\n",
      "memory usage: 170.4+ MB\n"
     ]
    }
   ],
   "source": [
    "training_dataframe.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1786800 entries, 0 to 1786799\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   UserID                 category\n",
      " 1   ItemID                 category\n",
      " 2   Recommender            category\n",
      " 3   Ranking                int64   \n",
      " 4   recommender_agreement  int64   \n",
      " 5   23                     float32 \n",
      " 6   21                     float32 \n",
      " 7   22                     float32 \n",
      " 8   20                     float32 \n",
      " 9   user_wide_hybrid       float32 \n",
      " 10  item_popularity        int32   \n",
      " 11  item_similarity        float32 \n",
      " 12  user_profile_len       int32   \n",
      " 13  top_10                 float64 \n",
      " 14  top_100                float64 \n",
      " 15  top_1000               float64 \n",
      " 16  user_similarity        float32 \n",
      "dtypes: category(3), float32(7), float64(3), int32(2), int64(2)\n",
      "memory usage: 144.0 MB\n"
     ]
    }
   ],
   "source": [
    "categorical_training_dataframe = training_dataframe\n",
    "for categorical_column in (\"UserID\", \"ItemID\", \"Recommender\"):\n",
    "    categorical_training_dataframe[categorical_column] = categorical_training_dataframe[categorical_column].astype(\"category\")\n",
    "categorical_training_dataframe.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_training_dataframe.to_parquet(\"ranker_training_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_training_dataframe = pd.read_parquet(\"ranker_training_data.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = categorical_training_dataframe.pop(\"fold\")\n",
    "\n",
    "train_df = categorical_training_dataframe[fold != 9]\n",
    "y_train = train_df[\"Label\"]\n",
    "X_train = train_df.drop(columns=\"Label\")\n",
    "\n",
    "val_df = categorical_training_dataframe[fold == 9]\n",
    "y_val = val_df[\"Label\"]\n",
    "X_val = val_df.drop(columns=\"Label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use the ranker one first needs to specify the size of the groups, a group is the dimension you rank on, in this case each group corresponds to a user. Since we have generated a fixed number of candidates for each user, all groups have the same length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35736,) (35736,)\n"
     ]
    }
   ],
   "source": [
    "train_groups = X_train.groupby(\"UserID\").size().to_numpy()\n",
    "val_groups = X_val.groupby(\"UserID\").size().to_numpy()\n",
    "\n",
    "print(train_groups.shape, val_groups.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False    0.94345\n",
      "True     0.05655\n",
      "Name: Label, dtype: float64\n",
      "False    0.94345\n",
      "True     0.05655\n",
      "Name: Label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for y in (y_train, y_val):\n",
    "    print(pd.Series(y_train).value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 16081200 entries, 0 to 17867999\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   UserID                 int64   \n",
      " 1   ItemID                 int64   \n",
      " 2   Recommender            category\n",
      " 3   Ranking                int64   \n",
      " 4   recommender_agreement  int64   \n",
      " 5   23                     float32 \n",
      " 6   21                     float32 \n",
      " 7   22                     float32 \n",
      " 8   20                     float32 \n",
      " 9   user_wide_hybrid       float32 \n",
      " 10  item_popularity        int32   \n",
      " 11  item_similarity        float32 \n",
      " 12  user_profile_len       int32   \n",
      " 13  top_10                 float64 \n",
      " 14  top_100                float64 \n",
      " 15  top_1000               float64 \n",
      " 16  user_similarity        float32 \n",
      "dtypes: category(1), float32(7), float64(3), int32(2), int64(4)\n",
      "memory usage: 1.5 GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1786800 entries, 256 to 17867998\n",
      "Data columns (total 17 columns):\n",
      " #   Column                 Dtype   \n",
      "---  ------                 -----   \n",
      " 0   UserID                 int64   \n",
      " 1   ItemID                 int64   \n",
      " 2   Recommender            category\n",
      " 3   Ranking                int64   \n",
      " 4   recommender_agreement  int64   \n",
      " 5   23                     float32 \n",
      " 6   21                     float32 \n",
      " 7   22                     float32 \n",
      " 8   20                     float32 \n",
      " 9   user_wide_hybrid       float32 \n",
      " 10  item_popularity        int32   \n",
      " 11  item_similarity        float32 \n",
      " 12  user_profile_len       int32   \n",
      " 13  top_10                 float64 \n",
      " 14  top_100                float64 \n",
      " 15  top_1000               float64 \n",
      " 16  user_similarity        float32 \n",
      "dtypes: category(1), float32(7), float64(3), int32(2), int64(4)\n",
      "memory usage: 172.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "for X in (X_train, X_val):\n",
    "    print(X.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = 50\n",
    "learning_rate = 1e-1\n",
    "reg_alpha = 1e-1\n",
    "reg_lambda = 1e-1\n",
    "max_depth = 3\n",
    "max_leaves = 0\n",
    "grow_policy = \"depthwise\"\n",
    "objective = \"pairwise\"\n",
    "booster = \"gbtree\"\n",
    "use_user_profile = False\n",
    "random_seed = None\n",
    "\n",
    "XGB_model = XGBRanker(\n",
    "    enable_categorical=True,\n",
    "    objective=\"rank:{}\".format(objective),\n",
    "    n_estimators=int(n_estimators),\n",
    "    random_state=random_seed,\n",
    "    learning_rate=learning_rate,\n",
    "    reg_alpha=reg_alpha,\n",
    "    reg_lambda=reg_lambda,\n",
    "    max_depth=int(max_depth),\n",
    "    max_leaves=int(max_leaves),\n",
    "    grow_policy=grow_policy,\n",
    "    verbosity=0,  # 2 if self.verbose else 0,\n",
    "    booster=booster,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=None,\n",
       "          device=None, early_stopping_rounds=None, enable_categorical=True,\n",
       "          eval_metric=None, feature_types=None, gamma=None,\n",
       "          grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "          interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "          max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=None,\n",
       "          max_depth=3, max_leaves=0, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=50,\n",
       "          n_jobs=None, num_parallel_tree=None, objective=&#x27;rank:pairwise&#x27;, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBRanker<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBRanker(base_score=None, booster=&#x27;gbtree&#x27;, callbacks=None,\n",
       "          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=None,\n",
       "          device=None, early_stopping_rounds=None, enable_categorical=True,\n",
       "          eval_metric=None, feature_types=None, gamma=None,\n",
       "          grow_policy=&#x27;depthwise&#x27;, importance_type=None,\n",
       "          interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "          max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=None,\n",
       "          max_depth=3, max_leaves=0, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=50,\n",
       "          n_jobs=None, num_parallel_tree=None, objective=&#x27;rank:pairwise&#x27;, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster='gbtree', callbacks=None,\n",
       "          colsample_bylevel=None, colsample_bynode=None, colsample_bytree=None,\n",
       "          device=None, early_stopping_rounds=None, enable_categorical=True,\n",
       "          eval_metric=None, feature_types=None, gamma=None,\n",
       "          grow_policy='depthwise', importance_type=None,\n",
       "          interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "          max_cat_threshold=None, max_cat_to_onehot=None, max_delta_step=None,\n",
       "          max_depth=3, max_leaves=0, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=50,\n",
       "          n_jobs=None, num_parallel_tree=None, objective='rank:pairwise', ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.fit(\n",
    "    X_train,  # .drop(columns=[\"UserID\", \"ItemID\"]),\n",
    "    y_train,\n",
    "    group=train_groups,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9442575656218453"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_model.score(\n",
    "    X_train,  # .drop(columns=[\"UserID\", \"ItemID\"]),\n",
    "    y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained we can use it to compute predictions. Each prediction will refer to a specific user-item pair, which we will then need to rank as we do in any other recommender model.\n",
    "\n",
    "**Important:** In order to use this model to predict the score of new datapoints (i.e., new recommendations) we have to repeat the same data processing steps but:\n",
    "- We do not need a train-label split, we can user all the data we have to compute the predictions and the features\n",
    "- The recommendation models used to generate the scores should be trained on all the available data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can have a look to the feature importance to assess which are the most informative ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: title={'center': 'Weight (Frequence)'}, xlabel='F score', ylabel='Features'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost import plot_importance\n",
    "\n",
    "plot_importance(XGB_model, importance_type=\"weight\", title=\"Weight (Frequence)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decode predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "      <td>454</td>\n",
       "      <td>-0.094380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>257</th>\n",
       "      <td>0</td>\n",
       "      <td>8505</td>\n",
       "      <td>-0.068681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>0</td>\n",
       "      <td>8505</td>\n",
       "      <td>-0.085446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>0</td>\n",
       "      <td>14888</td>\n",
       "      <td>-0.064724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>0</td>\n",
       "      <td>2746</td>\n",
       "      <td>-0.104188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867978</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>0.012558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867988</th>\n",
       "      <td>35735</td>\n",
       "      <td>37657</td>\n",
       "      <td>0.097238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867989</th>\n",
       "      <td>35735</td>\n",
       "      <td>36493</td>\n",
       "      <td>0.088098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867996</th>\n",
       "      <td>35735</td>\n",
       "      <td>36034</td>\n",
       "      <td>0.048838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17867998</th>\n",
       "      <td>35735</td>\n",
       "      <td>37800</td>\n",
       "      <td>0.008314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          UserID  ItemID     Score\n",
       "256            0     454 -0.094380\n",
       "257            0    8505 -0.068681\n",
       "264            0    8505 -0.085446\n",
       "265            0   14888 -0.064724\n",
       "266            0    2746 -0.104188\n",
       "...          ...     ...       ...\n",
       "17867978   35735   36775  0.012558\n",
       "17867988   35735   37657  0.097238\n",
       "17867989   35735   36493  0.088098\n",
       "17867996   35735   36034  0.048838\n",
       "17867998   35735   37800  0.008314\n",
       "\n",
       "[1786800 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_hat = X_val[[\"UserID\", \"ItemID\"]].copy()\n",
    "y_val_hat[\"Score\"] = XGB_model.predict(\n",
    "    X_val,\n",
    ")\n",
    "y_val_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UserID': 2379, 'ItemID': [[14748, 14748, 3638, 14748, 3638, 14748]]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_items_dicts = (\n",
    "    pl.from_pandas(y_val_hat[y_val]).group_by(\"UserID\").agg(item_to_list()).to_dicts()\n",
    ")\n",
    "val_items_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ItemID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37657</th>\n",
       "      <td>0.100747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36493</th>\n",
       "      <td>0.094613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37801</th>\n",
       "      <td>0.093326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36034</th>\n",
       "      <td>0.061902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37017</th>\n",
       "      <td>0.060956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37445</th>\n",
       "      <td>0.056658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36917</th>\n",
       "      <td>0.051948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36773</th>\n",
       "      <td>0.031359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36775</th>\n",
       "      <td>0.012558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37800</th>\n",
       "      <td>0.009141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35753</th>\n",
       "      <td>-0.007819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37193</th>\n",
       "      <td>-0.025015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>-0.030370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37759</th>\n",
       "      <td>-0.044457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37896</th>\n",
       "      <td>-0.061464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36779</th>\n",
       "      <td>-0.065797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37507</th>\n",
       "      <td>-0.081411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36774</th>\n",
       "      <td>-0.129330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37897</th>\n",
       "      <td>-0.248943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Score\n",
       "ItemID          \n",
       "37657   0.100747\n",
       "36493   0.094613\n",
       "37801   0.093326\n",
       "36034   0.061902\n",
       "37017   0.060956\n",
       "37445   0.056658\n",
       "36917   0.051948\n",
       "36773   0.031359\n",
       "36775   0.012558\n",
       "37800   0.009141\n",
       "35753  -0.007819\n",
       "37193  -0.025015\n",
       "34998  -0.030370\n",
       "37759  -0.044457\n",
       "37896  -0.061464\n",
       "36779  -0.065797\n",
       "37507  -0.081411\n",
       "36774  -0.129330\n",
       "37897  -0.248943"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val_hat[y_val_hat[\"UserID\"] == 35735].groupby(\"ItemID\").aggregate({\"Score\": \"mean\"}).sort_values(\"Score\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'UserID': 35735,\n",
       " 'ItemID': [[37657,\n",
       "   36493,\n",
       "   37801,\n",
       "   36034,\n",
       "   37017,\n",
       "   37445,\n",
       "   36917,\n",
       "   36773,\n",
       "   36775,\n",
       "   37800]]}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_predictions_dicts = (\n",
    "    pl.from_pandas(y_val_hat)\n",
    "    .group_by(\"UserID\", \"ItemID\")\n",
    "    .agg(pl.mean(\"Score\"))\n",
    "    .sort(\"UserID\", \"Score\", descending=True)\n",
    "    .group_by(\"UserID\")\n",
    "    .head(10)\n",
    "    .group_by(\"UserID\")\n",
    "    .agg(item_to_list())\n",
    "    .to_dicts()\n",
    ")\n",
    "val_predictions_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions_dict = encode_user_dicts(val_predictions_dicts)\n",
    "val_items_dict = encode_user_dicts(val_items_dicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18314"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_items_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35736"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_predictions_dict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute recommendation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_at_k(predictions: dict[int, list], true_labels: dict[int, list], k=10):\n",
    "    \"\"\"\n",
    "    Compute Mean Average Precision at K (MAP@K).\n",
    "\n",
    "    Parameters:\n",
    "    - predictions: A list of lists, where each inner list contains the predicted item IDs for a user (ranked in descending order of relevance).\n",
    "    - true_labels: A list of sets, where each set contains the ground-truth relevant item IDs for the corresponding user.\n",
    "    - k: The cutoff for precision evaluation.\n",
    "\n",
    "    Returns:\n",
    "    - mean_ap: Mean Average Precision at K across all users.\n",
    "    \"\"\"\n",
    "    def average_precision_at_k(predicted, actual, k):\n",
    "        if len(predicted) > k:\n",
    "            predicted = predicted[:k]\n",
    "\n",
    "        score = 0.0\n",
    "        num_hits = 0.0\n",
    "\n",
    "        for i, p in enumerate(predicted):\n",
    "            if p in actual and p not in predicted[:i]:  # Avoid duplicates\n",
    "                num_hits += 1.0\n",
    "                score += num_hits / (i + 1.0)\n",
    "\n",
    "        if not actual:\n",
    "            return 0.0\n",
    "\n",
    "        return score / min(len(actual), k)\n",
    "\n",
    "    # Calculate AP@K for each user\n",
    "    ap_scores = [\n",
    "        average_precision_at_k(predictions[user], true, k)\n",
    "        for user, true in true_labels.items()\n",
    "    ]\n",
    "\n",
    "    # Return the mean AP@K\n",
    "    return np.mean(ap_scores) / len(ap_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.558615161058339e-06"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_at_k(val_predictions_dict, val_items_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How to perform hyperparameter tuning?\n",
    "\n",
    "The issue with this method is that you need a label which should be an item the user has not interacted with but that is a correct recommendation. In practice the idea is:\n",
    "- Split the data in the usual training-validation-test\n",
    "- Split the training data in two: one part you use to train the recommenders and another you use as the hidden Label to train XGBoost\n",
    "- Evaluate your predictions on the validation data as you did for any other recommender model. Use this to select the optimal hyperparameters.\n",
    "- Given the selected hyperparameters, train the recommender models on all the available data and use all the available data to compute the features used by XGBoost.\n",
    "\n",
    "Challenge: Since the label we use for training XGBoost is the split of a split, it may happen that the actual correct recommendations are very few. This will result in a problem that is very unbalanced towards zero and will make the training difficult and the evaluation noisy. To mitigate this you may use k-fold cross validation and define the valdation result of a certain hyperparameter configuration as the average obtained with k different training-label splits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import optuna\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define the hyperparameter search space\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.01, 0.3)\n",
    "    n_estimators = trial.suggest_int(\"n_estimators\", 50, 500)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 3, 10)\n",
    "    reg_alpha = trial.suggest_float(\"reg_alpha\", 0.0, 1.0)\n",
    "    reg_lambda = trial.suggest_float(\"reg_lambda\", 0.0, 1.0)\n",
    "    subsample = trial.suggest_float(\"subsample\", 0.5, 1.0)\n",
    "    colsample_bytree = trial.suggest_float(\"colsample_bytree\", 0.5, 1.0)\n",
    "\n",
    "    # Initialize the XGBoost model\n",
    "    model = XGBRanker(\n",
    "        objective=\"rank:pairwise\",\n",
    "        learning_rate=learning_rate,\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        reg_alpha=reg_alpha,\n",
    "        reg_lambda=reg_lambda,\n",
    "        subsample=subsample,\n",
    "        colsample_bytree=colsample_bytree,\n",
    "    )\n",
    "\n",
    "    # Perform k-fold cross-validation\n",
    "    kf = KFold(n_splits=5)\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "        groups_train = groups[train_idx]\n",
    "        groups_val = groups[val_idx]\n",
    "\n",
    "        model.fit(\n",
    "            X_train_fold, y_train_fold, group=groups_train, eval_metric=\"ndcg\",\n",
    "            eval_set=[(X_val_fold, y_val_fold)], verbose=False, early_stopping_rounds=10\n",
    "        )\n",
    "        predictions = model.predict(X_val_fold)\n",
    "        score = map(predictions, y_val_fold)  # Replace with your metric\n",
    "        scores.append(score)\n",
    "\n",
    "    return sum(scores) / len(scores)  # Average score over k folds\n",
    "\n",
    "# Run the optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6166</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142024</td>\n",
       "      <td>0.421410</td>\n",
       "      <td>0.353835</td>\n",
       "      <td>0.270525</td>\n",
       "      <td>129</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11966</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145097</td>\n",
       "      <td>0.267107</td>\n",
       "      <td>0.893614</td>\n",
       "      <td>0.283992</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2743</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.452733</td>\n",
       "      <td>0.195061</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>0.521364</td>\n",
       "      <td>0.284803</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2637</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197307</td>\n",
       "      <td>0.381694</td>\n",
       "      <td>0.790003</td>\n",
       "      <td>0.218590</td>\n",
       "      <td>67</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>738</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.694155</td>\n",
       "      <td>0.103107</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.318969</td>\n",
       "      <td>0.093946</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37445</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.411239</td>\n",
       "      <td>0.408742</td>\n",
       "      <td>0.455056</td>\n",
       "      <td>3.137702</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36917</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.380329</td>\n",
       "      <td>0.453475</td>\n",
       "      <td>0.383239</td>\n",
       "      <td>2.259961</td>\n",
       "      <td>0.839466</td>\n",
       "      <td>76</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>36034</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.576296</td>\n",
       "      <td>0.430645</td>\n",
       "      <td>0.403139</td>\n",
       "      <td>2.485576</td>\n",
       "      <td>1.015675</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>36493</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11.521591</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.614241</td>\n",
       "      <td>2.720541</td>\n",
       "      <td>1.047983</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0            0   6166  user_wide_hybrid        7                      2   \n",
       "1            0  11966  user_wide_hybrid        6                      1   \n",
       "2            0   2743  user_wide_hybrid        5                      1   \n",
       "3            0   2637                22        8                      1   \n",
       "4            0    738                22        9                      1   \n",
       "...        ...    ...               ...      ...                    ...   \n",
       "1786795  35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796  35735  37445  user_wide_hybrid        4                      5   \n",
       "1786797  35735  36917  user_wide_hybrid        3                      5   \n",
       "1786798  35735  36034  user_wide_hybrid        2                      5   \n",
       "1786799  35735  36493  user_wide_hybrid        1                      5   \n",
       "\n",
       "                23        21        22        20  user_wide_hybrid  \\\n",
       "0         0.000000  0.142024  0.421410  0.353835          0.270525   \n",
       "1         0.000000  0.145097  0.267107  0.893614          0.283992   \n",
       "2         1.452733  0.195061  0.273309  0.521364          0.284803   \n",
       "3         0.000000  0.197307  0.381694  0.790003          0.218590   \n",
       "4         1.694155  0.103107  0.370141  0.318969          0.093946   \n",
       "...            ...       ...       ...       ...               ...   \n",
       "1786795   8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796   7.411239  0.408742  0.455056  3.137702          0.680556   \n",
       "1786797   8.380329  0.453475  0.383239  2.259961          0.839466   \n",
       "1786798  10.576296  0.430645  0.403139  2.485576          1.015675   \n",
       "1786799  11.521591  0.512244  0.614241  2.720541          1.047983   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  top_10  top_100  \\\n",
       "0                    129         0.000371               114     0.0      1.0   \n",
       "1                     52         0.000568               114     0.0      1.0   \n",
       "2                     39         0.000069               114     0.0      1.0   \n",
       "3                     67         0.000177               114     0.0      1.0   \n",
       "4                     29         0.000474               114     0.0      1.0   \n",
       "...                  ...              ...               ...     ...      ...   \n",
       "1786795               88         0.003954                37     0.0      0.0   \n",
       "1786796               27         0.000132                37     0.0      0.0   \n",
       "1786797               76         0.004296                37     0.0      0.0   \n",
       "1786798               81         0.000403                37     0.0      0.0   \n",
       "1786799               33         0.000083                37     0.0      0.0   \n",
       "\n",
       "         top_1000  user_similarity  \n",
       "0             7.0         0.000183  \n",
       "1             7.0         0.000183  \n",
       "2             7.0         0.000183  \n",
       "3             7.0         0.000183  \n",
       "4             7.0         0.000183  \n",
       "...           ...              ...  \n",
       "1786795       0.0         0.000272  \n",
       "1786796       0.0         0.000272  \n",
       "1786797       0.0         0.000272  \n",
       "1786798       0.0         0.000272  \n",
       "1786799       0.0         0.000272  \n",
       "\n",
       "[1786800 rows x 17 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>6166</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142024</td>\n",
       "      <td>0.421410</td>\n",
       "      <td>0.353835</td>\n",
       "      <td>0.270525</td>\n",
       "      <td>129</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>11966</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145097</td>\n",
       "      <td>0.267107</td>\n",
       "      <td>0.893614</td>\n",
       "      <td>0.283992</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2743</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.452733</td>\n",
       "      <td>0.195061</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>0.521364</td>\n",
       "      <td>0.284803</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2637</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197307</td>\n",
       "      <td>0.381694</td>\n",
       "      <td>0.790003</td>\n",
       "      <td>0.218590</td>\n",
       "      <td>67</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>738</td>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.694155</td>\n",
       "      <td>0.103107</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.318969</td>\n",
       "      <td>0.093946</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>35735</td>\n",
       "      <td>36775</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>35735</td>\n",
       "      <td>37445</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.411239</td>\n",
       "      <td>0.408742</td>\n",
       "      <td>0.455056</td>\n",
       "      <td>3.137702</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>35735</td>\n",
       "      <td>36917</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.380329</td>\n",
       "      <td>0.453475</td>\n",
       "      <td>0.383239</td>\n",
       "      <td>2.259961</td>\n",
       "      <td>0.839466</td>\n",
       "      <td>76</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>35735</td>\n",
       "      <td>36034</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.576296</td>\n",
       "      <td>0.430645</td>\n",
       "      <td>0.403139</td>\n",
       "      <td>2.485576</td>\n",
       "      <td>1.015675</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>35735</td>\n",
       "      <td>36493</td>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11.521591</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.614241</td>\n",
       "      <td>2.720541</td>\n",
       "      <td>1.047983</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        UserID ItemID       Recommender  Ranking  recommender_agreement  \\\n",
       "0            0   6166  user_wide_hybrid        7                      2   \n",
       "1            0  11966  user_wide_hybrid        6                      1   \n",
       "2            0   2743  user_wide_hybrid        5                      1   \n",
       "3            0   2637                22        8                      1   \n",
       "4            0    738                22        9                      1   \n",
       "...        ...    ...               ...      ...                    ...   \n",
       "1786795  35735  36775  user_wide_hybrid        5                      3   \n",
       "1786796  35735  37445  user_wide_hybrid        4                      5   \n",
       "1786797  35735  36917  user_wide_hybrid        3                      5   \n",
       "1786798  35735  36034  user_wide_hybrid        2                      5   \n",
       "1786799  35735  36493  user_wide_hybrid        1                      5   \n",
       "\n",
       "                23        21        22        20  user_wide_hybrid  \\\n",
       "0         0.000000  0.142024  0.421410  0.353835          0.270525   \n",
       "1         0.000000  0.145097  0.267107  0.893614          0.283992   \n",
       "2         1.452733  0.195061  0.273309  0.521364          0.284803   \n",
       "3         0.000000  0.197307  0.381694  0.790003          0.218590   \n",
       "4         1.694155  0.103107  0.370141  0.318969          0.093946   \n",
       "...            ...       ...       ...       ...               ...   \n",
       "1786795   8.471791  0.328802  0.358924  2.157352          0.664134   \n",
       "1786796   7.411239  0.408742  0.455056  3.137702          0.680556   \n",
       "1786797   8.380329  0.453475  0.383239  2.259961          0.839466   \n",
       "1786798  10.576296  0.430645  0.403139  2.485576          1.015675   \n",
       "1786799  11.521591  0.512244  0.614241  2.720541          1.047983   \n",
       "\n",
       "         item_popularity  item_similarity  user_profile_len  top_10  top_100  \\\n",
       "0                    129         0.000371               114     0.0      1.0   \n",
       "1                     52         0.000568               114     0.0      1.0   \n",
       "2                     39         0.000069               114     0.0      1.0   \n",
       "3                     67         0.000177               114     0.0      1.0   \n",
       "4                     29         0.000474               114     0.0      1.0   \n",
       "...                  ...              ...               ...     ...      ...   \n",
       "1786795               88         0.003954                37     0.0      0.0   \n",
       "1786796               27         0.000132                37     0.0      0.0   \n",
       "1786797               76         0.004296                37     0.0      0.0   \n",
       "1786798               81         0.000403                37     0.0      0.0   \n",
       "1786799               33         0.000083                37     0.0      0.0   \n",
       "\n",
       "         top_1000  user_similarity  \n",
       "0             7.0         0.000183  \n",
       "1             7.0         0.000183  \n",
       "2             7.0         0.000183  \n",
       "3             7.0         0.000183  \n",
       "4             7.0         0.000183  \n",
       "...           ...              ...  \n",
       "1786795       0.0         0.000272  \n",
       "1786796       0.0         0.000272  \n",
       "1786797       0.0         0.000272  \n",
       "1786798       0.0         0.000272  \n",
       "1786799       0.0         0.000272  \n",
       "\n",
       "[1786800 rows x 17 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_training_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>Ranking</th>\n",
       "      <th>recommender_agreement</th>\n",
       "      <th>23</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>20</th>\n",
       "      <th>user_wide_hybrid</th>\n",
       "      <th>item_popularity</th>\n",
       "      <th>item_similarity</th>\n",
       "      <th>user_profile_len</th>\n",
       "      <th>top_10</th>\n",
       "      <th>top_100</th>\n",
       "      <th>top_1000</th>\n",
       "      <th>user_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142024</td>\n",
       "      <td>0.421410</td>\n",
       "      <td>0.353835</td>\n",
       "      <td>0.270525</td>\n",
       "      <td>129</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145097</td>\n",
       "      <td>0.267107</td>\n",
       "      <td>0.893614</td>\n",
       "      <td>0.283992</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.452733</td>\n",
       "      <td>0.195061</td>\n",
       "      <td>0.273309</td>\n",
       "      <td>0.521364</td>\n",
       "      <td>0.284803</td>\n",
       "      <td>39</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.197307</td>\n",
       "      <td>0.381694</td>\n",
       "      <td>0.790003</td>\n",
       "      <td>0.218590</td>\n",
       "      <td>67</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.694155</td>\n",
       "      <td>0.103107</td>\n",
       "      <td>0.370141</td>\n",
       "      <td>0.318969</td>\n",
       "      <td>0.093946</td>\n",
       "      <td>29</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.000183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786795</th>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8.471791</td>\n",
       "      <td>0.328802</td>\n",
       "      <td>0.358924</td>\n",
       "      <td>2.157352</td>\n",
       "      <td>0.664134</td>\n",
       "      <td>88</td>\n",
       "      <td>0.003954</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786796</th>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>7.411239</td>\n",
       "      <td>0.408742</td>\n",
       "      <td>0.455056</td>\n",
       "      <td>3.137702</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786797</th>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>8.380329</td>\n",
       "      <td>0.453475</td>\n",
       "      <td>0.383239</td>\n",
       "      <td>2.259961</td>\n",
       "      <td>0.839466</td>\n",
       "      <td>76</td>\n",
       "      <td>0.004296</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786798</th>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10.576296</td>\n",
       "      <td>0.430645</td>\n",
       "      <td>0.403139</td>\n",
       "      <td>2.485576</td>\n",
       "      <td>1.015675</td>\n",
       "      <td>81</td>\n",
       "      <td>0.000403</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1786799</th>\n",
       "      <td>user_wide_hybrid</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>11.521591</td>\n",
       "      <td>0.512244</td>\n",
       "      <td>0.614241</td>\n",
       "      <td>2.720541</td>\n",
       "      <td>1.047983</td>\n",
       "      <td>33</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1786800 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Recommender  Ranking  recommender_agreement         23  \\\n",
       "0        user_wide_hybrid        7                      2   0.000000   \n",
       "1        user_wide_hybrid        6                      1   0.000000   \n",
       "2        user_wide_hybrid        5                      1   1.452733   \n",
       "3                      22        8                      1   0.000000   \n",
       "4                      22        9                      1   1.694155   \n",
       "...                   ...      ...                    ...        ...   \n",
       "1786795  user_wide_hybrid        5                      3   8.471791   \n",
       "1786796  user_wide_hybrid        4                      5   7.411239   \n",
       "1786797  user_wide_hybrid        3                      5   8.380329   \n",
       "1786798  user_wide_hybrid        2                      5  10.576296   \n",
       "1786799  user_wide_hybrid        1                      5  11.521591   \n",
       "\n",
       "               21        22        20  user_wide_hybrid  item_popularity  \\\n",
       "0        0.142024  0.421410  0.353835          0.270525              129   \n",
       "1        0.145097  0.267107  0.893614          0.283992               52   \n",
       "2        0.195061  0.273309  0.521364          0.284803               39   \n",
       "3        0.197307  0.381694  0.790003          0.218590               67   \n",
       "4        0.103107  0.370141  0.318969          0.093946               29   \n",
       "...           ...       ...       ...               ...              ...   \n",
       "1786795  0.328802  0.358924  2.157352          0.664134               88   \n",
       "1786796  0.408742  0.455056  3.137702          0.680556               27   \n",
       "1786797  0.453475  0.383239  2.259961          0.839466               76   \n",
       "1786798  0.430645  0.403139  2.485576          1.015675               81   \n",
       "1786799  0.512244  0.614241  2.720541          1.047983               33   \n",
       "\n",
       "         item_similarity  user_profile_len  top_10  top_100  top_1000  \\\n",
       "0               0.000371               114     0.0      1.0       7.0   \n",
       "1               0.000568               114     0.0      1.0       7.0   \n",
       "2               0.000069               114     0.0      1.0       7.0   \n",
       "3               0.000177               114     0.0      1.0       7.0   \n",
       "4               0.000474               114     0.0      1.0       7.0   \n",
       "...                  ...               ...     ...      ...       ...   \n",
       "1786795         0.003954                37     0.0      0.0       0.0   \n",
       "1786796         0.000132                37     0.0      0.0       0.0   \n",
       "1786797         0.004296                37     0.0      0.0       0.0   \n",
       "1786798         0.000403                37     0.0      0.0       0.0   \n",
       "1786799         0.000083                37     0.0      0.0       0.0   \n",
       "\n",
       "         user_similarity  \n",
       "0               0.000183  \n",
       "1               0.000183  \n",
       "2               0.000183  \n",
       "3               0.000183  \n",
       "4               0.000183  \n",
       "...                  ...  \n",
       "1786795         0.000272  \n",
       "1786796         0.000272  \n",
       "1786797         0.000272  \n",
       "1786798         0.000272  \n",
       "1786799         0.000272  \n",
       "\n",
       "[1786800 rows x 15 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_training_dataframe.drop(columns=[\"UserID\", \"ItemID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{35735: [37657, 36493, 36773, 36917, 36034, 37445, 37660, 36920, 37865, 36775],\n",
       " 35734: [37069, 36610, 36168, 35345, 37550, 37067, 35093, 36880, 37803, 36094],\n",
       " 35733: [37853, 37388, 37372, 36056, 38072, 37540, 37858, 36676, 28418, 28304],\n",
       " 35732: [27590, 37317, 27644, 31350, 38005, 33330, 37402, 27814, 37109, 36919],\n",
       " 35731: [37739, 36263, 38027, 37427, 36525, 37623, 28119, 35394, 36856, 27349],\n",
       " 35730: [28247, 38027, 37211, 37420, 37739, 37874, 27350, 28119, 37719, 37631],\n",
       " 35729: [36844, 26093, 24415, 24417, 35548, 36527, 26581, 27531, 37461, 27067],\n",
       " 35728: [35370, 35777, 36665, 14090, 19651, 28374, 37565, 27497, 27510, 36346],\n",
       " 35727: [37280, 27520, 28088, 28203, 37416, 37291, 37712, 28097, 14664, 27693],\n",
       " 35726: [37851, 37940, 37527, 28447, 27768, 37740, 28234, 36866, 38045, 37510],\n",
       " 35725: [36652, 37540, 28458, 37431, 37661, 37785, 38018, 28547, 37924, 27623],\n",
       " 35724: [28281, 37178, 37940, 36866, 27346, 36504, 26869, 27689, 27756, 37461],\n",
       " 35723: [28461, 28247, 36065, 37739, 36567, 27161, 37211, 28424, 37899, 27662],\n",
       " 35722: [37731, 27593, 37902, 27364, 35269, 36063, 27720, 27485, 20545, 36718],\n",
       " 35721: [37958, 36027, 37983, 20107, 37120, 37785, 35906, 36016, 38018, 28418],\n",
       " 35720: [33877, 28165, 35531, 37372, 20106, 36346, 35882, 35162, 37958, 36676],\n",
       " 35719: [26188, 27505, 26609, 26225, 27772, 27374, 35904, 28306, 37498, 36929],\n",
       " 35718: [28164, 34482, 37158, 27828, 26917, 35566, 37225, 35561, 27416, 37666],\n",
       " 35717: [35951, 35584, 31577, 28547, 27623, 26932, 37177, 37124, 37222, 26688],\n",
       " 35716: [28419, 27134, 26795, 35278, 35219, 27807, 27604, 27751, 20331, 34174],\n",
       " 35715: [37910, 38112, 27638, 28133, 26351, 28241, 37105, 34775, 36397, 26105],\n",
       " 35714: [27807, 27720, 35374, 26424, 35561, 26922, 26330, 37433, 28334, 28288],\n",
       " 35713: [31336, 27045, 27815, 19675, 32257, 33919, 32226, 25750, 26001, 32402],\n",
       " 35712: [36806, 36579, 32572, 26357, 36974, 38115, 27338, 28110, 24704, 26963],\n",
       " 35711: [30374, 34421, 35218, 35016, 36467, 14673, 27172, 14462, 26761, 26811],\n",
       " 35710: [36902, 26848, 34426, 34119, 22822, 28012, 28162, 36826, 36595, 35017],\n",
       " 35709: [28162, 26475, 33617, 37985, 34426, 37637, 35945, 35017, 31381, 30908],\n",
       " 35708: [26794, 27106, 27067, 25415, 28025, 27655, 28020, 27583, 28292, 36802],\n",
       " 35707: [34983, 26851, 2474, 25591, 37604, 34985, 27675, 26609, 36241, 26263],\n",
       " 35706: [33570, 34254, 37160, 37870, 37884, 35960, 11040, 37259, 35612, 27720],\n",
       " 35705: [36844, 26794, 36439, 25417, 26302, 25436, 37510, 23844, 37740, 28532],\n",
       " 35704: [28273, 25415, 37880, 27784, 28513, 27709, 27580, 27423, 36001, 37872],\n",
       " 35703: [27580, 31020, 28306, 20576, 27671, 25639, 27047, 27443, 28226, 25640],\n",
       " 35702: [28262, 37913, 27720, 37527, 25412, 38107, 25406, 25369, 25414, 38066],\n",
       " 35701: [28470, 37731, 27852, 28521, 31947, 28094, 25415, 20479, 27513, 37607],\n",
       " 35700: [27859, 36438, 25418, 31045, 35254, 32063, 25420, 26682, 28110, 28001],\n",
       " 35699: [36397, 27205, 33928, 27485, 37105, 34318, 33743, 28177, 34110, 27357],\n",
       " 35698: [35438, 36676, 36755, 35187, 36249, 35650, 26356, 36346, 36940, 35876],\n",
       " 35697: [35218, 34421, 35654, 35016, 14673, 26242, 14462, 35151, 33126, 35240],\n",
       " 35696: [37382, 31751, 32165, 25784, 27027, 26099, 28025, 7964, 37733, 24915],\n",
       " 35695: [34833, 27650, 34848, 25795, 36330, 34509, 36813, 33214, 24188, 14343],\n",
       " 35694: [38027, 27426, 37211, 37874, 35995, 28119, 37321, 28351, 36065, 36263],\n",
       " 35693: [34201, 24936, 25249, 20289, 27216, 24922, 24935, 32537, 36025, 33479],\n",
       " 35692: [35932, 36991, 33825, 28519, 36297, 27008, 34425, 26356, 35125, 27024],\n",
       " 35691: [27972, 20399, 26471, 25046, 35799, 37001, 26972, 28100, 27135, 27423],\n",
       " 35690: [34645, 36635, 36701, 36548, 36055, 32572, 26429, 35099, 26646, 28110],\n",
       " 35689: [14343, 37925, 37541, 24912, 27607, 28361, 27328, 24755, 36900, 37250],\n",
       " 35688: [27759, 28432, 36008, 36144, 37565, 36645, 26932, 35187, 26390, 36665],\n",
       " 35687: [28323, 28479, 28438, 28466, 35428, 31874, 31875, 27537, 26256, 33263],\n",
       " 35686: [37712, 28413, 37864, 23712, 25077, 27165, 25352, 28192, 27912, 28129],\n",
       " 35685: [24878, 26797, 34873, 34425, 28331, 34362, 35404, 36298, 34732, 35169],\n",
       " 35684: [24878, 26430, 36980, 26107, 27008, 35988, 34425, 33825, 28064, 26397],\n",
       " 35683: [36544, 36665, 24629, 25918, 33785, 36452, 35370, 37372, 35989, 26906],\n",
       " 35682: [25968, 28104, 25863, 27290, 27348, 20175, 36532, 20176, 37816, 26930],\n",
       " 35681: [36355, 20397, 37108, 37711, 36069, 37578, 14681, 28026, 36397, 27317],\n",
       " 35680: [36296, 35960, 32380, 14681, 32001, 31876, 31877, 26113, 35151, 31875],\n",
       " 35679: [28088, 26113, 28442, 38045, 27693, 28441, 37331, 37515, 38109, 37202],\n",
       " 35678: [26217, 25486, 34543, 26394, 28229, 26553, 26751, 26453, 26170, 37541],\n",
       " 35677: [27689, 24186, 28561, 36866, 27106, 32146, 28025, 37510, 35548, 37287],\n",
       " 35676: [25295, 25570, 34694, 26217, 32314, 34684, 26868, 27796, 34543, 26553],\n",
       " 35675: [30927, 37840, 28416, 28306, 26225, 35647, 25353, 26827, 27030, 34317],\n",
       " 35674: [25179, 34211, 36536, 26971, 27008, 25210, 25500, 25119, 35077, 36433],\n",
       " 35673: [24500, 27739, 37268, 37343, 34211, 36544, 36249, 34892, 35041, 25496],\n",
       " 35672: [32718, 20498, 25440, 33263, 33284, 33003, 8095, 8072, 7964, 20063],\n",
       " 35671: [26875, 26827, 27443, 25435, 20305, 25234, 27913, 20744, 26471, 26609],\n",
       " 35670: [23846, 36439, 23841, 23712, 25418, 25419, 25426, 25411, 25435, 20305],\n",
       " 35669: [30169, 34167, 37984, 27783, 27626, 37913, 27067, 2476, 11128, 25718],\n",
       " 35668: [25286, 33791, 25465, 25466, 25301, 31873, 25136, 33766, 26652, 32754],\n",
       " 35667: [34795, 28519, 35370, 36144, 36893, 34290, 36536, 36357, 26698, 35397],\n",
       " 35666: [34543, 24773, 35414, 37186, 27128, 28501, 34790, 25055, 27800, 37319],\n",
       " 35665: [26078, 35216, 10564, 34135, 28298, 32714, 31842, 35570, 35473, 31614],\n",
       " 35664: [24771, 32843, 34118, 22903, 32890, 33734, 36344, 36002, 30925, 34340],\n",
       " 35663: [30914, 25565, 26513, 22819, 22870, 33159, 31325, 33220, 22896, 30885],\n",
       " 35662: [34206, 27579, 26809, 27575, 27655, 36738, 36083, 37940, 27345, 33297],\n",
       " 35661: [34790, 37379, 24538, 24384, 27424, 36595, 26762, 25055, 34629, 24408],\n",
       " 35660: [26875, 26113, 20535, 26298, 19508, 31811, 25352, 31803, 11134, 26007],\n",
       " 35659: [22067, 22217, 22208, 22190, 35386, 22188, 22154, 22200, 22196, 22179],\n",
       " 35658: [31021, 25436, 37041, 27225, 26712, 27067, 26424, 14579, 26950, 25415],\n",
       " 35657: [37108, 38042, 27110, 35784, 22825, 35847, 28219, 28427, 33904, 26848],\n",
       " 35656: [31846, 27575, 31849, 34602, 27577, 24774, 36370, 28551, 25392, 27300],\n",
       " 35655: [27502, 25106, 34770, 34253, 24022, 25732, 33908, 28315, 28323, 27537],\n",
       " 35654: [31999, 34324, 32063, 28110, 31998, 33850, 33319, 25136, 35581, 26963],\n",
       " 35653: [25486, 25208, 26868, 25565, 27800, 25246, 25243, 27426, 26202, 32778],\n",
       " 35652: [26254, 20574, 28065, 28226, 27231, 37341, 21095, 36453, 28137, 20575],\n",
       " 35651: [14652, 35012, 34415, 34212, 28251, 20488, 37994, 36635, 27485, 28014],\n",
       " 35650: [25426, 25392, 37592, 27844, 28226, 28415, 28198, 28200, 25699, 36920],\n",
       " 35649: [30828, 30827, 24388, 26501, 27509, 23847, 30955, 24993, 23840, 23841],\n",
       " 35648: [27318, 19618, 35096, 37985, 23845, 36612, 36468, 31657, 27580, 26914],\n",
       " 35647: [27611, 31020, 37432, 27844, 25392, 25426, 36612, 36223, 14579, 20575],\n",
       " 35646: [35897, 26134, 26639, 28285, 34849, 26680, 35530, 25572, 28373, 25571],\n",
       " 35645: [36906, 34747, 28470, 14620, 37535, 28442, 36355, 26886, 28357, 37527],\n",
       " 35644: [27578, 37622, 30855, 36876, 11135, 20488, 37960, 20712, 27989, 28530],\n",
       " 35643: [36806, 37515, 28192, 37527, 28353, 28097, 28100, 11135, 28428, 27732],\n",
       " 35642: [24182, 37775, 37108, 37573, 37913, 27861, 38069, 28154, 28490, 27713],\n",
       " 35641: [36157, 28100, 28213, 33965, 35647, 27917, 28203, 27732, 34674, 27231],\n",
       " 35640: [28053, 20766, 14621, 37341, 27208, 36064, 27690, 38006, 28245, 31877],\n",
       " 35639: [26038, 25570, 33277, 32624, 33540, 25225, 7789, 32673, 33382, 12335],\n",
       " 35638: [36806, 31885, 37168, 31887, 28100, 37416, 37291, 28129, 37871, 28192],\n",
       " 35637: [28101, 28353, 25224, 25716, 28395, 38033, 34658, 35302, 27288, 27310],\n",
       " 35636: [38016, 37689, 37653, 28441, 31036, 31037, 36502, 30326, 20776, 19720],\n",
       " 35635: [34841, 28414, 32071, 27989, 28354, 28464, 28198, 20574, 25406, 27544],\n",
       " 35634: [27111, 20739, 20574, 27709, 33724, 20575, 31181, 36087, 33698, 27172],\n",
       " 35633: [26131, 37132, 20766, 14654, 36832, 20763, 37919, 37712, 27539, 37416],\n",
       " 35632: [26785, 36468, 28100, 27190, 27732, 27520, 27745, 28397, 27423, 25420],\n",
       " 35631: [27675, 37984, 28158, 20488, 20717, 28200, 37009, 20747, 38092, 38069],\n",
       " 35630: [37622, 27709, 37713, 28129, 28020, 37930, 37424, 11135, 20388, 11134],\n",
       " 35629: [37280, 27917, 27732, 38100, 28353, 28100, 37507, 28020, 36448, 28464],\n",
       " 35628: [32916, 27091, 20487, 20488, 37667, 30650, 27989, 34129, 20205, 31012],\n",
       " 35627: [37768, 38092, 37667, 37721, 20488, 30961, 20487, 30963, 32081, 31012],\n",
       " 35626: [37209, 35845, 26730, 38007, 32104, 32000, 32114, 37014, 34349, 37646],\n",
       " 35625: [28252, 25415, 19938, 36999, 19939, 28097, 38115, 14709, 37712, 37026],\n",
       " 35624: [27423, 28100, 31975, 20488, 28353, 27989, 31974, 37667, 38092, 31973],\n",
       " 35623: [25039, 24455, 24382, 34963, 26647, 24045, 36005, 24189, 36489, 33949],\n",
       " 35622: [35591, 27696, 27963, 36129, 36622, 20740, 28500, 37198, 26851, 27917],\n",
       " 35621: [14621, 28158, 27092, 37774, 20632, 28306, 27693, 28550, 35012, 35444],\n",
       " 35620: [37930, 27583, 38116, 20740, 28448, 31584, 37497, 31580, 28004, 27784],\n",
       " 35619: [37491, 20740, 28318, 38022, 37341, 36943, 30954, 37550, 36129, 35441],\n",
       " 35618: [27193, 37101, 28306, 32055, 37329, 28097, 28397, 27917, 24181, 36308],\n",
       " 35617: [37893, 26780, 35520, 14655, 27841, 35521, 36463, 37241, 37904, 28368],\n",
       " 35616: [36361, 28359, 35253, 14709, 37712, 37257, 27768, 20677, 28176, 37855],\n",
       " 35615: [31581, 31583, 36877, 37101, 32069, 20305, 14612, 31585, 19980, 20728],\n",
       " 35614: [36645, 35900, 23893, 36231, 26016, 35468, 34783, 35077, 36830, 35584],\n",
       " 35613: [37527, 37713, 36569, 14654, 35708, 27208, 26937, 20576, 20575, 28343],\n",
       " 35612: [36427, 31876, 28197, 28353, 28337, 26909, 25435, 27047, 26682, 35012],\n",
       " 35611: [37574, 27376, 37362, 36541, 14657, 36409, 37828, 31039, 28443, 27784],\n",
       " 35610: [32050, 37813, 26302, 27298, 38045, 35160, 25076, 37902, 26923, 35790],\n",
       " 35609: [20634, 30503, 20635, 25699, 37865, 28540, 27437, 37910, 28562, 37942],\n",
       " 35608: [27769, 31765, 27236, 27374, 37774, 27278, 27242, 37053, 28169, 37022],\n",
       " 35607: [28353, 36047, 14621, 28205, 27812, 27805, 28549, 27543, 38030, 31977],\n",
       " 35606: [28349, 27963, 27607, 27935, 28476, 27709, 20632, 27304, 28353, 36107],\n",
       " 35605: [25518, 26885, 25606, 24412, 31847, 27105, 31967, 34819, 27122, 34261],\n",
       " 35604: [26727, 35556, 37886, 25415, 36006, 35308, 38117, 36488, 25431, 27134],\n",
       " 35603: [27923, 27092, 27221, 27784, 36108, 25411, 20633, 35521, 28353, 36937],\n",
       " 35602: [28246, 24179, 20635, 25363, 36260, 37526, 28008, 20124, 34906, 20125],\n",
       " 35601: [28065, 35664, 27154, 36397, 20696, 36570, 27647, 36157, 27472, 26810],\n",
       " 35600: [29856, 25566, 31963, 36825, 31720, 31721, 28110, 31562, 31608, 31723],\n",
       " 35599: [37108, 26298, 36658, 25039, 36149, 27809, 37026, 27424, 22871, 27601],\n",
       " 35598: [28405, 37515, 38039, 20575, 20574, 31033, 31034, 31031, 27978, 31583],\n",
       " 35597: [36876, 37998, 37041, 20574, 20575, 27709, 37895, 28260, 28200, 37880],\n",
       " 35596: [31975, 28504, 37223, 28100, 20575, 19986, 20574, 37329, 38102, 27709],\n",
       " 35595: [27190, 20575, 20305, 28353, 37930, 28265, 27917, 25594, 20574, 27732],\n",
       " 35594: [36397, 28474, 28065, 36004, 27176, 27295, 31980, 28395, 36570, 28097],\n",
       " 35593: [27706, 37689, 36950, 37515, 27959, 36832, 37310, 37527, 27859, 36004],\n",
       " 35592: [27831, 28100, 28456, 20633, 28306, 20575, 27616, 28137, 20574, 20632],\n",
       " 35591: [27677, 21728, 27709, 27784, 27690, 25423, 21729, 20575, 28353, 37902],\n",
       " 35590: [27791, 36570, 27579, 26254, 27696, 31020, 27262, 28065, 26302, 36069],\n",
       " 35589: [36110, 37515, 37836, 20574, 37910, 34902, 28226, 25369, 14654, 28442],\n",
       " 35588: [14654, 25416, 25343, 25560, 25436, 24417, 24416, 21096, 20724, 25431],\n",
       " 35587: [28474, 36123, 37864, 28226, 27978, 37895, 28273, 27495, 21094, 27852],\n",
       " 35586: [28490, 28466, 20575, 28438, 36694, 28472, 37984, 31020, 28077, 38107],\n",
       " 35585: [20576, 25591, 25435, 27917, 21095, 25560, 25417, 25416, 25418, 27701],\n",
       " 35584: [20634, 26818, 31961, 31962, 37527, 27167, 35715, 31720, 37524, 30168],\n",
       " 35583: [37913, 37290, 37592, 25416, 27812, 28097, 27878, 21096, 25415, 38107],\n",
       " 35582: [28252, 27356, 27706, 29593, 24415, 27090, 26298, 27231, 25431, 37813],\n",
       " 35581: [28363, 20574, 14664, 36957, 37417, 28096, 37424, 36663, 27601, 36751],\n",
       " 35580: [35524, 20575, 26533, 35626, 34684, 26309, 34695, 25795, 25571, 37317],\n",
       " 35579: [27693, 20576, 28100, 27447, 37467, 14645, 27318, 26619, 28275, 26225],\n",
       " 35578: [14568, 37745, 35765, 27303, 37856, 38091, 36037, 27741, 12829, 37603],\n",
       " 35577: [36364, 20564, 20565, 27979, 26217, 20567, 33467, 26023, 27352, 27031],\n",
       " 35576: [24896, 31336, 19675, 35207, 33249, 33983, 25750, 23846, 34658, 23847],\n",
       " 35575: [20576, 20574, 27262, 20555, 27709, 37775, 27423, 28353, 20375, 27745],\n",
       " 35574: [28470, 31026, 20644, 35254, 35521, 25418, 36439, 31033, 25434, 31032],\n",
       " 35573: [26928, 31810, 27135, 26298, 35939, 27744, 25392, 27655, 27785, 32813],\n",
       " 35572: [28262, 26761, 36947, 20667, 24412, 31994, 28316, 20676, 26767, 26412],\n",
       " 35571: [26368, 37579, 27957, 26427, 28331, 32670, 35429, 34342, 27008, 35169],\n",
       " 35570: [28008, 27926, 31732, 28323, 28368, 20535, 37026, 37535, 28474, 37423],\n",
       " 35569: [26269, 36982, 21095, 27423, 35217, 37039, 28100, 35847, 26959, 37985],\n",
       " 35568: [27785, 20637, 31852, 37058, 27135, 25077, 24423, 28267, 36001, 27601],\n",
       " 35567: [28264, 28065, 27579, 27675, 36844, 27831, 37960, 20532, 36230, 28282],\n",
       " 35566: [20574, 33354, 27345, 20529, 20576, 25392, 27455, 28025, 25389, 24389],\n",
       " 35565: [27506, 14654, 26875, 25415, 27231, 24417, 25416, 27030, 26827, 26535],\n",
       " 35564: [28481, 37497, 37259, 28428, 28049, 28226, 28097, 37585, 31582, 37807],\n",
       " 35563: [27236, 27785, 26254, 27649, 25415, 36663, 31978, 25167, 26712, 28226],\n",
       " 35562: [37481, 37510, 36844, 28281, 37636, 36866, 26491, 27633, 20730, 32057],\n",
       " 35561: [28292, 20677, 25167, 25419, 35715, 25418, 26420, 36438, 35662, 20730],\n",
       " 35560: [36560, 36078, 31345, 27167, 20632, 20554, 31343, 20523, 27745, 20563],\n",
       " 35559: [27255, 34702, 28248, 37062, 36008, 35370, 27481, 37388, 36652, 35283],\n",
       " 35558: [28088, 37371, 37432, 37925, 12442, 35985, 20488, 27693, 14586, 36086],\n",
       " 35557: [37881, 35584, 35777, 36052, 35370, 28547, 35988, 27739, 27957, 36458],\n",
       " 35556: [37423, 26351, 28088, 27723, 27831, 27693, 20499, 28479, 38057, 35466],\n",
       " 35555: [27805, 30755, 25716, 36873, 20499, 20388, 28353, 27271, 27577, 20554],\n",
       " 35554: [27607, 27858, 36123, 28332, 31765, 27179, 28368, 35893, 27345, 37038],\n",
       " 35553: [37497, 36984, 20500, 20633, 35278, 36750, 37742, 28476, 37276, 31580],\n",
       " 35552: [27580, 28353, 21095, 25077, 25591, 23712, 25416, 25343, 20576, 20574],\n",
       " 35551: [36299, 27504, 36509, 21095, 36558, 35831, 37261, 28226, 34662, 35436],\n",
       " 35550: [31026, 26399, 32057, 31034, 31031, 25423, 31032, 31020, 14615, 14623],\n",
       " 35549: [26960, 36397, 37813, 26813, 20555, 35943, 14546, 25591, 28268, 20375],\n",
       " 35548: [28213, 26984, 26681, 37037, 27785, 14673, 27638, 28005, 27786, 15332],\n",
       " 35547: [27092, 35304, 36004, 20607, 28387, 27040, 27709, 27654, 26404, 26276],\n",
       " 35546: [36866, 38024, 37940, 36744, 32701, 35548, 33625, 27003, 37218, 28364],\n",
       " 35545: [31021, 28192, 28476, 14579, 20485, 27835, 28038, 20483, 36616, 20632],\n",
       " 35544: [14615, 28401, 14671, 25418, 31797, 21730, 26379, 20484, 20607, 14623],\n",
       " 35543: [31567, 28353, 20479, 27977, 26803, 27231, 35160, 24495, 26041, 27675],\n",
       " 35542: [20574, 25076, 20594, 25437, 25591, 25392, 28306, 28025, 25369, 27779],\n",
       " 35541: [27262, 14586, 26875, 20481, 7905, 27172, 27254, 37314, 28226, 37592],\n",
       " 35540: [20704, 35218, 37014, 14673, 34805, 25415, 25379, 34569, 25380, 35012],\n",
       " 35539: [26194, 26298, 26619, 14579, 25392, 20305, 25417, 26854, 25343, 27030],\n",
       " 35538: [14317, 24965, 26467, 18282, 25701, 20305, 23846, 26501, 35160, 27208],\n",
       " 35537: [36841, 27864, 25179, 27497, 31825, 37595, 33877, 36061, 27726, 36867],\n",
       " 35536: [27798, 36397, 27650, 26170, 33660, 26480, 37105, 36261, 28390, 14343],\n",
       " 35535: [37913, 23703, 20397, 37813, 35879, 38069, 20456, 20457, 38016, 27455],\n",
       " 35534: [26715, 37026, 26552, 14709, 28129, 37807, 27784, 27761, 38087, 20457],\n",
       " 35533: [32388, 27524, 25233, 25187, 8324, 33514, 24800, 25508, 24768, 30755],\n",
       " 35532: [25853, 35807, 30755, 33823, 24686, 25187, 38012, 23712, 25140, 26778],\n",
       " 35531: [34833, 34104, 30919, 20290, 26474, 28006, 34213, 36330, 26654, 33814],\n",
       " 35530: [28371, 25897, 28421, 31977, 37833, 27814, 37631, 35431, 20315, 26018],\n",
       " 35529: [28273, 20632, 20575, 28100, 38094, 37259, 37864, 25415, 37432, 37834],\n",
       " 35528: [27231, 27807, 33350, 34896, 30184, 37038, 37742, 37509, 20500, 37376],\n",
       " 35527: [28456, 20574, 28554, 32055, 27709, 20548, 28226, 36070, 20748, 27423],\n",
       " 35526: [20546, 27300, 27374, 24388, 26505, 26886, 27978, 25437, 37484, 20420],\n",
       " 35525: [28200, 31947, 35160, 27784, 28226, 34427, 25437, 26712, 20420, 20744],\n",
       " 35524: [27403, 28208, 37139, 20526, 36336, 26025, 27451, 28436, 20413, 21096],\n",
       " 35523: [26835, 20402, 24416, 25380, 20401, 26744, 25415, 24417, 27917, 20406],\n",
       " 35522: [36608, 32065, 34791, 26750, 28504, 19255, 37588, 20773, 37477, 36813],\n",
       " 35521: [27525, 36806, 28252, 36004, 38115, 27455, 28200, 37666, 27541, 28241],\n",
       " 35520: [37472, 35350, 20550, 27221, 36397, 27154, 21095, 36937, 27129, 15330],\n",
       " 35519: [26803, 27193, 27977, 27074, 20575, 24416, 28250, 20566, 20393, 20392],\n",
       " 35518: [32047, 27165, 27374, 27923, 20633, 27844, 20392, 20632, 37866, 20715],\n",
       " 35517: [36677, 20107, 26606, 34524, 36757, 28243, 35760, 37177, 36942, 37431],\n",
       " 35516: [37291, 20387, 36213, 20717, 28180, 28353, 37416, 36083, 20386, 25640],\n",
       " 35515: [20714, 28464, 25397, 27236, 37479, 35601, 28538, 27254, 25398, 36921],\n",
       " 35514: [25415, 38027, 11134, 25392, 27930, 37381, 37153, 27172, 28096, 11135],\n",
       " 35513: [34200, 36573, 27356, 34672, 28552, 37864, 37720, 27878, 20575, 20535],\n",
       " 35512: [20593, 20575, 26254, 27859, 25416, 20576, 25415, 20386, 14414, 27345],\n",
       " 35511: [26357, 20386, 27390, 20716, 28048, 27072, 36825, 25566, 20718, 28110],\n",
       " 35510: [37535, 28114, 20479, 26535, 27401, 25415, 20388, 20715, 26922, 20714],\n",
       " 35509: [20606, 27745, 27047, 27030, 24965, 20714, 37527, 31045, 27913, 20388],\n",
       " 35508: [37640, 27423, 27057, 36107, 27647, 25415, 36570, 28353, 37083, 26332],\n",
       " 35507: [26886, 20576, 20376, 25436, 25507, 26992, 27978, 20305, 26861, 33994],\n",
       " 35506: [26624, 31883, 27561, 31880, 27595, 26852, 31887, 37156, 31886, 20673],\n",
       " 35505: [28110, 35332, 34135, 36825, 24455, 20362, 26429, 26202, 20481, 25851],\n",
       " 35504: [26631, 28008, 33906, 26886, 28100, 20574, 26105, 32081, 27671, 27423],\n",
       " 35503: [20532, 33394, 25968, 25411, 32788, 32643, 36713, 26654, 27450, 26206],\n",
       " 35502: [20632, 26269, 27675, 20344, 28476, 24495, 28200, 14546, 27575, 28268],\n",
       " 35501: [20698, 36872, 27250, 14654, 20344, 27583, 14100, 27236, 37497, 20343],\n",
       " 35500: [28474, 20343, 27852, 27495, 24574, 26535, 26867, 25560, 28114, 27185],\n",
       " 35499: [24495, 24388, 28200, 23712, 25077, 28029, 20575, 14215, 28537, 25352],\n",
       " 35498: [25090, 34843, 26951, 27518, 32763, 20339, 25486, 20338, 36364, 26208],\n",
       " 35497: [26395, 20340, 26008, 35490, 26842, 8324, 25965, 24568, 26875, 24768],\n",
       " 35496: [35282, 33887, 35047, 28323, 28368, 35723, 25398, 28438, 21826, 28292],\n",
       " 35495: [30911, 32898, 36707, 30915, 27234, 30918, 30920, 35081, 35660, 34305],\n",
       " 35494: [32606, 28523, 28504, 37666, 37209, 34719, 36110, 33320, 38102, 20325],\n",
       " 35493: [33933, 34695, 34696, 34728, 34694, 33708, 34168, 27776, 20325, 35086],\n",
       " 35492: [36426, 30293, 28256, 35086, 33068, 33214, 26645, 35849, 37567, 27426],\n",
       " 35491: [27298, 26819, 36004, 37038, 28241, 37551, 25889, 37742, 27891, 27441],\n",
       " 35490: [28015, 36318, 20718, 38004, 36838, 35956, 7905, 25077, 36359, 25243],\n",
       " 35489: [26254, 25392, 25437, 26923, 26033, 27509, 28025, 26501, 26548, 27846],\n",
       " 35488: [25458, 33091, 37740, 36002, 25397, 28561, 25583, 27650, 37287, 28282],\n",
       " 35487: [25419, 25392, 25418, 25436, 25417, 25411, 25343, 23840, 25167, 24993],\n",
       " 35486: [37777, 37329, 34427, 37428, 25435, 32056, 25563, 25426, 24412, 36308],\n",
       " 35485: [25436, 23929, 25640, 25415, 26254, 2461, 27074, 12458, 25352, 11128],\n",
       " 35484: [37642, 25435, 25699, 27772, 24574, 28198, 26609, 27030, 26827, 37479],\n",
       " 35483: [20574, 36069, 14683, 20576, 25435, 24416, 25416, 26254, 21096, 27154],\n",
       " 35482: [25365, 26717, 27208, 11079, 25434, 25423, 20635, 27745, 31996, 11098],\n",
       " 35481: [34773, 26515, 35251, 26657, 36996, 25436, 26923, 26854, 37146, 26535],\n",
       " 35480: [28020, 25435, 20575, 25417, 25436, 20574, 27583, 36438, 27143, 26420],\n",
       " 35479: [34064, 20593, 27374, 27318, 36281, 27709, 28226, 20298, 27208, 27779],\n",
       " 35478: [28562, 31031, 37798, 20299, 27188, 34658, 26230, 20652, 35805, 27992],\n",
       " 35477: [24192, 26515, 20499, 35078, 20525, 27485, 37742, 31766, 20298, 35566],\n",
       " 35476: [14317, 30755, 33823, 25701, 23840, 25541, 25234, 23845, 24870, 26653],\n",
       " 35475: [30293, 32015, 20480, 30905, 25039, 30326, 33214, 26210, 34318, 34213],\n",
       " 35474: [27407, 36108, 20576, 36020, 28097, 26886, 27774, 27462, 37509, 20575],\n",
       " 35473: [24988, 27072, 33912, 33743, 25953, 34318, 33814, 20289, 20481, 32068],\n",
       " 35472: [25876, 26217, 26453, 25570, 25567, 24178, 25295, 26929, 27031, 25486],\n",
       " 35471: [31993, 25908, 23601, 33023, 31996, 32713, 35127, 33816, 27381, 33988],\n",
       " 35470: [33742, 33961, 20479, 34318, 35525, 32070, 20481, 33766, 34359, 32071],\n",
       " 35469: [32067, 32069, 33961, 20633, 20481, 27137, 33814, 20632, 28106, 25392],\n",
       " 35468: [36549, 28048, 26480, 37984, 25953, 27072, 28004, 37182, 37994, 27797],\n",
       " 35467: [20277, 26052, 35067, 27298, 36523, 30949, 20294, 25888, 36045, 35189],\n",
       " 35466: [36919, 25301, 35769, 11079, 25375, 31996, 26755, 36427, 26263, 27462],\n",
       " 35465: [28476, 37331, 28354, 38112, 20344, 14621, 27591, 28275, 28549, 37512],\n",
       " 35464: [20261, 27395, 27090, 27298, 37845, 27735, 28060, 36489, 26590, 20575],\n",
       " 35463: [27342, 26342, 27438, 3101, 22702, 27062, 25393, 24768, 24412, 30934],\n",
       " 35462: [25578, 30888, 26377, 26744, 27355, 36337, 36095, 25736, 38000, 20450],\n",
       " 35461: [27078, 27074, 26825, 27509, 8324, 20300, 26033, 26080, 20335, 20420],\n",
       " 35460: [26552, 26886, 27457, 20697, 20757, 26505, 28025, 27852, 27583, 27619],\n",
       " 35459: [31877, 35444, 27771, 31875, 31874, 21094, 34742, 30893, 35901, 35095],\n",
       " 35458: [28190, 28405, 28470, 37880, 28273, 27047, 28354, 14654, 27231, 20575],\n",
       " 35457: [20935, 27734, 34844, 28260, 35362, 20325, 35960, 35581, 1953, 34403],\n",
       " 35456: [14343, 27650, 26351, 27176, 26035, 36974, 20575, 30907, 20574, 22899],\n",
       " 35455: [25838, 28192, 36010, 35308, 27593, 25077, 28161, 27360, 25343, 27172],\n",
       " 35454: [27176, 20575, 28112, 27231, 26429, 36291, 27001, 27807, 22265, 28361],\n",
       " 35453: [20574, 20500, 20576, 27760, 27583, 25437, 38100, 27374, 27844, 36069],\n",
       " 35452: [28270, 35922, 27785, 27981, 36362, 31979, 26977, 27137, 35861, 27257],\n",
       " 35451: [25076, 20479, 25426, 26854, 14654, 25423, 27844, 24388, 25415, 25392],\n",
       " 35450: [34232, 25507, 33589, 27300, 37108, 27250, 24416, 28230, 26519, 37585],\n",
       " 35449: [27693, 27067, 28353, 27859, 37331, 27216, 28275, 20208, 21728, 27208],\n",
       " 35448: [20574, 37675, 38100, 25415, 37866, 28200, 27818, 31847, 28337, 27254],\n",
       " 35447: [34303, 28169, 35491, 20632, 35630, 36397, 28476, 32583, 35520, 35521],\n",
       " 35446: [37888, 26607, 25090, 27800, 25055, 26208, 37291, 28501, 20173, 20676],\n",
       " 35445: [34120, 20677, 37902, 37341, 36490, 35995, 34261, 37939, 34521, 27834],\n",
       " 35444: [37427, 37402, 28349, 27140, 28480, 31383, 37201, 36761, 36142, 34790],\n",
       " 35443: [27898, 20107, 25119, 25210, 27556, 24629, 37372, 36757, 35041, 27481],\n",
       " 35442: [34201, 20479, 27106, 14654, 35393, 27457, 27374, 36697, 28200, 35790],\n",
       " 35441: [20507, 27963, 20587, 27786, 28544, 27463, 26984, 27123, 35742, 37676],\n",
       " 35440: [28476, 30950, 35326, 37454, 30955, 38045, 20500, 30952, 30954, 37038],\n",
       " 35439: [26254, 27861, 28154, 27420, 20594, 20124, 27221, 25435, 27968, 25594],\n",
       " 35438: [20484, 27089, 26590, 34810, 27090, 35088, 28292, 28364, 28333, 28562],\n",
       " 35437: [27943, 27445, 28252, 28273, 37882, 37880, 27420, 38115, 26886, 25362],\n",
       " 35436: [26038, 26652, 34689, 25571, 32739, 34696, 34694, 34684, 8400, 26309],\n",
       " 35435: [36001, 25362, 25366, 20124, 34343, 36382, 7889, 35056, 7897, 27777],\n",
       " 35434: [37675, 27771, 35012, 20747, 34415, 27443, 25889, 27047, 25362, 24428],\n",
       " 35433: [35777, 35429, 27258, 35370, 37388, 35277, 35125, 35989, 36231, 28547],\n",
       " 35432: [36346, 37853, 37372, 37661, 36676, 38028, 28418, 37540, 38018, 20106],\n",
       " 35431: [26064, 37344, 37404, 37983, 32921, 35650, 37748, 34149, 23922, 32370],\n",
       " 35430: [30842, 25435, 36034, 27074, 27852, 25948, 35456, 20298, 38000, 36918],\n",
       " 35429: [27723, 34166, 28097, 26225, 31029, 26827, 28306, 31033, 27745, 28100],\n",
       " 35428: [35072, 30556, 26361, 34964, 25572, 34532, 34565, 25567, 25794, 25569],\n",
       " 35427: [26932, 27026, 26606, 25131, 14227, 35843, 5843, 26356, 27983, 34290],\n",
       " 35426: [33926, 35760, 19588, 34686, 35404, 34149, 20106, 35370, 35125, 27481],\n",
       " 35425: [34524, 33751, 35746, 37914, 35876, 33655, 35390, 33464, 34332, 36061],\n",
       " 35424: [34749, 20107, 35749, 34290, 35470, 35370, 27026, 34732, 26698, 35429],\n",
       " 35423: [27739, 24878, 33825, 35125, 33964, 34425, 26427, 27024, 26368, 26016],\n",
       " 35422: [34689, 34695, 34004, 25039, 33339, 34168, 26647, 32902, 29705, 33507],\n",
       " 35421: [20704, 20073, 33717, 36707, 20294, 33744, 30761, 34767, 20501, 35612],\n",
       " 35420: [26453, 20030, 36643, 20339, 27520, 27800, 26572, 31879, 37186, 31882],\n",
       " 35419: [36530, 31336, 26038, 36303, 25639, 11837, 26508, 34666, 36447, 27537],\n",
       " 35418: [33143, 36297, 36061, 36240, 35992, 37850, 33655, 26411, 35963, 36597],\n",
       " 35417: [33044, 37851, 20479, 27072, 20575, 36743, 27377, 36427, 36825, 24704],\n",
       " 35416: [24455, 35956, 35400, 22818, 24887, 28298, 22820, 27776, 22816, 28015],\n",
       " 35415: [33264, 20175, 33947, 27128, 14602, 26509, 36020, 27518, 26528, 31797],\n",
       " 35414: [24993, 26547, 30872, 20633, 27822, 25343, 20487, 25426, 31973, 25392],\n",
       " 35413: [25389, 33892, 20479, 27534, 20574, 20576, 37510, 25390, 28306, 12416],\n",
       " 35412: [19986, 31976, 31974, 38045, 28323, 37592, 31979, 27675, 26039, 25422],\n",
       " 35411: [33570, 31976, 31979, 31974, 28306, 19982, 31980, 19983, 31971, 36727],\n",
       " 35410: [27709, 20575, 25415, 27583, 28353, 36906, 31977, 27030, 35444, 20740],\n",
       " 35409: [34318, 26597, 27298, 24415, 19982, 27078, 34548, 19985, 20292, 31973],\n",
       " 35408: [31973, 31567, 19984, 31974, 19982, 35174, 35647, 19985, 31971, 20675],\n",
       " 35407: [26803, 19966, 20378, 25639, 36069, 25640, 25701, 14661, 37105, 2375],\n",
       " 35406: [20511, 25577, 19966, 25889, 26085, 27910, 24574, 26528, 20305, 20575],\n",
       " 35405: [24415, 19966, 20376, 31854, 20511, 20748, 20392, 25591, 27298, 25415],\n",
       " 35404: [20377, 25639, 36409, 27959, 28080, 19965, 33840, 35196, 17802, 36607],\n",
       " 35403: [37814, 19964, 25560, 35790, 25640, 27154, 25168, 26399, 26813, 27910],\n",
       " 35402: [28074, 27675, 27064, 20499, 37481, 37342, 37992, 27891, 37042, 28194],\n",
       " 35401: [20086, 20085, 31383, 31385, 30828, 19619, 31658, 20089, 20088, 20091],\n",
       " 35400: [26495, 19938, 26301, 27937, 25640, 28198, 26835, 27760, 27298, 20705],\n",
       " 35399: [27888, 27137, 26715, 19938, 35302, 20511, 27575, 28025, 20705, 20376],\n",
       " 35398: [26298, 31883, 19938, 20525, 20705, 27785, 31886, 27818, 28337, 31882],\n",
       " 35397: [22779, 27580, 20633, 25416, 28265, 33487, 28545, 32026, 33983, 27329],\n",
       " 35396: [33961, 33814, 20740, 20581, 28441, 35332, 28029, 24388, 28442, 27441],\n",
       " 35395: [31852, 27785, 26619, 20705, 27649, 28252, 36663, 28414, 36356, 25415],\n",
       " 35394: [37178, 26960, 27295, 36530, 27689, 27345, 26795, 31581, 31582, 19939],\n",
       " 35393: [37880, 37041, 25423, 21095, 28200, 25415, 20545, 25418, 20575, 19939],\n",
       " 35392: [27616, 20343, 36863, 36107, 27543, 38057, 25437, 25416, 20686, 36714],\n",
       " 35391: [14341, 27835, 27190, 36049, 37713, 27216, 27852, 26886, 36798, 28405],\n",
       " 35390: [26550, 27067, 26818, 32701, 26776, 19939, 36579, 27137, 24553, 27656],\n",
       " 35389: [24553, 33023, 33038, 32787, 34477, 26367, 33196, 33912, 35362, 33507],\n",
       " 35388: [31847, 20729, 14577, 20526, 28143, 26993, 26728, 31849, 34790, 26023],\n",
       " 35387: [36902, 36373, 35856, 35918, 28176, 36260, 37211, 24182, 28318, 2383],\n",
       " 35386: [26501, 27231, 25435, 25594, 24388, 2476, 14544, 27807, 27118, 24412],\n",
       " 35385: [27050, 26950, 19915, 27912, 31581, 27685, 26188, 25039, 27455, 25436],\n",
       " 35384: [31326, 25964, 26533, 26879, 27650, 26256, 26001, 37421, 27003, 14343],\n",
       " 35383: [35584, 35988, 36052, 25119, 19588, 31613, 34355, 35429, 35938, 35579],\n",
       " 35382: [25295, 26624, 26868, 25215, 27703, 27994, 25193, 26852, 28216, 24838],\n",
       " 35381: [35441, 32738, 32274, 25232, 32557, 33487, 32886, 30955, 34128, 33983],\n",
       " 35380: [20339, 20338, 25507, 35561, 20731, 25581, 26191, 19869, 26424, 36507],\n",
       " 35379: [26688, 28310, 14636, 20106, 35162, 26417, 27481, 27255, 33825, 25500],\n",
       " 35378: [27739, 28290, 26417, 24246, 34399, 33873, 26016, 34430, 35412, 26688],\n",
       " 35377: [35932, 37858, 36233, 19837, 20107, 37177, 37272, 37431, 27623, 37372],\n",
       " 35376: [34290, 37714, 20038, 19834, 20601, 19832, 29847, 19836, 20106, 19816],\n",
       " 35375: [37579, 33926, 26692, 20022, 35179, 34524, 19816, 26107, 27481, 20106],\n",
       " 35374: [25591, 26225, 25435, 25489, 26609, 27030, 26015, 26139, 27304, 27163],\n",
       " 35373: [19791, 19790, 37712, 26131, 25415, 25436, 28353, 25594, 25718, 24415],\n",
       " 35372: [20339, 20365, 34521, 35326, 34261, 20072, 27994, 25090, 26204, 29202],\n",
       " 35371: [27295, 28177, 27203, 35556, 27469, 36069, 28192, 14096, 35436, 28250],\n",
       " 35370: [27685, 28187, 35165, 35192, 35765, 20338, 20397, 28169, 31797, 14681],\n",
       " 35369: [24965, 20071, 20297, 20294, 33413, 20072, 20363, 25426, 33030, 25898],\n",
       " 35368: [19766, 12875, 25807, 31292, 14196, 20640, 24930, 24223, 34028, 25449],\n",
       " 35367: [36616, 27831, 36813, 27424, 26677, 35362, 14407, 32430, 36575, 37807],\n",
       " 35366: [30449, 24449, 35131, 33724, 27878, 36321, 27356, 28353, 27208, 35088],\n",
       " 35365: [30907, 27768, 19720, 26351, 26105, 14563, 27777, 30092, 33395, 27880],\n",
       " 35364: [25560, 27745, 20576, 27030, 26827, 25639, 31045, 28187, 28389, 26712],\n",
       " 35363: [27318, 35251, 28050, 26330, 33737, 20633, 35374, 27831, 26189, 36499],\n",
       " 35362: [31953, 34363, 24855, 26784, 34731, 25077, 24473, 23712, 25833, 33095],\n",
       " 35361: [36693, 27759, 28310, 35992, 26100, 27556, 37404, 27790, 37062, 28083],\n",
       " 35360: [35370, 34524, 36452, 28290, 35397, 36755, 35882, 33197, 37220, 36676],\n",
       " 35359: [26430, 34290, 24878, 36817, 34067, 34342, 37062, 35169, 35404, 26397],\n",
       " 35358: [20016, 36231, 34873, 34290, 31824, 36888, 35169, 19651, 35470, 36867],\n",
       " 35357: [25295, 32309, 24894, 24556, 27800, 24705, 25215, 27659, 26717, 26453],\n",
       " 35356: [26217, 34694, 34689, 24544, 21920, 25215, 34684, 27800, 24556, 26868],\n",
       " 35355: [33821, 32738, 24404, 33855, 25570, 24412, 32763, 24268, 24895, 26717],\n",
       " 35354: [35992, 27255, 35229, 35470, 37215, 35397, 34702, 27765, 26932, 36665],\n",
       " 35353: [31980, 19986, 19938, 31974, 19939, 37379, 36595, 27111, 18283, 27110],\n",
       " 35352: [24176, 30605, 35377, 31432, 32645, 24642, 32904, 32778, 33187, 37619],\n",
       " 35351: [20390, 35397, 20038, 34892, 36591, 36893, 36991, 20107, 36505, 36357],\n",
       " 35350: [25564, 27164, 34342, 26016, 27258, 26430, 19635, 27957, 26397, 27790],\n",
       " 35349: [34332, 35385, 35526, 23677, 36027, 28290, 36693, 35370, 26430, 35882],\n",
       " 35348: [37592, 28104, 31961, 20575, 37998, 37720, 20576, 36020, 24774, 7905],\n",
       " 35347: [26189, 28349, 30828, 27805, 27910, 14681, 25435, 26609, 36381, 25233],\n",
       " 35346: [27613, 36570, 25417, 26970, 25436, 36291, 27749, 24774, 27818, 25167],\n",
       " 35345: [28438, 28479, 28447, 28490, 24382, 24774, 24383, 28158, 31035, 28349],\n",
       " 35344: [24382, 35968, 24408, 28447, 32307, 28096, 35836, 24865, 35959, 34629],\n",
       " 35343: [27016, 34766, 28094, 31020, 20622, 32001, 27208, 31996, 26505, 27577],\n",
       " 35342: [20301, 31678, 32402, 25938, 31159, 31658, 34052, 30893, 19618, 32577],\n",
       " 35341: [34909, 20547, 31663, 37484, 24412, 20545, 15966, 19619, 30827, 35160],\n",
       " 35340: [36004, 35127, 35290, 25136, 37448, 38096, 36331, 27699, 28241, 27267],\n",
       " 35339: [28466, 36876, 28364, 28349, 37864, 38030, 25428, 38102, 28282, 28262],\n",
       " 35338: [35169, 34267, 33825, 35125, 26356, 26797, 35746, 27026, 26427, 27258],\n",
       " 35337: [4074, 31873, 25125, 34311, 33507, 36218, 32478, 35325, 35011, 35597],\n",
       " 35336: [27751, 37968, 34848, 37201, 35219, 28349, 37988, 33900, 30921, 37146],\n",
       " 35335: [14311, 31994, 26105, 33683, 31993, 27173, 33466, 33850, 34166, 27799],\n",
       " 35334: [26907, 26084, 14411, 20564, 26038, 25001, 20291, 20566, 25211, 33210],\n",
       " 35333: [19588, 35385, 35932, 27957, 35650, 35876, 36693, 36346, 35494, 28064],\n",
       " 35332: [24415, 27374, 14414, 27675, 27208, 14215, 25352, 26923, 26298, 20343],\n",
       " 35331: [26217, 32738, 34790, 32739, 25968, 33208, 20103, 36805, 24538, 19581],\n",
       " 35330: [33825, 34399, 26427, 35531, 34732, 34173, 24801, 14260, 28064, 26368],\n",
       " 35329: [26356, 20106, 26698, 26107, 20107, 35531, 34369, 14260, 24803, 33358],\n",
       " 35328: [36902, 28119, 24179, 24403, 31386, 37317, 35784, 37427, 37705, 36911],\n",
       " 35327: [20380, 19965, 25507, 20377, 20023, 20376, 20379, 19967, 26332, 26309],\n",
       " 35326: [35470, 27255, 20390, 19651, 27510, 34524, 27961, 36226, 36403, 36249],\n",
       " 35325: [27624, 27556, 34149, 34326, 36703, 26104, 20106, 27255, 23893, 20107],\n",
       " 35324: [26932, 26107, 25918, 27759, 36346, 33468, 33877, 35650, 20107, 36459],\n",
       " 35323: [35988, 34607, 37595, 35185, 28432, 33785, 27821, 26430, 34290, 36231],\n",
       " 35322: [33197, 33877, 36771, 35397, 37654, 27139, 35531, 27481, 35357, 27726],\n",
       " 35321: [27255, 28310, 25179, 36591, 33197, 37318, 27510, 34290, 27957, 27026],\n",
       " 35320: [37715, 35531, 33765, 20646, 26430, 31826, 26397, 33785, 35429, 34732],\n",
       " 35319: [24383, 24771, 24642, 32995, 33531, 35005, 28448, 34118, 34340, 33131],\n",
       " 35318: [25467, 20469, 36373, 35245, 24655, 26682, 32775, 27756, 24875, 24586],\n",
       " 35317: [20244, 34843, 32763, 27044, 26038, 23915, 26224, 32473, 24894, 24838],\n",
       " 35316: [25210, 26430, 20020, 31829, 32370, 36629, 34534, 20106, 35531, 37958],\n",
       " 35315: [36299, 26918, 34844, 37081, 38057, 34322, 27831, 36291, 14414, 34143],\n",
       " 35314: [25564, 34290, 26430, 26016, 34173, 26390, 26944, 26107, 33655, 27864],\n",
       " 35313: [35370, 27481, 28499, 37404, 35470, 27672, 35760, 37372, 36346, 35531],\n",
       " 35312: [34267, 33825, 33888, 33197, 19635, 36591, 35125, 27276, 31829, 34248],\n",
       " 35311: [32504, 19470, 35370, 25918, 29820, 34326, 24801, 29828, 19890, 37914],\n",
       " 35310: [31385, 31678, 37888, 36761, 29858, 30955, 36583, 24177, 24383, 20244],\n",
       " 35309: [36806, 19439, 20721, 33064, 35012, 28025, 28004, 25489, 37228, 37994],\n",
       " 35308: [37958, 36676, 37620, 37608, 37120, 36458, 38072, 37540, 35772, 35229],\n",
       " 35307: [36850, 36107, 26712, 20575, 25640, 24416, 31575, 35119, 25435, 20607],\n",
       " 35306: [27583, 36069, 26977, 20698, 37105, 35601, 26675, 27783, 27926, 28292],\n",
       " 35305: [14090, 36841, 36452, 19835, 36956, 35954, 35532, 36839, 36693, 36591],\n",
       " 35304: [27255, 31825, 27898, 35777, 37715, 35932, 20107, 34431, 27008, 36233],\n",
       " 35303: [34658, 20652, 35805, 28416, 26498, 25423, 26278, 14093, 25929, 28198],\n",
       " 35302: [14127, 35992, 37620, 26944, 34578, 34290, 25496, 27957, 35179, 35988],\n",
       " 35301: [25500, 35900, 33765, 27389, 26734, 33964, 35584, 31578, 26971, 31828],\n",
       " 35300: [35882, 14090, 36591, 36841, 36819, 38072, 28502, 37958, 36458, 36956],\n",
       " 35299: [33825, 25564, 26430, 36458, 24878, 14182, 35125, 24785, 26822, 28331],\n",
       " 35298: [36249, 33765, 32370, 31575, 31578, 35760, 29003, 32921, 36591, 37892],\n",
       " 35297: [25166, 32982, 27140, 33688, 33123, 25118, 34144, 25228, 25124, 25898],\n",
       " 35296: [20107, 37858, 27726, 36433, 35906, 37372, 27276, 27008, 27739, 20106],\n",
       " 35295: [35650, 28418, 36905, 36665, 20153, 36346, 29829, 27497, 26692, 35370],\n",
       " 35294: [37810, 37809, 37557, 36204, 32019, 37651, 38113, 36334, 19085, 36387],\n",
       " 35293: [28248, 34524, 26606, 37715, 28083, 28310, 27276, 14326, 35526, 37093],\n",
       " 35292: [34934, 34355, 31575, 34783, 32832, 36061, 5843, 33785, 25496, 26104],\n",
       " 35291: [27790, 35526, 34749, 20601, 27024, 27008, 27759, 15554, 26698, 27481],\n",
       " 35290: [34702, 34369, 37654, 37372, 27739, 36309, 36144, 27255, 36757, 35772],\n",
       " 35289: [25496, 26104, 36231, 31575, 25846, 35619, 23893, 35988, 37222, 25119],\n",
       " 35288: [31445, 24500, 34267, 24830, 27258, 26427, 27026, 33646, 25536, 35988],\n",
       " 35287: [37120, 37344, 36645, 28165, 37744, 14090, 37861, 28547, 37185, 32966],\n",
       " 35286: [35370, 28290, 36676, 36841, 19651, 37088, 37476, 37149, 36839, 36693],\n",
       " 35285: [24629, 25245, 28331, 25884, 27255, 32370, 37792, 36867, 35989, 20016],\n",
       " 35284: [35882, 36819, 35229, 36226, 14509, 36452, 24953, 36591, 35532, 36757],\n",
       " 35283: [33253, 32579, 14042, 27478, 31187, 21109, 31529, 25037, 23589, 31990],\n",
       " 35282: [35556, 26513, 37864, 20635, 24415, 25406, 28226, 20564, 25594, 35653],\n",
       " 35281: [33879, 26921, 27487, 26795, 20344, 25435, 28224, 27807, 21096, 27030],\n",
       " 35280: [22215, 22225, 22223, 22122, 22154, 22167, 22168, 22190, 22238, 22179],\n",
       " 35279: [27530, 27732, 24613, 31978, 36974, 37363, 20773, 37081, 28097, 31975],\n",
       " 35278: [28177, 37515, 28026, 20773, 38118, 37420, 20636, 31888, 37574, 14654],\n",
       " 35277: [27861, 37997, 26970, 20632, 20773, 37387, 37486, 28043, 25735, 20725],\n",
       " 35276: [25180, 25979, 26581, 26969, 25435, 35119, 36020, 26093, 27910, 36001],\n",
       " 35275: [27834, 26434, 35821, 20633, 19967, 37075, 34116, 27455, 19966, 26188],\n",
       " 35274: [25435, 26298, 36475, 27163, 25343, 35630, 37086, 25436, 27254, 37046],\n",
       " 35273: [37527, 37864, 35150, 27661, 27455, 14681, 20740, 27583, 25889, 36612],\n",
       " 35272: [26910, 37832, 34477, 26202, 28014, 19250, 25889, 37111, 25431, 25246],\n",
       " 35271: [15332, 28230, 14414, 28273, 27675, 28537, 36070, 37153, 27749, 27575],\n",
       " 35270: [34497, 25979, 27170, 26909, 36449, 37700, 37866, 25370, 27894, 28517],\n",
       " 35269: [36004, 27118, 32074, 25420, 27671, 28425, 28397, 28365, 37994, 27979],\n",
       " 35268: [34497, 37196, 27310, 36397, 28065, 28464, 36667, 26457, 38041, 28555],\n",
       " 35267: [24993, 31580, 27236, 20380, 31582, 25365, 20379, 25435, 24412, 24404],\n",
       " 35266: [20246, 29029, 16666, 18009, 20063, 24590, 32310, 32195, 8083, 14294],\n",
       " 35265: [24192, 26813, 24191, 25423, 14546, 28268, 37491, 28216, 25428, 28020],\n",
       " 35264: [27940, 27771, 35630, 26875, 19254, 37902, 37498, 20548, 28532, 36397],\n",
       " 35263: [27940, 28359, 35520, 36966, 36573, 11135, 24388, 35734, 15966, 37855],\n",
       " 35262: [27685, 36573, 27374, 20343, 27675, 25417, 25416, 26851, 21096, 28200],\n",
       " 35261: [27776, 25968, 26039, 35815, 24234, 26930, 14050, 25863, 24887, 25570],\n",
       " 35260: [20305, 20377, 25808, 20376, 25426, 25417, 24404, 25352, 35790, 20344],\n",
       " 35259: [30332, 22819, 22812, 24887, 26105, 24474, 19719, 22817, 30905, 22816],\n",
       " 35258: [20278, 20279, 32680, 32625, 19758, 19228, 33258, 14351, 36523, 25228],\n",
       " 35257: [30334, 19719, 32205, 30616, 31711, 27582, 30905, 30332, 30984, 25085],\n",
       " 35256: [26013, 36529, 20554, 14615, 14671, 38061, 37994, 31032, 37712, 35133],\n",
       " 35255: [37904, 27123, 20759, 27340, 20456, 35272, 27893, 8400, 20244, 28362],\n",
       " 35254: [30755, 33823, 33791, 14462, 34110, 34695, 34684, 34805, 34696, 35016],\n",
       " 35253: [37887, 37809, 32019, 36037, 38098, 25402, 25406, 36387, 36607, 36842],\n",
       " 35252: [35923, 32019, 38113, 36204, 26917, 36123, 38101, 35669, 28063, 36607],\n",
       " 35251: [36386, 36334, 19751, 32041, 26814, 37448, 38000, 19753, 19752, 37441],\n",
       " 35250: [26558, 30615, 20712, 31479, 31480, 26367, 35686, 30613, 33951, 29523],\n",
       " 35249: [17555, 21379, 17537, 29763, 29776, 29748, 18965, 28928, 17561, 17542],\n",
       " 35248: [17555, 21395, 21408, 18970, 21385, 21398, 21909, 17107, 29340, 21553],\n",
       " 35247: [25243, 25973, 27032, 27517, 25969, 27223, 35617, 30763, 28015, 28014],\n",
       " 35246: [25224, 26165, 28212, 20526, 36612, 27108, 25736, 24685, 25566, 14054],\n",
       " 35245: [26452, 26163, 34687, 24575, 35525, 26113, 25471, 26202, 25301, 26041],\n",
       " 35244: [25877, 25883, 25875, 34596, 34755, 37083, 36334, 4065, 8088, 10560],\n",
       " 35243: [20514, 20401, 20406, 31872, 36302, 20349, 37312, 5666, 25947, 35212],\n",
       " 35242: [18824, 22245, 22158, 22117, 22133, 22166, 22113, 22153, 22225, 22164],\n",
       " 35241: [22225, 22219, 22165, 22245, 22164, 22106, 22190, 22109, 22168, 22167],\n",
       " 35240: [22206, 22106, 22190, 22114, 22217, 22045, 22060, 22200, 22153, 22219],\n",
       " 35239: [23851, 20223, 34762, 27802, 31872, 20264, 25731, 31360, 25197, 36973],\n",
       " 35238: [28344, 37223, 36844, 32055, 28441, 26361, 32057, 35653, 20369, 20370],\n",
       " 35237: [19915, 24234, 27893, 35571, 25968, 27123, 28362, 24474, 25567, 32104],\n",
       " 35236: [34318, 24474, 26879, 33912, 32068, 24249, 20480, 26646, 33814, 36825],\n",
       " 35235: [25140, 27225, 31854, 31029, 20576, 26298, 27808, 24181, 27110, 25417],\n",
       " 35234: [36779, 36776, 36031, 36968, 35504, 30888, 36264, 37192, 38034, 37191],\n",
       " 35233: [37432, 28480, 27709, 28298, 24553, 36468, 27580, 27799, 37513, 37925],\n",
       " 35232: [35639, 35556, 34902, 37864, 38076, 28020, 28025, 31883, 27235, 26923],\n",
       " 35231: [20484, 25435, 26093, 20338, 27074, 20340, 27531, 24412, 24404, 25750],\n",
       " 35230: [25224, 25637, 18390, 34181, 32583, 28211, 26963, 24685, 26429, 24809],\n",
       " 35229: [10617, 34745, 27211, 14686, 25973, 14272, 35617, 10552, 8069, 20403],\n",
       " 35228: [31581, 19628, 18285, 33272, 24416, 14654, 24388, 25423, 35362, 24417],\n",
       " 35227: [27579, 37156, 35807, 37416, 20740, 37845, 37009, 20670, 27692, 27583],\n",
       " 35226: [34698, 26810, 36108, 20124, 27143, 26851, 24411, 28500, 37909, 25417],\n",
       " 35225: [27745, 25716, 19966, 28541, 28297, 28353, 28554, 25392, 27298, 37083],\n",
       " 35224: [36750, 31580, 24191, 34339, 20575, 24192, 31585, 26361, 26178, 35061],\n",
       " 35223: [14462, 33323, 36467, 33847, 37864, 33739, 37368, 24456, 25582, 25422],\n",
       " 35222: [36773, 27783, 36779, 37193, 34485, 27926, 37191, 27506, 26969, 36266],\n",
       " 35221: [28074, 20696, 27964, 28260, 37960, 27745, 20388, 20715, 25418, 37432],\n",
       " 35220: [19766, 23889, 19768, 24716, 34943, 19071, 35540, 27802, 25197, 31958],\n",
       " 35219: [26503, 30510, 34324, 28172, 34790, 26327, 32243, 27650, 25090, 26751],\n",
       " 35218: [36509, 26813, 35943, 35893, 27455, 27723, 36884, 38087, 27978, 32070],\n",
       " 35217: [26185, 34135, 25246, 27032, 28298, 36607, 18156, 36386, 37496, 20214],\n",
       " 35216: [31874, 35757, 34278, 27352, 25411, 17945, 8164, 31877, 24473, 23894],\n",
       " 35215: [17851, 17878, 17893, 17900, 17911, 17882, 17895, 17884, 17865, 17853],\n",
       " 35214: [24716, 25932, 33500, 28233, 25184, 25100, 25021, 20565, 25197, 19988],\n",
       " 35213: [22156, 22217, 28861, 22245, 22226, 22180, 22189, 22170, 22148, 22220],\n",
       " 35212: [35304, 32081, 20712, 31704, 30616, 30963, 31711, 33582, 31935, 14652],\n",
       " 35211: [17700, 11618, 26904, 24533, 24280, 20277, 27153, 27802, 24459, 24927],\n",
       " 35210: [27207, 27124, 17699, 17705, 28583, 25001, 27071, 20169, 27352, 35360],\n",
       " 35209: [28262, 37423, 37798, 28438, 20575, 34611, 20576, 20163, 20486, 37337],\n",
       " 35208: [17341, 36994, 35639, 37421, 38007, 36142, 36943, 37050, 37645, 26840],\n",
       " 35207: [16666, 33991, 28233, 25197, 8083, 19253, 24594, 14595, 15555, 31872],\n",
       " 35206: [20638, 27134, 34415, 35444, 33432, 27176, 26715, 35846, 27167, 27771],\n",
       " 35205: [19453, 23087, 23111, 23145, 35335, 23081, 19988, 19359, 19639, 23075],\n",
       " 35204: [21400, 21598, 18973, 21301, 19034, 4503, 21411, 19001, 21414, 19016],\n",
       " 35203: [19034, 18973, 18968, 4742, 29362, 4457, 21551, 29365, 29303, 18989],\n",
       " 35202: [17555, 18964, 21385, 17552, 19002, 29480, 19007, 17560, 18968, 18931],\n",
       " 35201: [18964, 19002, 19031, 17530, 17531, 29747, 21329, 29499, 17562, 17550],\n",
       " 35200: [18970, 19034, 18973, 17555, 18968, 21909, 18987, 19044, 17528, 19014],\n",
       " 35199: [17552, 17555, 21903, 18973, 19014, 19002, 19034, 18937, 18987, 29424],\n",
       " 35198: [17974, 17850, 17999, 17833, 17996, 17823, 18003, 17967, 17995, 17977],\n",
       " 35197: [21903, 29331, 18964, 19034, 21304, 21404, 21909, 21400, 21365, 29388],\n",
       " 35196: [19034, 18964, 21385, 18970, 21328, 19002, 17560, 17532, 19018, 19021],\n",
       " 35195: [30523, 26825, 25415, 25140, 20607, 27701, 25594, 26178, 17407, 37947],\n",
       " 35194: [27888, 28428, 27488, 20633, 28517, 20774, 37751, 36850, 27282, 36762],\n",
       " 35193: [26590, 19982, 31974, 37287, 31971, 28364, 19986, 28306, 35088, 31973],\n",
       " 35192: [26105, 36412, 27030, 31762, 34341, 20152, 19939, 26609, 34826, 17335],\n",
       " 35191: [24402, 17312, 28459, 27771, 34909, 36039, 22783, 28026, 27061, 35869],\n",
       " 35190: [36876, 28106, 17261, 17249, 28260, 25379, 28226, 20500, 20723, 28171],\n",
       " 35189: [20498, 20632, 25363, 20122, 28476, 36865, 20500, 36260, 34343, 37038],\n",
       " 35188: [17261, 31708, 26351, 27111, 27971, 30641, 14414, 30619, 27091, 30616],\n",
       " 35187: [21404, 19034, 29389, 29424, 21551, 29357, 19044, 22144, 21390, 19389],\n",
       " 35186: [27859, 26661, 26875, 26288, 24403, 35422, 30448, 33782, 33395, 28397],\n",
       " 35185: [17501, 30689, 21586, 16837, 17897, 23115, 17503, 17902, 17998, 17506],\n",
       " 35184: [17829, 17994, 16784, 17874, 17835, 16783, 17862, 16862, 16860, 17905],\n",
       " 35183: [17861, 17878, 16785, 17974, 16783, 17998, 17865, 16766, 17851, 17916],\n",
       " 35182: [20693, 17895, 17998, 17501, 22217, 17892, 16837, 17898, 31957, 17902],\n",
       " 35181: [22231, 22225, 22200, 16857, 22226, 16827, 16820, 28872, 22167, 22135],\n",
       " 35180: [17835, 16819, 16676, 16769, 16720, 16828, 16801, 5139, 17949, 17989],\n",
       " 35179: [17555, 18964, 21909, 18970, 18986, 21556, 29765, 21385, 19008, 18989],\n",
       " 35178: [27027, 28349, 27383, 35723, 28158, 27873, 20132, 34225, 37526, 37052],\n",
       " 35177: [16801, 16828, 16827, 16769, 16823, 16819, 16714, 16656, 16862, 16840],\n",
       " 35176: [16803, 21557, 18936, 18937, 17555, 16694, 18931, 18930, 19003, 9543],\n",
       " 35175: [17975, 36543, 17887, 17819, 27132, 14578, 17996, 34894, 16596, 34929],\n",
       " 35174: [25507, 32701, 32665, 32758, 32739, 25571, 32473, 26039, 32262, 25215],\n",
       " 35173: [27568, 16752, 23299, 23136, 16771, 17879, 23142, 17552, 16828, 17881],\n",
       " 35172: [18970, 29362, 13083, 29402, 21385, 21596, 16770, 19034, 29401, 4499],\n",
       " 35171: [16782, 16662, 16860, 16785, 16713, 16657, 16840, 16783, 16704, 16650],\n",
       " 35170: [19034, 29289, 16657, 18968, 29411, 21385, 16776, 16656, 16784, 29401],\n",
       " 35169: [16803, 16765, 16827, 16691, 16686, 16656, 18986, 16784, 16802, 16769],\n",
       " 35168: [16657, 16753, 16776, 16819, 16703, 16690, 16782, 29357, 16780, 16697],\n",
       " 35167: [19034, 16779, 16814, 16666, 22113, 21385, 16803, 16679, 16657, 19008],\n",
       " 35166: [17862, 16723, 17830, 17835, 17833, 17818, 17864, 17978, 17828, 17859],\n",
       " 35165: [16679, 16657, 16776, 16758, 16713, 16675, 16699, 16770, 16695, 19007],\n",
       " 35164: [16783, 16840, 16779, 16827, 16770, 16713, 16819, 16782, 16771, 16777],\n",
       " 35163: [16819, 16802, 16784, 16758, 16754, 16785, 16770, 16783, 16713, 16722],\n",
       " 35162: [16609, 16635, 16686, 16785, 16638, 17555, 16725, 16620, 17966, 16684],\n",
       " 35161: [18964, 29411, 29480, 16780, 17966, 29424, 16779, 16716, 18968, 18989],\n",
       " 35160: [16819, 23297, 16676, 16811, 16722, 16771, 16802, 16801, 16777, 16787],\n",
       " 35159: [17555, 21322, 29386, 16785, 16721, 19001, 18992, 16656, 18023, 16658],\n",
       " 35158: [16860, 16819, 16862, 16703, 16770, 16827, 16776, 16713, 16751, 16754],\n",
       " 35157: [16784, 16656, 16736, 16823, 16779, 16785, 16801, 16838, 16866, 16657],\n",
       " 35156: [16827, 16749, 17971, 16802, 16722, 16657, 16779, 16690, 16784, 16776],\n",
       " 35155: [16819, 17882, 17879, 16749, 17836, 17811, 18001, 17906, 16776, 17955],\n",
       " 35154: [16780, 16723, 16671, 16725, 16620, 16638, 16609, 16703, 16643, 16690],\n",
       " 35153: [16705, 16620, 16627, 16728, 16679, 16781, 16696, 16784, 16703, 16675],\n",
       " 35152: [16815, 16671, 16728, 16635, 16827, 16708, 16769, 16657, 16638, 16801],\n",
       " 35151: [16728, 16670, 16749, 16769, 16620, 16722, 16801, 16779, 16776, 16676],\n",
       " 35150: [16671, 16686, 16620, 16725, 16670, 16703, 16802, 16739, 16676, 16669],\n",
       " 35149: [16720, 17942, 13192, 16807, 19641, 18006, 17919, 17949, 8373, 17947],\n",
       " 35148: [16661, 16780, 16724, 16770, 16776, 16742, 16716, 16615, 16657, 16723],\n",
       " 35147: [18770, 16656, 16785, 16676, 16784, 16769, 16779, 16713, 16742, 16811],\n",
       " 35146: [33263, 15508, 16590, 15484, 17917, 26951, 17966, 32546, 32973, 16749],\n",
       " 35145: [17938, 14578, 19513, 16670, 33313, 34734, 31899, 16620, 16720, 36212],\n",
       " 35144: [35842, 8373, 17938, 17845, 16720, 17920, 32973, 8111, 8105, 17942],\n",
       " 35143: [26503, 27231, 24046, 23372, 19072, 22441, 22265, 23398, 20325, 22322],\n",
       " 35142: [19834, 31445, 19832, 31572, 29840, 19836, 29846, 29847, 29844, 19458],\n",
       " 35141: [27342, 26201, 37764, 24388, 35723, 35916, 20450, 37025, 36384, 28292],\n",
       " 35140: [28332, 28429, 36474, 27303, 37874, 36941, 35958, 26743, 37739, 35570],\n",
       " 35139: [34645, 28465, 20543, 37574, 27709, 28216, 37291, 26505, 36055, 27179],\n",
       " 35138: [28332, 27675, 36263, 37874, 36065, 36173, 27179, 36063, 27350, 36635],\n",
       " 35137: [36323, 36610, 35914, 37304, 36772, 28459, 36773, 36779, 37301, 35915],\n",
       " 35136: [17881, 26303, 26635, 27653, 18148, 26527, 22180, 17836, 22173, 20735],\n",
       " 35135: [27045, 27840, 27796, 26183, 32994, 31967, 34176, 35022, 28399, 20090],\n",
       " 35134: [26188, 25393, 16197, 25842, 27910, 20525, 27583, 16238, 27709, 34378],\n",
       " 35133: [27582, 35304, 30175, 28251, 37768, 20487, 38092, 31704, 32081, 33951],\n",
       " 35132: [31038, 27033, 27376, 37712, 36405, 37386, 37807, 14664, 35768, 37385],\n",
       " 35131: [30615, 20488, 30619, 35562, 36804, 30984, 37703, 33951, 30993, 20487],\n",
       " 35130: [34702, 19470, 15552, 14636, 20107, 26517, 25500, 34276, 32832, 20476],\n",
       " 35129: [22816, 22814, 19985, 22804, 16171, 36426, 20361, 35684, 31999, 37631],\n",
       " 35128: [26351, 37778, 26170, 36577, 37541, 37427, 25246, 33068, 37321, 26503],\n",
       " 35127: [28519, 37715, 37343, 19458, 37390, 14643, 26390, 28068, 36696, 28508],\n",
       " 35126: [31385, 27650, 36579, 34543, 27612, 35639, 28485, 21753, 35990, 29858],\n",
       " 35125: [20470, 20681, 35990, 32082, 31647, 20682, 31876, 31649, 36988, 36418],\n",
       " 35124: [20210, 27492, 10943, 32015, 34381, 37963, 27328, 36900, 36378, 20061],\n",
       " 35123: [29867, 23061, 29340, 29620, 23059, 16688, 29877, 17967, 18144, 16671],\n",
       " 35122: [37349, 36996, 36701, 34426, 16092, 16170, 37706, 35079, 36533, 16116],\n",
       " 35121: [28432, 34267, 35470, 25506, 24878, 34940, 27026, 27008, 35277, 34581],\n",
       " 35120: [34766, 26225, 33965, 27224, 31020, 33214, 20566, 25415, 34317, 33933],\n",
       " 35119: [37880, 28481, 28273, 19985, 31974, 27807, 19984, 37895, 37416, 19986],\n",
       " 35118: [26750, 28097, 27375, 27451, 27485, 15325, 26548, 27805, 27846, 24403],\n",
       " 35117: [26581, 27374, 27923, 27732, 36381, 24417, 27111, 35782, 24415, 26505],\n",
       " 35116: [25987, 24556, 25803, 24404, 33855, 22701, 26572, 26387, 25392, 26930],\n",
       " 35115: [26609, 24412, 25560, 27250, 26254, 25808, 25343, 25640, 26923, 26875],\n",
       " 35114: [18282, 26854, 24412, 20479, 26851, 27374, 25435, 27074, 26244, 20331],\n",
       " 35113: [26854, 20393, 27236, 31854, 20394, 3213, 27675, 26574, 31581, 25426],\n",
       " 35112: [23846, 25419, 25343, 24388, 25417, 23847, 35254, 25435, 24404, 25434],\n",
       " 35111: [27374, 27300, 27057, 26851, 24412, 20420, 36001, 26977, 27403, 20397],\n",
       " 35110: [26412, 28362, 27893, 24935, 37307, 27303, 35360, 26907, 25964, 24898],\n",
       " 35109: [19618, 30827, 16197, 32104, 20334, 32114, 35096, 31657, 26951, 31806],\n",
       " 35108: [28323, 28096, 27190, 28205, 36005, 28265, 27649, 38057, 35799, 37423],\n",
       " 35107: [34267, 31825, 26430, 34430, 36189, 35179, 34248, 24878, 24629, 25536],\n",
       " 35106: [33403, 7309, 33014, 34695, 14343, 20023, 34684, 25571, 36318, 20324],\n",
       " 35105: [28285, 33685, 27472, 27438, 27441, 28090, 26810, 21109, 31847, 36798],\n",
       " 35104: [26738, 15826, 26682, 26519, 27105, 25466, 20042, 26191, 24388, 25286],\n",
       " 35103: [15550, 19854, 26733, 27315, 25079, 26911, 32006, 28233, 33122, 22464],\n",
       " 35102: [16660, 16679, 16658, 16828, 16614, 16823, 16737, 16697, 16703, 16713],\n",
       " 35101: [18964, 18989, 21551, 29375, 19039, 21398, 29487, 21598, 16815, 22746],\n",
       " 35100: [35876, 35397, 37372, 26107, 26427, 26692, 20602, 32567, 26662, 35385],\n",
       " 35099: [32738, 25558, 25573, 37028, 33208, 24620, 25071, 24573, 24789, 25571],\n",
       " 35098: [25875, 25883, 16749, 16807, 16593, 22928, 8372, 16583, 33263, 16670],\n",
       " 35097: [26392, 14199, 35043, 16723, 21245, 17951, 20264, 18006, 19768, 19329],\n",
       " 35096: [18832, 18830, 22060, 22110, 18824, 22158, 17892, 17638, 22219, 28867],\n",
       " 35095: [22062, 18840, 18830, 22196, 22245, 22198, 22042, 17728, 22148, 22096],\n",
       " 35094: [18792, 29387, 22449, 30867, 19080, 19077, 22061, 17967, 31193, 31270],\n",
       " 35093: [16583, 16690, 15508, 17881, 32718, 17973, 17972, 17826, 16769, 27413],\n",
       " 35092: [30200, 17973, 17832, 17844, 5122, 17848, 17998, 17948, 17940, 18794],\n",
       " 35091: [17832, 17865, 17843, 17899, 17916, 17908, 17835, 17819, 17973, 17853],\n",
       " 35090: [16664, 16770, 16777, 16861, 16703, 16751, 16784, 30202, 16808, 16676],\n",
       " 35089: [28862, 28867, 18970, 19044, 28872, 19034, 21385, 28868, 21392, 21909],\n",
       " 35088: [29718, 18970, 18964, 21392, 21371, 17554, 29714, 19034, 17555, 21553],\n",
       " 35087: [18970, 19034, 18964, 21553, 29346, 21385, 17107, 17530, 29550, 18987],\n",
       " 35086: [36564, 31567, 36964, 28459, 20507, 20696, 28441, 28049, 37537, 37016],\n",
       " 35085: [30755, 37515, 36791, 25419, 37895, 27577, 28203, 36439, 33514, 37615],\n",
       " 35084: [28063, 27846, 27374, 26875, 28397, 27520, 27894, 27831, 27254, 26909],\n",
       " 35083: [20498, 37592, 38112, 37998, 27785, 35547, 32074, 35384, 27441, 37432],\n",
       " 35082: [35774, 34790, 27324, 20673, 19879, 25571, 36170, 27628, 26309, 19880],\n",
       " 35081: [28466, 28158, 28438, 28074, 28244, 14669, 28267, 28523, 37526, 35765],\n",
       " 35080: [20397, 25076, 20594, 27509, 34507, 24430, 14500, 31580, 26298, 14609],\n",
       " 35079: [27764, 28416, 31973, 28100, 37657, 27709, 28554, 19986, 31979, 37507],\n",
       " 35078: [32067, 20305, 26148, 36873, 37864, 25436, 28226, 25699, 25167, 25434],\n",
       " 35077: [27378, 26254, 24613, 28395, 35790, 20551, 24712, 11134, 27543, 28548],\n",
       " 35076: [28213, 36529, 37930, 27917, 28025, 19233, 31977, 27732, 37712, 37153],\n",
       " 35075: [20574, 27236, 28416, 20375, 20576, 21095, 14546, 27745, 24416, 27534],\n",
       " 35074: [28213, 27812, 28097, 36361, 35624, 27917, 28389, 36602, 36439, 20526],\n",
       " 35073: [37041, 24388, 25437, 27403, 36509, 2461, 27298, 27520, 25701, 25402],\n",
       " 35072: [29964, 13229, 28605, 29971, 29963, 18521, 21378, 18553, 22658, 22714],\n",
       " 35071: [24671, 32853, 20638, 19653, 27374, 25434, 36439, 25411, 20637, 25418],\n",
       " 35070: [17552, 17555, 21385, 17107, 18963, 17550, 21299, 21901, 17554, 18939],\n",
       " 35069: [18964, 17555, 19014, 19035, 18973, 19009, 18970, 29424, 19018, 19002],\n",
       " 35068: [16679, 16635, 16769, 16723, 16807, 18964, 17552, 29380, 16643, 16749],\n",
       " 35067: [19034, 18964, 19044, 29747, 18934, 19013, 29499, 19015, 19035, 29500],\n",
       " 35066: [25102, 34060, 22819, 26407, 22825, 27054, 34796, 27599, 25940, 26470],\n",
       " 35065: [30826, 30827, 26038, 8400, 25055, 33218, 34596, 33208, 14981, 28762],\n",
       " 35064: [27190, 14358, 35669, 36973, 17254, 36468, 28302, 37159, 35622, 37016],\n",
       " 35063: [33990, 25189, 14311, 12388, 8083, 12060, 24695, 19856, 19091, 14294],\n",
       " 35062: [35715, 36698, 26977, 35601, 35062, 26854, 37730, 37813, 27452, 20644],\n",
       " 35061: [37091, 37695, 38101, 11879, 20500, 20499, 37742, 10973, 37038, 14872],\n",
       " 35060: [37250, 33244, 25090, 35086, 32898, 32701, 36364, 26991, 35902, 34237],\n",
       " 35059: [20574, 37561, 27784, 37712, 37851, 37026, 28332, 14692, 36529, 28353],\n",
       " 35058: [37959, 27777, 37908, 38016, 37939, 38003, 20603, 37246, 32036, 37948],\n",
       " 35057: [27693, 38030, 37331, 36107, 27744, 26638, 37102, 37904, 34104, 26809],\n",
       " 35056: [28459, 27579, 26909, 26330, 34941, 26950, 25416, 36708, 34834, 36478],\n",
       " 35055: [26977, 36183, 20740, 26836, 27583, 20633, 27822, 36884, 36413, 37551],\n",
       " 35054: [27649, 14674, 31999, 27930, 28106, 36974, 37416, 36695, 28025, 11134],\n",
       " 35053: [19986, 20487, 27114, 8327, 33589, 20386, 20715, 34212, 19983, 20716],\n",
       " 35052: [31854, 20757, 20244, 27785, 27172, 22824, 36214, 20759, 24425, 34759],\n",
       " 35051: [28507, 28461, 37321, 28368, 28323, 28262, 28438, 31383, 18286, 37109],\n",
       " 35050: [28262, 28466, 28507, 20500, 28527, 27067, 35952, 14272, 37291, 28413],\n",
       " 35049: [33597, 33772, 34190, 26367, 28251, 32356, 30984, 33161, 32916, 36377],\n",
       " 35048: [26574, 35347, 35000, 30854, 35710, 34786, 35707, 31766, 20125, 34994],\n",
       " 35047: [37774, 25434, 35254, 36448, 27661, 36740, 37484, 25411, 24388, 20546],\n",
       " 35046: [14620, 37561, 28554, 27709, 20633, 27423, 14714, 28276, 28096, 37026],\n",
       " 35045: [28008, 26297, 27763, 14714, 25392, 26886, 25411, 37723, 28226, 29221],\n",
       " 35044: [20704, 20380, 14714, 20379, 27128, 37763, 36806, 31973, 28020, 35836],\n",
       " 35043: [31386, 37898, 26038, 26524, 33551, 25039, 30555, 25968, 26868, 25295],\n",
       " 35042: [36006, 27575, 24416, 37864, 20344, 28562, 14215, 14338, 20314, 37384],\n",
       " 35041: [36110, 28465, 14669, 27176, 27575, 27721, 27616, 27163, 20633, 27831],\n",
       " 35040: [14643, 36693, 36126, 27510, 37372, 35876, 28519, 28547, 37654, 37214],\n",
       " 35039: [30545, 24374, 14329, 20654, 30277, 14302, 26242, 30503, 18898, 30494],\n",
       " 35038: [14675, 38094, 25397, 20748, 36752, 18286, 35993, 28337, 27575, 35096],\n",
       " 35037: [32074, 28180, 37971, 26814, 28494, 14680, 28558, 33138, 28514, 32847],\n",
       " 35036: [16759, 17919, 17945, 17942, 16669, 30690, 29308, 28595, 20693, 16879],\n",
       " 35035: [30301, 25343, 23712, 26330, 25784, 35669, 25582, 26448, 8158, 26065],\n",
       " 35034: [27154, 36448, 20575, 27590, 27647, 27298, 20574, 24416, 31973, 27601],\n",
       " 35033: [14633, 26052, 27374, 36802, 27520, 27831, 27455, 37733, 26928, 28020],\n",
       " 35032: [27390, 27420, 28100, 27506, 27318, 27656, 26962, 26712, 32788, 20397],\n",
       " 35031: [20208, 27423, 37930, 27696, 27656, 27917, 37960, 35384, 27732, 28100],\n",
       " 35030: [26875, 24415, 25395, 27231, 31584, 24417, 38076, 27656, 25416, 14671],\n",
       " 35029: [27530, 31973, 31978, 14654, 31976, 27513, 28100, 14621, 37631, 14645],\n",
       " 35028: [27709, 27785, 34346, 27503, 28554, 28097, 27917, 20386, 28038, 37551],\n",
       " 35027: [14701, 24558, 20287, 27847, 24977, 26873, 26638, 27086, 27559, 32439],\n",
       " 35026: [26928, 20378, 25301, 28555, 25471, 27744, 27534, 37894, 37105, 20376],\n",
       " 35025: [14695, 26548, 27575, 36530, 31029, 20576, 20748, 37315, 35189, 28025],\n",
       " 35024: [14677, 20345, 28049, 25343, 36570, 25426, 25437, 28405, 37677, 36872],\n",
       " 35023: [35521, 14654, 31975, 20555, 20576, 20575, 35062, 31973, 19939, 31979],\n",
       " 35022: [20550, 20574, 20723, 31045, 27420, 27208, 36563, 18283, 28050, 26113],\n",
       " 35021: [14677, 37105, 26189, 36261, 35561, 36069, 35967, 35196, 37196, 28288],\n",
       " 35020: [23929, 25392, 25929, 25435, 23847, 23846, 25411, 20420, 37315, 20300],\n",
       " 35019: [20632, 25415, 28476, 25431, 25392, 24388, 20575, 20574, 25718, 28200],\n",
       " 35018: [25363, 20122, 27390, 14683, 26962, 38092, 36260, 34343, 7898, 36382],\n",
       " 35017: [26960, 37589, 37242, 35095, 37486, 36937, 36480, 37790, 37315, 37278],\n",
       " 35016: [28476, 34810, 27709, 27154, 28100, 37371, 14640, 37315, 37592, 35167],\n",
       " 35015: [28267, 37515, 27114, 27670, 31020, 26609, 37930, 28226, 14529, 28200],\n",
       " 35014: [20733, 38092, 36804, 27971, 30616, 30963, 20488, 20712, 36344, 30993],\n",
       " 35013: [27154, 37105, 20387, 37808, 20388, 37845, 27826, 20716, 32011, 37196],\n",
       " 35012: [27445, 28147, 28088, 37202, 28387, 14680, 14645, 34922, 36642, 34296],\n",
       " 35011: [37202, 27221, 26610, 26473, 26875, 32050, 27182, 20661, 20388, 20715],\n",
       " 35010: [36069, 27580, 27706, 36108, 15330, 32081, 25413, 25431, 19254, 27709],\n",
       " 35009: [20546, 27300, 26495, 37864, 37484, 27784, 27675, 35302, 37786, 26302],\n",
       " 35008: [37385, 36982, 36958, 27601, 37108, 36974, 14674, 37765, 37597, 35398],\n",
       " 35007: [27709, 36366, 28100, 20434, 27601, 36663, 36982, 37424, 15325, 36974],\n",
       " 35006: [34821, 14096, 27709, 36620, 27423, 20713, 28133, 27543, 27638, 36509],\n",
       " 35005: [37984, 37866, 28169, 27841, 37560, 37534, 28171, 37893, 35708, 27451],\n",
       " 35004: [27530, 35591, 27785, 36663, 27649, 24388, 28192, 36974, 25416, 36784],\n",
       " 35003: [20575, 25415, 26093, 24417, 24430, 25431, 35225, 27163, 37720, 26254],\n",
       " 35002: [37423, 36020, 37026, 28252, 36974, 37765, 27785, 37895, 37876, 27649],\n",
       " 35001: [21717, 27859, 27575, 36361, 36602, 26875, 25416, 27537, 27172, 21826],\n",
       " 35000: [37014, 26105, 24287, 32453, 35218, 14462, 34509, 26035, 36467, 32061],\n",
       " 34999: [28200, 35654, 38092, 14462, 20705, 19938, 36803, 28226, 20574, 35218],\n",
       " 34998: [26835, 27675, 27735, 37432, 36205, 37592, 37998, 27356, 27733, 27807],\n",
       " 34997: [28476, 33174, 27456, 37291, 14462, 27783, 27626, 36529, 33364, 36364],\n",
       " 34996: [20632, 26105, 27675, 36612, 36803, 28226, 27111, 27575, 27607, 27935],\n",
       " 34995: [36361, 27236, 27760, 20714, 31026, 20574, 20670, 27709, 26977, 20388],\n",
       " 34994: [27647, 26950, 20575, 27416, 26425, 34834, 27154, 20576, 37105, 37845],\n",
       " 34993: [28177, 28262, 26901, 35278, 28323, 28368, 37423, 28438, 14369, 37960],\n",
       " 34992: [25392, 25417, 25418, 25435, 27074, 20099, 24405, 28123, 25437, 25343],\n",
       " 34991: [27763, 20527, 26367, 28350, 25411, 27191, 35069, 35380, 15326, 24389],\n",
       " 34990: [35774, 31880, 20031, 20339, 20457, 31884, 20338, 36580, 20456, 20600],\n",
       " 34989: [33655, 34399, 34342, 14636, 26390, 24416, 35650, 27009, 36061, 24415],\n",
       " 34988: [20154, 37595, 37958, 38081, 28458, 37274, 37620, 28432, 37540, 36928],\n",
       " 34987: [35876, 27258, 36652, 34940, 37476, 37744, 37372, 35084, 27026, 35470],\n",
       " 34986: [33825, 34399, 28432, 35277, 33873, 34732, 34749, 26397, 35899, 35330],\n",
       " 34985: [36008, 35992, 34578, 33358, 35397, 35404, 35876, 35882, 26430, 27024],\n",
       " 34984: [26397, 25564, 28064, 35579, 27008, 26314, 35749, 27024, 24877, 34940],\n",
       " 34983: [36693, 35777, 37388, 36458, 36905, 36839, 37565, 37858, 36591, 24500],\n",
       " 34982: [27497, 34524, 24465, 26368, 35531, 20107, 28499, 35397, 35610, 35277],\n",
       " 34981: [28260, 27445, 20393, 37882, 26505, 25970, 35174, 34212, 28389, 37081],\n",
       " 34980: [28260, 26581, 28540, 27143, 28187, 27591, 37959, 37033, 35119, 28525],\n",
       " 34979: [26276, 37992, 28353, 27619, 28100, 26082, 27242, 28289, 36583, 27709],\n",
       " 34978: [31567, 14654, 37729, 20644, 34658, 28554, 27709, 20523, 28415, 27423],\n",
       " 34977: [34064, 26918, 27908, 14676, 24742, 36150, 27777, 34602, 27601, 31854],\n",
       " 34976: [36405, 36806, 25966, 27812, 32643, 28200, 36150, 34507, 28137, 11135],\n",
       " 34975: [20324, 26811, 26013, 20326, 28119, 37398, 36154, 35217, 28148, 36902],\n",
       " 34974: [25224, 27216, 29029, 33863, 37498, 24888, 17964, 32719, 18009, 35360],\n",
       " 34973: [36702, 28126, 14640, 27540, 20675, 26707, 37827, 36876, 28555, 26921],\n",
       " 34972: [20593, 30169, 26712, 35307, 27537, 28389, 28219, 36070, 37963, 35790],\n",
       " 34971: [25415, 36336, 36934, 28226, 26727, 36903, 20739, 36069, 25431, 36123],\n",
       " 34970: [32226, 28100, 28048, 31994, 32001, 31999, 14563, 27239, 27423, 38021],\n",
       " 34969: [27216, 37989, 27191, 35928, 37246, 27345, 27943, 28177, 27231, 28281],\n",
       " 34968: [36452, 36249, 35882, 26606, 14090, 35438, 14643, 37748, 37995, 28083],\n",
       " 34967: [27739, 35988, 26906, 28068, 36346, 37792, 37958, 37079, 24552, 14271],\n",
       " 34966: [20684, 20469, 28132, 31033, 32082, 37908, 37997, 28470, 37851, 14671],\n",
       " 34965: [37039, 28363, 36816, 35127, 28371, 35175, 26015, 35034, 27814, 37833],\n",
       " 34964: [28443, 27859, 14664, 35624, 28200, 37843, 28203, 38065, 36655, 37725],\n",
       " 34963: [27908, 33724, 31979, 34896, 37681, 27989, 28504, 28354, 28442, 36984],\n",
       " 34962: [20340, 26394, 26006, 27264, 36105, 24411, 26395, 20731, 24686, 2476],\n",
       " 34961: [27191, 27199, 27288, 20752, 37866, 36832, 37342, 20525, 36378, 25432],\n",
       " 34960: [27732, 25416, 20575, 37575, 28106, 24385, 37763, 25423, 27377, 25415],\n",
       " 34959: [27910, 26188, 27374, 34714, 27375, 37380, 20511, 25415, 36530, 20376],\n",
       " 34958: [20137, 14654, 20479, 27583, 20608, 14096, 37845, 28500, 26851, 37484],\n",
       " 34957: [27378, 37515, 20574, 37713, 20724, 31031, 20723, 27768, 31034, 25423],\n",
       " 34956: [34902, 20723, 36844, 25392, 28282, 38045, 25413, 12565, 36636, 36070],\n",
       " 34955: [36873, 25432, 20388, 28273, 37515, 20724, 36005, 26610, 27437, 37880],\n",
       " 34954: [37387, 28077, 20633, 20724, 27607, 27935, 37675, 36020, 27304, 27001],\n",
       " 34953: [27427, 26590, 31581, 20576, 27298, 22783, 30169, 1660, 1775, 37808],\n",
       " 34952: [27575, 14654, 20392, 28226, 25415, 21096, 26254, 38069, 27236, 27298],\n",
       " 34951: [37058, 27313, 20724, 26559, 20723, 26225, 28097, 26827, 25591, 27030],\n",
       " 34950: [35556, 27407, 31979, 26810, 20637, 37058, 26969, 20723, 37168, 27067],\n",
       " 34949: [28527, 26410, 37640, 20723, 35160, 20615, 28480, 35302, 31035, 14621],\n",
       " 34948: [37423, 37178, 28438, 20575, 20724, 28281, 20723, 20576, 27750, 28364],\n",
       " 34947: [28509, 28158, 28459, 37813, 34343, 36919, 36260, 35831, 35919, 20677],\n",
       " 34946: [20574, 20576, 31975, 19986, 21096, 14338, 27298, 31977, 27575, 38092],\n",
       " 34945: [20575, 27236, 20566, 28226, 31977, 26750, 31973, 19983, 26254, 27675],\n",
       " 34944: [31350, 37527, 20574, 37713, 20576, 34791, 28333, 20725, 24416, 14100],\n",
       " 34943: [28428, 34767, 28251, 27989, 38092, 36402, 20712, 14621, 37721, 30037],\n",
       " 34942: [28164, 27575, 34623, 35967, 37432, 20232, 37530, 28441, 28126, 27878],\n",
       " 34941: [35556, 31722, 28260, 38073, 31725, 20634, 37851, 31978, 20576, 31678],\n",
       " 34940: [25102, 28301, 37026, 28172, 27588, 37130, 28129, 28097, 28267, 27781],\n",
       " 34939: [28077, 36582, 28158, 27432, 37491, 28208, 34909, 38107, 20210, 20485],\n",
       " 34938: [32081, 27201, 36804, 26754, 37667, 22387, 27971, 37560, 36402, 20777],\n",
       " 34937: [30331, 28292, 27675, 20392, 20705, 20344, 25431, 25392, 21095, 30855],\n",
       " 34936: [27295, 27445, 28180, 27831, 36373, 20713, 26715, 36798, 37217, 28400],\n",
       " 34935: [36397, 28349, 27154, 28226, 27760, 27403, 26936, 20633, 27439, 35790],\n",
       " 34934: [28476, 31978, 36261, 31980, 37677, 27647, 31975, 28023, 28349, 37551],\n",
       " 34933: [37289, 26820, 19939, 37578, 37711, 28100, 14632, 37791, 36583, 38092],\n",
       " 34932: [32068, 20575, 20594, 14579, 20344, 27298, 14654, 20137, 25392, 25437],\n",
       " 34931: [31765, 28368, 27709, 36919, 27423, 32041, 28353, 28466, 37759, 35227],\n",
       " 34930: [37026, 37462, 37960, 36781, 37432, 28414, 38087, 20630, 37942, 28402],\n",
       " 34929: [36210, 25080, 34496, 31763, 26894, 19467, 24579, 31920, 25962, 35425],\n",
       " 34928: [23677, 35041, 29847, 37372, 36297, 31573, 27164, 27276, 27983, 37717],\n",
       " 34927: [35370, 27497, 36126, 28374, 20601, 27510, 27255, 35531, 37792, 26688],\n",
       " 34926: [34211, 35468, 34783, 36703, 34290, 35550, 14689, 27759, 20657, 27624],\n",
       " 34925: [27164, 34332, 35992, 35397, 28432, 28454, 36849, 37023, 35777, 37404],\n",
       " 34924: [36800, 33751, 34372, 37215, 23677, 14418, 36629, 36144, 27255, 14482],\n",
       " 34923: [26606, 37388, 34795, 24246, 35229, 20107, 25210, 26944, 31446, 34783],\n",
       " 34922: [36529, 36362, 27785, 28065, 36070, 38011, 38013, 37422, 36784, 37712],\n",
       " 34921: [37026, 28106, 30872, 14546, 27580, 27701, 31976, 27047, 28268, 27913],\n",
       " 34920: [28401, 28049, 37041, 37813, 28282, 28200, 37510, 20644, 36729, 37816],\n",
       " 34919: [30808, 38094, 37537, 27696, 27732, 28203, 27963, 37720, 14096, 37712],\n",
       " 34918: [31563, 25389, 27805, 27575, 27495, 28309, 36444, 37780, 37286, 26422],\n",
       " 34917: [31565, 38030, 26424, 37798, 27750, 21096, 37525, 35374, 27346, 14546],\n",
       " 34916: [26597, 37108, 36740, 28097, 27079, 28226, 28200, 25415, 28545, 37289],\n",
       " 34915: [19939, 34397, 35521, 20375, 34631, 27552, 20697, 25370, 15330, 15966],\n",
       " 34914: [37289, 35879, 36616, 20635, 37172, 27756, 37561, 14621, 28260, 37718],\n",
       " 34913: [28476, 37041, 20575, 27709, 36069, 27423, 28554, 27723, 27154, 37791],\n",
       " 34912: [27760, 28053, 27647, 26619, 20739, 36570, 27744, 26851, 28104, 37886],\n",
       " 34911: [24575, 20575, 27675, 27111, 27231, 25423, 24417, 27067, 28126, 25415],\n",
       " 34910: [37259, 37840, 37763, 28260, 28126, 37753, 37998, 37481, 34923, 37592],\n",
       " 34909: [20388, 28226, 27163, 25437, 20305, 25426, 37400, 28415, 38054, 28200],\n",
       " 34908: [27616, 20632, 37472, 26436, 36247, 27693, 28384, 28402, 36714, 28549],\n",
       " 34907: [27525, 28078, 28441, 27458, 25591, 14100, 28333, 37872, 37793, 20575],\n",
       " 34906: [20632, 34573, 37998, 28333, 20575, 20576, 21096, 28260, 28562, 28516],\n",
       " 34905: [37108, 19939, 27744, 36394, 26886, 19938, 20727, 36872, 20344, 28200],\n",
       " 34904: [27888, 20633, 20632, 37960, 37400, 27575, 27675, 37289, 31043, 36529],\n",
       " 34903: [20397, 31725, 31723, 35393, 28479, 34561, 27337, 31179, 26429, 25122],\n",
       " 34902: [27888, 37774, 20766, 28065, 36107, 27027, 28123, 37716, 27329, 36414],\n",
       " 34901: [28476, 37791, 26269, 20575, 20725, 28397, 26559, 38092, 37497, 25392],\n",
       " 34900: [31350, 24993, 24415, 27636, 34810, 28292, 25908, 35715, 20748, 35269],\n",
       " 34899: [19936, 27844, 19938, 28441, 31980, 27750, 25406, 32068, 35150, 19935],\n",
       " 34898: [27610, 31989, 36616, 31336, 26960, 26476, 27835, 33983, 38082, 37960],\n",
       " 34897: [30951, 30950, 36737, 26827, 36370, 24774, 27745, 26225, 36821, 25503],\n",
       " 34896: [26960, 20494, 28555, 27543, 27270, 27720, 23712, 35797, 25352, 26922],\n",
       " 34895: [28364, 28442, 37510, 36230, 37731, 20576, 32009, 26818, 37727, 37168],\n",
       " 34894: [26688, 24629, 14636, 37206, 27726, 36800, 36233, 35882, 34332, 29829],\n",
       " 34893: [31577, 35185, 31612, 28071, 36226, 32897, 19477, 34226, 19475, 33785],\n",
       " 34892: [20015, 35187, 37715, 15552, 35771, 16175, 35179, 35370, 26944, 28071],\n",
       " 34891: [28374, 28310, 34067, 26944, 37062, 26417, 33358, 36073, 27759, 32832],\n",
       " 34890: [26797, 24878, 26944, 26430, 27008, 19458, 20107, 34686, 35169, 27258],\n",
       " 34889: [33197, 23677, 26688, 26944, 24629, 27008, 34873, 36340, 36178, 27024],\n",
       " 34888: [14182, 34399, 25564, 34940, 37088, 36980, 35988, 37785, 19458, 25884],\n",
       " 34887: [26390, 37206, 25210, 19458, 27510, 35370, 35412, 34342, 27759, 27009],\n",
       " 34886: [28547, 38081, 28304, 37344, 25564, 26427, 35283, 26688, 36346, 35963],\n",
       " 34885: [27864, 27739, 28083, 37120, 26932, 26944, 35876, 35882, 32038, 35397],\n",
       " 34884: [36233, 36676, 37620, 25884, 35370, 36346, 35882, 37206, 36693, 36505],\n",
       " 34883: [27487, 20705, 36749, 27242, 27163, 27047, 26162, 19983, 20500, 20344],\n",
       " 34882: [27616, 28222, 28482, 27280, 14596, 21111, 27964, 28503, 34253, 20633],\n",
       " 34881: [36806, 25077, 25343, 28226, 25639, 24575, 36570, 28192, 26332, 37105],\n",
       " 34880: [20575, 27744, 34857, 14682, 37315, 24553, 25001, 20498, 37466, 20576],\n",
       " 34879: [20704, 36840, 27530, 25416, 36480, 14567, 36784, 27709, 37424, 27601],\n",
       " 34878: [27469, 26664, 24885, 35669, 27535, 20469, 26330, 27140, 35428, 25515],\n",
       " 34877: [25286, 25415, 25465, 20412, 35253, 27349, 27785, 25301, 25466, 27649],\n",
       " 34876: [27137, 26918, 27777, 20574, 36129, 28097, 14682, 31031, 20576, 28187],\n",
       " 34875: [27193, 37515, 28213, 27723, 27135, 27917, 27732, 14682, 37725, 20748],\n",
       " 34874: [27622, 28349, 37561, 28194, 31968, 28464, 31967, 38115, 14473, 37355],\n",
       " 34873: [25365, 27505, 28100, 20479, 34397, 27768, 25699, 25413, 26918, 27818],\n",
       " 34872: [26962, 14683, 20633, 35157, 27374, 28137, 27701, 26727, 35765, 28337],\n",
       " 34871: [20338, 28500, 35601, 36884, 20731, 20740, 30163, 20698, 3108, 36413],\n",
       " 34870: [35889, 26597, 19629, 25039, 22825, 26600, 26018, 36012, 25795, 37646],\n",
       " 34869: [36738, 37940, 27345, 36844, 36866, 28561, 14671, 14626, 37525, 35548],\n",
       " 34868: [28262, 20575, 14671, 14615, 37423, 26909, 31034, 27693, 27443, 31035],\n",
       " 34867: [27047, 28507, 27485, 24575, 27616, 26922, 20481, 33976, 33961, 25594],\n",
       " 34866: [28549, 20576, 20633, 28088, 27744, 28025, 36642, 28476, 27959, 37925],\n",
       " 34865: [14654, 31020, 20723, 28200, 21096, 20632, 14579, 28354, 37665, 37763],\n",
       " 34864: [36750, 31581, 28275, 31585, 31580, 26886, 14621, 36994, 37713, 28333],\n",
       " 34863: [28260, 28264, 37864, 28275, 28354, 27693, 37832, 14645, 31977, 28549],\n",
       " 34862: [37712, 28164, 37998, 27675, 28252, 28275, 37960, 36069, 37807, 27154],\n",
       " 34861: [35734, 27403, 27583, 14621, 35520, 36129, 20551, 27143, 37864, 28549],\n",
       " 34860: [20575, 31580, 31582, 28275, 28226, 27721, 20209, 37665, 37479, 28549],\n",
       " 34859: [36069, 36409, 20576, 20740, 27143, 26851, 37845, 28294, 28147, 36884],\n",
       " 34858: [28275, 27917, 27625, 37041, 20485, 15966, 32050, 35521, 28301, 27812],\n",
       " 34857: [28549, 27580, 27723, 28554, 35366, 20575, 27709, 31726, 20484, 27423],\n",
       " 34856: [27057, 28285, 27963, 38093, 36699, 37083, 37139, 31797, 37001, 28245],\n",
       " 34855: [27588, 28549, 37880, 28267, 26342, 37432, 28349, 26126, 28158, 38094],\n",
       " 34854: [32069, 20748, 37472, 27783, 36781, 14645, 27926, 28428, 20682, 27445],\n",
       " 34853: [20485, 28476, 19234, 36781, 37925, 14645, 37331, 36647, 14680, 37552],\n",
       " 34852: [20574, 36993, 31947, 31020, 37428, 35653, 27745, 27534, 37329, 14579],\n",
       " 34851: [36806, 20632, 27575, 37108, 31021, 26977, 27723, 19255, 28476, 35715],\n",
       " 34850: [28441, 36726, 14621, 28052, 14680, 37832, 28402, 36381, 37737, 37871],\n",
       " 34849: [36950, 35841, 27723, 37012, 24553, 28275, 20484, 28549, 24958, 28292],\n",
       " 34848: [37882, 24416, 31582, 26126, 24415, 31585, 26809, 31580, 28088, 31581],\n",
       " 34847: [37472, 27693, 26960, 27771, 37925, 36863, 14645, 25140, 35012, 28275],\n",
       " 34846: [36570, 20499, 28065, 27831, 20498, 36881, 37038, 37742, 24192, 36698],\n",
       " 34845: [37888, 14677, 28077, 36726, 28441, 38066, 37832, 37634, 28275, 25423],\n",
       " 34844: [31327, 17313, 37481, 20499, 28158, 37331, 27693, 27831, 28349, 27654],\n",
       " 34843: [36123, 28409, 20696, 37723, 37105, 28476, 28053, 28416, 28275, 37341],\n",
       " 34842: [28158, 14621, 37882, 27573, 37315, 28334, 37942, 26369, 28241, 36383],\n",
       " 34841: [31382, 36961, 28104, 26501, 31021, 20124, 31385, 28267, 26424, 27110],\n",
       " 34840: [36948, 28275, 36480, 28049, 28496, 14680, 28402, 36247, 38065, 28200],\n",
       " 34839: [14621, 27693, 37331, 36247, 36107, 38045, 28298, 38057, 37496, 37472],\n",
       " 34838: [37561, 28252, 37895, 27580, 38117, 28273, 37925, 37331, 37960, 20576],\n",
       " 34837: [28459, 27811, 28275, 37081, 28169, 37371, 35708, 26163, 27140, 20338],\n",
       " 34836: [20574, 28549, 36069, 25077, 20344, 36397, 27917, 28226, 21096, 14338],\n",
       " 34835: [28275, 36726, 37925, 28402, 20633, 27709, 28476, 36642, 28100, 27445],\n",
       " 34834: [27374, 27579, 36150, 14714, 28275, 23846, 20305, 38076, 26959, 28187],\n",
       " 34833: [36988, 32082, 27774, 36781, 21826, 14462, 21717, 35654, 36467, 36895],\n",
       " 34832: [27830, 28285, 14560, 26766, 28005, 14473, 31968, 36305, 26664, 31606],\n",
       " 34831: [20757, 20756, 33706, 20754, 20073, 20295, 31879, 34352, 33717, 20293],\n",
       " 34830: [25851, 14620, 28063, 37832, 36616, 27140, 37723, 27835, 28066, 26163],\n",
       " 34829: [23175, 24382, 37400, 36992, 31381, 28550, 31385, 28436, 28049, 31383],\n",
       " 34828: [14620, 20617, 20638, 28368, 28344, 37423, 38027, 20210, 20705, 20637],\n",
       " 34827: [20484, 27830, 28456, 28554, 27693, 27455, 37472, 37156, 36714, 38087],\n",
       " 34826: [31567, 27575, 27912, 20608, 31581, 27208, 28353, 26712, 25591, 20575],\n",
       " 34825: [35742, 28355, 35050, 35914, 35557, 36088, 36089, 37758, 36323, 36324],\n",
       " 34824: [38044, 27599, 32068, 28256, 37462, 26188, 27031, 21886, 34972, 34261],\n",
       " 34823: [24993, 26501, 27172, 24388, 25343, 25436, 25417, 26886, 23712, 14317],\n",
       " 34822: [28549, 31034, 31027, 27723, 37930, 14615, 26387, 27917, 27859, 31035],\n",
       " 34821: [37592, 28132, 37998, 26709, 31989, 37289, 27110, 37905, 31026, 31027],\n",
       " 34820: [38119, 28474, 26835, 14671, 26861, 28413, 14588, 26379, 27978, 26709],\n",
       " 34819: [28353, 28038, 27106, 25431, 37960, 25415, 20525, 36714, 37472, 27693],\n",
       " 34818: [25362, 14676, 26254, 26541, 31994, 31027, 27118, 31978, 27580, 31029],\n",
       " 34817: [31034, 37423, 28438, 31027, 14671, 14588, 26697, 31025, 21717, 14623],\n",
       " 34816: [20483, 31563, 24416, 31035, 20575, 31031, 14671, 20574, 38039, 35850],\n",
       " 34815: [31025, 31034, 37105, 31027, 26886, 28275, 37960, 26505, 36616, 14671],\n",
       " 34814: [26712, 31027, 31032, 20511, 31035, 28108, 14714, 28097, 14671, 20725],\n",
       " 34813: [38039, 25418, 36439, 25432, 30301, 14626, 25661, 26420, 26697, 26379],\n",
       " 34812: [36608, 31034, 20633, 20638, 27675, 26040, 14623, 28050, 28106, 27231],\n",
       " 34811: [31033, 28474, 28476, 14671, 31032, 31028, 26379, 26697, 14623, 31035],\n",
       " 34810: [28262, 28527, 31029, 31035, 28438, 14615, 14671, 38039, 31034, 24774],\n",
       " 34809: [20638, 36397, 32068, 14680, 20377, 28088, 20378, 36642, 37925, 25699],\n",
       " 34808: [27649, 27709, 28287, 34674, 28137, 14612, 28097, 20523, 36397, 31977],\n",
       " 34807: [26486, 35458, 34812, 30890, 26720, 8044, 36724, 26993, 19675, 20600],\n",
       " 34806: [37870, 27831, 36214, 20633, 25608, 36463, 38021, 37321, 27498, 1935],\n",
       " 34805: [20575, 37178, 31034, 31026, 14615, 14671, 36844, 37882, 20523, 28282],\n",
       " 34804: [24949, 24991, 14582, 26480, 37075, 36021, 14563, 14661, 33778, 27192],\n",
       " 34803: [26963, 27001, 25136, 26661, 35527, 37834, 31725, 19980, 19718, 17337],\n",
       " 34802: [27739, 26698, 27026, 33785, 26016, 28547, 28499, 27024, 35330, 36755],\n",
       " 34801: [35229, 27624, 37062, 34892, 14428, 36178, 27890, 36629, 37850, 26932],\n",
       " 34800: [27216, 26794, 23840, 35253, 36863, 27520, 14626, 14623, 37498, 14681],\n",
       " 34799: [27541, 31854, 37022, 26909, 28096, 26959, 28200, 34507, 27047, 31043],\n",
       " 34798: [32655, 26298, 21095, 25415, 23712, 24429, 27709, 25392, 24412, 28020],\n",
       " 34797: [26107, 36538, 26427, 27892, 25496, 27814, 37372, 35370, 33271, 35397],\n",
       " 34796: [35149, 14602, 26194, 33947, 35773, 25392, 24388, 25436, 25435, 25393],\n",
       " 34795: [37930, 31020, 27917, 25428, 27732, 27826, 26522, 36637, 28306, 25343],\n",
       " 34794: [27724, 26794, 31606, 27647, 19939, 27345, 36069, 37105, 31881, 35587],\n",
       " 34793: [36806, 32067, 26254, 27452, 20632, 32069, 28476, 27231, 34212, 27723],\n",
       " 34792: [27583, 25392, 31886, 31885, 28096, 31887, 20714, 27298, 31884, 27763],\n",
       " 34791: [26207, 26992, 27300, 31021, 20723, 31581, 37484, 20546, 14579, 20525],\n",
       " 34790: [20575, 27300, 27225, 25426, 25418, 25434, 27671, 28226, 25417, 25168],\n",
       " 34789: [20684, 20305, 20681, 27495, 26505, 36988, 36698, 32082, 32048, 14680],\n",
       " 34788: [27790, 37120, 36144, 37149, 36226, 35882, 35650, 36346, 26606, 37748],\n",
       " 34787: [35509, 32716, 25854, 34247, 8095, 37807, 33394, 34387, 24936, 25962],\n",
       " 34786: [31372, 19767, 19766, 19768, 26021, 32597, 5651, 31520, 10520, 11245],\n",
       " 34785: [28364, 31035, 28262, 28368, 31034, 26697, 31027, 14593, 38119, 37880],\n",
       " 34784: [31026, 27760, 27427, 14593, 26541, 38039, 14627, 14625, 26254, 14544],\n",
       " 34783: [31033, 14623, 14625, 31035, 14588, 14544, 26262, 31025, 14659, 20316],\n",
       " 34782: [14590, 31994, 37416, 20576, 19899, 31027, 25415, 14588, 19900, 31031],\n",
       " 34781: [31029, 14615, 14544, 31035, 14588, 25415, 31032, 38039, 26379, 20530],\n",
       " 34780: [32158, 27626, 36151, 14671, 31033, 31032, 38119, 31031, 26170, 31034],\n",
       " 34779: [14591, 31027, 24993, 27374, 21717, 14588, 37290, 20594, 31035, 20575],\n",
       " 34778: [27530, 14627, 19938, 14623, 27709, 37720, 20499, 27074, 32048, 31027],\n",
       " 34777: [14625, 31028, 14544, 14588, 11079, 25402, 14651, 25406, 26686, 25397],\n",
       " 34776: [31032, 31027, 14588, 38039, 14544, 31028, 25411, 25402, 31025, 25406],\n",
       " 34775: [26697, 14430, 31035, 31026, 31029, 14588, 20575, 14544, 25419, 27208],\n",
       " 34774: [26697, 14591, 14671, 14626, 38039, 14588, 14544, 31025, 38119, 28100],\n",
       " 34773: [31029, 14623, 14588, 14659, 14544, 31025, 20576, 20574, 20575, 25411],\n",
       " 34772: [14593, 14591, 31029, 14615, 14659, 14544, 14588, 31028, 25402, 26379],\n",
       " 34771: [36595, 38119, 14659, 14588, 14544, 31028, 34119, 31025, 14651, 26379],\n",
       " 34770: [31033, 14625, 31027, 38119, 31028, 14659, 14588, 14544, 25419, 28262],\n",
       " 34769: [14593, 31035, 31034, 14623, 14588, 14544, 14659, 26686, 31030, 14651],\n",
       " 34768: [14625, 14588, 14544, 31028, 31025, 25411, 26541, 25402, 25406, 14651],\n",
       " 34767: [14590, 31034, 38039, 31025, 28523, 26541, 37908, 14588, 28504, 14659],\n",
       " 34766: [31033, 14590, 31026, 38039, 14659, 31028, 14588, 14544, 25436, 25435],\n",
       " 34765: [31996, 27917, 26709, 14591, 31034, 27732, 14615, 31994, 31031, 33355],\n",
       " 34764: [31027, 14615, 14659, 31028, 14544, 14588, 31025, 25402, 25406, 14651],\n",
       " 34763: [14627, 31026, 31032, 36694, 31993, 31996, 28262, 14671, 14623, 14626],\n",
       " 34762: [14591, 31034, 31035, 31027, 36844, 14544, 14588, 28282, 38119, 28472],\n",
       " 34761: [27943, 35928, 28295, 26240, 27345, 37886, 37116, 37463, 33963, 28269],\n",
       " 34760: [37287, 28282, 36504, 35548, 14544, 27689, 38013, 27419, 14096, 27744],\n",
       " 34759: [28405, 27462, 20574, 28368, 26715, 14544, 27978, 20576, 27661, 25471],\n",
       " 34758: [27784, 14544, 23929, 27030, 27772, 23712, 25435, 27163, 12458, 30856],\n",
       " 34757: [27037, 14544, 26619, 20705, 19967, 25415, 26188, 27170, 35302, 35647],\n",
       " 34756: [26697, 14627, 14544, 14615, 31033, 14625, 31032, 31035, 31025, 38039],\n",
       " 34755: [34791, 27706, 26351, 14544, 14671, 31033, 25431, 25417, 31027, 31031],\n",
       " 34754: [24427, 21728, 20494, 27135, 34941, 21730, 27625, 24425, 24428, 24416],\n",
       " 34753: [35414, 30950, 30952, 37065, 30954, 19731, 31581, 37497, 31583, 35189],\n",
       " 34752: [30951, 30950, 26856, 27466, 24836, 30954, 37454, 25503, 27317, 20532],\n",
       " 34751: [20343, 19254, 37042, 37432, 38115, 25643, 34412, 26923, 24426, 27575],\n",
       " 34750: [14639, 27677, 36570, 20727, 31021, 28023, 27661, 27852, 24388, 25428],\n",
       " 34749: [19868, 31985, 19898, 37396, 36291, 28117, 28024, 37280, 37729, 20600],\n",
       " 34748: [37428, 14563, 26682, 28048, 26917, 32074, 34641, 32056, 32055, 36308],\n",
       " 34747: [28110, 35654, 35218, 25136, 26963, 14462, 25545, 14582, 30780, 35435],\n",
       " 34746: [35270, 27390, 14563, 24949, 28048, 20499, 26285, 26330, 37350, 36708],\n",
       " 34745: [36463, 14563, 26354, 25797, 25187, 14567, 14613, 27517, 14661, 37241],\n",
       " 34744: [26351, 14563, 20315, 14613, 35362, 31963, 30907, 20317, 35527, 36255],\n",
       " 34743: [14690, 27231, 31725, 14563, 28014, 31973, 28192, 34135, 27675, 14613],\n",
       " 34742: [33650, 25369, 28353, 28004, 20500, 20386, 27632, 20715, 35012, 20714],\n",
       " 34741: [26861, 27304, 25365, 25369, 27001, 25413, 37426, 26336, 25406, 27040],\n",
       " 34740: [26891, 20575, 26424, 26861, 35435, 26619, 25417, 14546, 35091, 28268],\n",
       " 34739: [27356, 31581, 19967, 20511, 34573, 27505, 19938, 37604, 27042, 14654],\n",
       " 34738: [36608, 28389, 27675, 20748, 28200, 20574, 30775, 20575, 28226, 32071],\n",
       " 34737: [28158, 31021, 36844, 20485, 28281, 32057, 28316, 20483, 37105, 14692],\n",
       " 34736: [27375, 20574, 20576, 14654, 28200, 12565, 28343, 14498, 37763, 20723],\n",
       " ...}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_prediction_dict = decode_predictions(categorical_training_dataframe, drop_ids=False)\n",
    "submission_prediction_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_recommendation(recommendation: list[str]) -> str:\n",
    "    return \" \".join([str(item) for item in recommendation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>572 7547 9911 399 7703 11580 14888 531 4232 28958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6348 14748 13766 9812 18964 11149 7139 572 313...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>8403 22692 15542 29963 13252 22714 21363 22589...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>25140 25079 6189 25643 23023 23712 11362 6827 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15902 9812 17624 8612 9447 18304 4695 18647 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34226</th>\n",
       "      <td>35729</td>\n",
       "      <td>36844 26093 24415 24417 35548 36527 26581 2753...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34227</th>\n",
       "      <td>35730</td>\n",
       "      <td>28247 38027 37211 37420 37739 37874 27350 2811...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34228</th>\n",
       "      <td>35731</td>\n",
       "      <td>37739 36263 38027 37427 36525 37623 28119 3539...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34229</th>\n",
       "      <td>35734</td>\n",
       "      <td>37069 36610 36168 35345 37550 37067 35093 3688...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34230</th>\n",
       "      <td>35735</td>\n",
       "      <td>37657 36493 36773 36917 36034 37445 37660 3692...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34231 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       user_id                                          item_list\n",
       "0            0  572 7547 9911 399 7703 11580 14888 531 4232 28958\n",
       "1            1  6348 14748 13766 9812 18964 11149 7139 572 313...\n",
       "2            2  8403 22692 15542 29963 13252 22714 21363 22589...\n",
       "3            3  25140 25079 6189 25643 23023 23712 11362 6827 ...\n",
       "4            4  15902 9812 17624 8612 9447 18304 4695 18647 34...\n",
       "...        ...                                                ...\n",
       "34226    35729  36844 26093 24415 24417 35548 36527 26581 2753...\n",
       "34227    35730  28247 38027 37211 37420 37739 37874 27350 2811...\n",
       "34228    35731  37739 36263 38027 37427 36525 37623 28119 3539...\n",
       "34229    35734  37069 36610 36168 35345 37550 37067 35093 3688...\n",
       "34230    35735  37657 36493 36773 36917 36034 37445 37660 3692...\n",
       "\n",
       "[34231 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[\"item_list\"] = [\n",
    "    encode_recommendation(recommendation)\n",
    "    for recommendation in pd.Series(submission_prediction_dict).loc[test_df[\"user_id\"]]\n",
    "]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(SUBMISSION_PATH, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
