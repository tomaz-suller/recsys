{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Evaluation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m average_precision_score\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mEvaluation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mEvaluator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluatorHoldout\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Evaluation'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Tuple, Callable, Dict, Optional, List\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from Evaluation.Evaluator import EvaluatorHoldout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URM = pd.read_csv(\"./data/data_train.csv\")\n",
    "ICM = pd.read_csv(\"./data/data_ICM_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_users = URM.user_id.unique()\n",
    "max_user_id = unique_users.max()\n",
    "min_user_id = unique_users.min()\n",
    "num_users = unique_users.size\n",
    "print(f\"Max User ID: {max_user_id}, Min User ID: {min_user_id}, Number of IDs: {num_users}\")\n",
    "\n",
    "unique_items = ICM.item_id.unique()\n",
    "max_item_id = ICM.item_id.max()\n",
    "min_item_id = ICM.item_id.min()\n",
    "num_items = unique_items.size\n",
    "unique_features = ICM.feature_id.unique()\n",
    "num_features = unique_features.size\n",
    "min_features_id = ICM.feature_id.min()\n",
    "max_features_id = ICM.feature_id.max()\n",
    "print(f\"Max Item ID: {max_item_id}, Min Item ID: {min_item_id}, Number of IDs: {num_items}\")\n",
    "print(f\"Max Feature ID: {max_features_id}, Min Item ID: {min_features_id}, Number of IDs: {num_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_splits(ratings, num_users, num_items, validation_percentage: float, testing_percentage: float):\n",
    "    seed = 1234\n",
    "\n",
    "    # Construct the whole URM as a sparse matrix\n",
    "    urm_all = sp.csr_matrix((ratings.data, (ratings.user_id, ratings.item_id)),\n",
    "                            shape=(num_users, num_items))\n",
    "\n",
    "    # Split into train + validation and test sets\n",
    "    train_val_indices, test_indices = train_test_split(\n",
    "        np.arange(len(ratings)),\n",
    "        test_size=testing_percentage,\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Split train + validation into train and validation\n",
    "    train_indices, val_indices = train_test_split(\n",
    "        train_val_indices,\n",
    "        test_size=validation_percentage / (1 - testing_percentage),\n",
    "        shuffle=True,\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Get user, item, and rating data for each set\n",
    "    train_data = ratings.iloc[train_indices]\n",
    "    val_data = ratings.iloc[val_indices]\n",
    "    test_data = ratings.iloc[test_indices]\n",
    "    \n",
    "    # Construct sparse matrices\n",
    "    urm_train = sp.csr_matrix((train_data.data, (train_data.user_id, train_data.item_id)), \n",
    "                              shape=(num_users, num_items))\n",
    "    urm_validation = sp.csr_matrix((val_data.data, (val_data.user_id, val_data.item_id)), \n",
    "                                   shape=(num_users, num_items))\n",
    "    urm_test = sp.csr_matrix((test_data.data, (test_data.user_id, test_data.item_id)), \n",
    "                             shape=(num_users, num_items))\n",
    "\n",
    "    return urm_all, urm_train, urm_validation, urm_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urm_all, urm_train, urm_validation, urm_test = dataset_splits(URM, \n",
    "                                                     num_users=num_users, \n",
    "                                                     num_items=num_items, \n",
    "                                                     validation_percentage=0.10, \n",
    "                                                     testing_percentage=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ICM' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m icm_matrix \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39mcsr_matrix((\u001b[43mICM\u001b[49m\u001b[38;5;241m.\u001b[39mdata, (ICM\u001b[38;5;241m.\u001b[39mitem_id, ICM\u001b[38;5;241m.\u001b[39mfeature_id)), \n\u001b[1;32m      2\u001b[0m                            shape\u001b[38;5;241m=\u001b[39m(num_items, num_features))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ICM' is not defined"
     ]
    }
   ],
   "source": [
    "icm_matrix = sp.csr_matrix((ICM.data, (ICM.item_id, ICM.feature_id)), \n",
    "                           shape=(num_items, num_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_rp3_slim_hybrid(urm_train, icm, urm_validation, n_trials=30, output_folder=\"optimization_results\"):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    log_file = os.path.join(output_folder, f'rp3_slim_optimization_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.log')\n",
    "    \n",
    "    logging.basicConfig(\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "        handlers=[\n",
    "            logging.FileHandler(log_file),\n",
    "            logging.StreamHandler()\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    evaluator_validation = EvaluatorHoldout(urm_validation, cutoff_list=[10])  # Set cutoff to 10\n",
    "    \n",
    "    def objective(trial):\n",
    "        try:\n",
    "            # RP3beta parameters\n",
    "            rp3beta_params = {\n",
    "                \"topK\": trial.suggest_int(\"rp3_topK\", 10, 200),\n",
    "                \"alpha\": trial.suggest_float(\"rp3_alpha\", 0.1, 1.0),\n",
    "                \"beta\": trial.suggest_float(\"rp3_beta\", 0.1, 1.0),\n",
    "                \"delta\": trial.suggest_float(\"rp3_delta\", 0.0, 1.0),\n",
    "                \"min_rating\": trial.suggest_float(\"rp3_min_rating\", 0.0, 5.0),\n",
    "                \"implicit\": trial.suggest_categorical(\"rp3_implicit\", [True, False]),\n",
    "                \"normalize_similarity\": trial.suggest_categorical(\"rp3_normalize\", [True, False])\n",
    "            }\n",
    "            \n",
    "            # SLIM parameters\n",
    "            slim_params = {\n",
    "                \"l1_ratio\": trial.suggest_float(\"slim_l1_ratio\", 0.0, 1.0),\n",
    "                \"alpha\": trial.suggest_float(\"slim_alpha\", 1e-4, 1e1, log=True),\n",
    "                \"positive_only\": trial.suggest_categorical(\"slim_positive_only\", [True, False]),\n",
    "                \"topK\": trial.suggest_int(\"slim_topK\", 10, 200),\n",
    "                \"do_feature_selection\": trial.suggest_categorical(\"do_feature_selection\", [True])\n",
    "            }\n",
    "            \n",
    "            # Hybrid weights\n",
    "            hybrid_params = {\n",
    "                \"rp3beta_weight\": trial.suggest_float(\"rp3beta_weight\", 0.0, 1.0),\n",
    "                \"slim_weight\": trial.suggest_float(\"slim_weight\", 0.0, 1.0)\n",
    "            }\n",
    "            \n",
    "            # Train RP3beta\n",
    "            rp3beta_recommender = RP3betaRecommenderICM(URM_train=urm_train, ICM=icm)\n",
    "            rp3beta_recommender.fit(**rp3beta_params)\n",
    "            \n",
    "            # Train SLIM\n",
    "            slim_recommender = SLIMElasticNetRecommender(URM_train=urm_train)\n",
    "            slim_recommender.fit(**slim_params)\n",
    "            \n",
    "            # Combine into Hybrid\n",
    "            hybrid_recommender = HybridRecommender(\n",
    "                URM_train=urm_train,\n",
    "                recommender_list=[rp3beta_recommender, slim_recommender],\n",
    "                recommender_weights=[hybrid_params[\"rp3beta_weight\"], hybrid_params[\"slim_weight\"]]\n",
    "            )\n",
    "            \n",
    "            # Evaluate using Recall@10\n",
    "            results_df, _ = evaluator_validation.evaluateRecommender(hybrid_recommender)\n",
    "            recall_at_10 = results_df.loc[10][\"RECALL\"]\n",
    "            \n",
    "            logging.info(f\"\\nTrial {trial.number} results:\")\n",
    "            logging.info(f\"Recall@10: {recall_at_10}\")\n",
    "            logging.info(f\"RP3beta weight: {hybrid_recommender.recommender_weights[0]:.3f}\")\n",
    "            logging.info(f\"SLIM weight: {hybrid_recommender.recommender_weights[1]:.3f}\")\n",
    "            \n",
    "            return recall_at_10\n",
    "            \n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error in trial {trial.number}: {str(e)}\")\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "    \n",
    "    # Create Optuna study and optimize\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    \n",
    "    try:\n",
    "        study.optimize(objective, n_trials=n_trials)\n",
    "        \n",
    "        best_params = study.best_params\n",
    "        best_recall = study.best_value\n",
    "        \n",
    "        logging.info(\"\\nOptimization completed!\")\n",
    "        logging.info(f\"Best Recall@10: {best_recall}\")\n",
    "        logging.info(\"Best parameters:\")\n",
    "        logging.info(json.dumps(best_params, indent=2))\n",
    "        \n",
    "        # Optional: Save visualization plots\n",
    "        try:\n",
    "            from optuna.visualization import plot_optimization_history, plot_param_importances\n",
    "            plot_optimization_history(study).write_image(os.path.join(output_folder, \"optimization_history.png\"))\n",
    "            plot_param_importances(study).write_image(os.path.join(output_folder, \"param_importances.png\"))\n",
    "        except ImportError:\n",
    "            logging.warning(\"Plotly not installed. Skipping visualization generation.\")\n",
    "        \n",
    "        return best_params, best_recall\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Optimization failed: {str(e)}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_recall = optimize_rp3_slim_hybrid(\n",
    "    urm_train=urm_train,\n",
    "    icm=icm_matrix,\n",
    "    urm_validation=urm_validation,\n",
    "    n_trials=2\n",
    ")\n",
    "\n",
    "print(\"Best Recall@10:\", best_recall)\n",
    "print(\"Best Parameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Recommenders.SLIM.SLIMElasticNetRecommender import SLIMElasticNetRecommender\n",
    "from Recommenders.GraphBased.RP3betaRecommenderICM import RP3betaRecommenderICM\n",
    "\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "\n",
    "def train_hybrid_with_best_params(urm_all, icm, best_params):\n",
    "    # RP3beta parameters\n",
    "    rp3beta_params = {\n",
    "        \"topK\": best_params[\"rp3_topK\"],\n",
    "        \"alpha\": best_params[\"rp3_alpha\"],\n",
    "        \"beta\": best_params[\"rp3_beta\"],\n",
    "        \"delta\": best_params[\"rp3_delta\"],\n",
    "        \"min_rating\": best_params[\"rp3_min_rating\"],\n",
    "        \"implicit\": best_params[\"rp3_implicit\"],\n",
    "        \"normalize_similarity\": best_params[\"rp3_normalize\"]\n",
    "    }\n",
    "    \n",
    "    # SLIM parameters\n",
    "    slim_params = {\n",
    "        \"l1_ratio\": best_params[\"slim_l1_ratio\"],\n",
    "        \"alpha\": best_params[\"slim_alpha\"],\n",
    "        \"positive_only\": best_params[\"slim_positive_only\"],\n",
    "        \"topK\": best_params[\"slim_topK\"],\n",
    "        \"do_feature_selection\": best_params[\"do_feature_selection\"]\n",
    "    }\n",
    "    \n",
    "    # Hybrid weights\n",
    "    hybrid_weights = [\n",
    "        best_params[\"rp3beta_weight\"],\n",
    "        best_params[\"slim_weight\"]\n",
    "    ]\n",
    "    \n",
    "    # Train RP3beta Recommender\n",
    "    logging.info(\"Training RP3beta Recommender...\")\n",
    "    rp3beta_recommender = RP3betaRecommenderICM(URM_train=urm_all, ICM=icm)\n",
    "    rp3beta_recommender.fit(**rp3beta_params)\n",
    "    logging.info(\"RP3beta Recommender trained successfully.\")\n",
    "    \n",
    "    # Train SLIM Recommender\n",
    "    logging.info(\"Training SLIM ElasticNet Recommender...\")\n",
    "    slim_recommender = SLIMElasticNetRecommender(URM_train=urm_all)\n",
    "    slim_recommender.fit(**slim_params)\n",
    "    logging.info(\"SLIM ElasticNet Recommender trained successfully.\")\n",
    "    \n",
    "    # Combine into Hybrid Recommender\n",
    "    logging.info(\"Training Hybrid Recommender...\")\n",
    "    hybrid_recommender = HybridRecommender(\n",
    "        URM_train=urm_all,\n",
    "        recommender_list=[rp3beta_recommender, slim_recommender],\n",
    "        recommender_weights=hybrid_weights\n",
    "    )\n",
    "    logging.info(\"Hybrid Recommender successfully trained.\")\n",
    "    \n",
    "    return hybrid_recommender\n",
    "\n",
    "# Fit the hybrid model with optimized parameters\n",
    "hybrid_model = train_hybrid_with_best_params(\n",
    "    urm_all=urm_all,\n",
    "    icm=icm_matrix,\n",
    "    best_params=best_params\n",
    ")\n",
    "\n",
    "# Optionally save the trained hybrid model\n",
    "output_model_file = \"hybrid_recommender.pkl\"\n",
    "import pickle\n",
    "with open(output_model_file, \"wb\") as file:\n",
    "    pickle.dump(hybrid_model, file)\n",
    "logging.info(f\"Hybrid model saved to {output_model_file}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
